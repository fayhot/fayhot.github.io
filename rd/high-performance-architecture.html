<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Fayhot's Blog" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-pace-theme-center-atom.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://fayhot.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: true,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="基础篇  高并发系统：它的通用设计方法是什么 高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。 我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：   Scale-out（横向扩展） 分而治之是一种常见的高并发系统设">
<meta name="keywords" content="Architecture">
<meta property="og:type" content="article">
<meta property="og:title" content="海量高并发系统架构设计">
<meta property="og:url" content="http:&#x2F;&#x2F;fayhot.github.io&#x2F;rd&#x2F;high-performance-architecture.html">
<meta property="og:site_name" content="Fayhot&#39;s Blog">
<meta property="og:description" content="基础篇  高并发系统：它的通用设计方法是什么 高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。 我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：   Scale-out（横向扩展） 分而治之是一种常见的高并发系统设">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801015445.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801020223.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801022321.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801023138.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801100734.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801104931.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105052.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105411.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105504.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801114354.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801115650.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801120009.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801123011.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801132328.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801132935.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801133231.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801134036.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801135310.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801144513.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801144922.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801145039.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801150736.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801152942.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801153004.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801153146.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801165824.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801170748.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801170817.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801171216.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801173226.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801173704.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801174534.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801174209.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801213850.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801213950.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801214139.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801214331.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801214434.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801215759.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801220108.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801220237.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801220900.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801223102.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801223333.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801223412.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801223813.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801224100.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801224140.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801224405.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801231029.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801232025.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801235001.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802002525.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802003646.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802004009.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802004109.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802004259.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802005612.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802005737.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802005917.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802005950.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802010347.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210802010533.png">
<meta property="og:updated_time" content="2021-08-01T17:17:23.550Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801015445.png">

<link rel="canonical" href="http://fayhot.github.io/rd/high-performance-architecture.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>海量高并发系统架构设计 | Fayhot's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fayhot's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://fayhot.github.io/rd/high-performance-architecture.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Fayhot">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fayhot's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          海量高并发系统架构设计
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-08-01 01:28:59" itemprop="dateCreated datePublished" datetime="2021-08-01T01:28:59+08:00">2021-08-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-08-02 01:17:23" itemprop="dateModified" datetime="2021-08-02T01:17:23+08:00">2021-08-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Research-And-Develop/" itemprop="url" rel="index">
                    <span itemprop="name">Research And Develop</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="基础篇"><a class="markdownIt-Anchor" href="#基础篇"></a> 基础篇</h2>
<h3 id="高并发系统它的通用设计方法是什么"><a class="markdownIt-Anchor" href="#高并发系统它的通用设计方法是什么"></a> 高并发系统：它的通用设计方法是什么</h3>
<p>高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。</p>
<p>我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：</p>
<ol>
<li>
<p>Scale-out（横向扩展）<br>
分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。</p>
</li>
<li>
<p>缓存<br>
使用缓存来提高系统的性能，就好比用 「拓宽河道」的方式抵抗高并发大流量的冲击。</p>
</li>
<li>
<p>异步<br>
在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。</p>
</li>
</ol>
<a id="more"></a>
<p>我们先来了解第一种方法：Scale-out。</p>
<h4 id="scale-up-vs-scale-out"><a class="markdownIt-Anchor" href="#scale-up-vs-scale-out"></a> Scale-up vs Scale-out</h4>
<ul>
<li>Scale-up 通过购买性能更好的硬件来提升系统的并发处理能力</li>
<li>Scale-out 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。</li>
</ul>
<p>一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。</p>
<p>Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？等等。其中每一个问题都涉及很多的知识点，我会在后面的课程中深入地讲解，这里暂时不展开了。</p>
<p>说完了 Scale-out，我们再来看看高并发系统设计的另一种方法：缓存。</p>
<h4 id="缓存提升性能"><a class="markdownIt-Anchor" href="#缓存提升性能"></a> 缓存提升性能</h4>
<p>我们使用缓存的主要作用是提升系统的访问性能，那么在高并发的场景下，就可以支撑更多用户的同时访问。</p>
<p>那么为什么缓存可以大幅度提升系统的性能呢？我们知道数据是放在持久化存储中的，一般的持久化存储都是使用磁盘作为存储介质的，而普通磁盘数据由机械手臂、磁头、转轴、盘片组成，盘片又分为磁道、柱面和扇区。</p>
<p>盘片是存储介质，每个盘片被划分为多个同心圆，信息都被存储在同心圆之中，这些 同心圆就是磁道。在磁盘工作时盘片是在高速旋转的，机械手臂驱动磁头沿着径向移动，在磁道上读取所需要的数据。我们把<strong>磁头寻找信息花费的时间叫做寻道时间</strong>。</p>
<p>普通磁盘的寻道时间是 <code>10ms</code> 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 <code>ns（纳秒）</code>级别，从千兆网卡上读取数据的时间是在 <code>μs（微秒）</code>级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。</p>
<p>当然，缓存的语义已经丰富了很多，我们<strong>可以将任何降低响应时间的中间存储都称为缓存</strong>。缓存的思想遍布很多设计领域，比如在操作系统中 <code>CPU</code> 有<code>多级缓存</code>，文件有 <code>Page Cache 缓存</code>，你应该有所了解。</p>
<h4 id="异步处理"><a class="markdownIt-Anchor" href="#异步处理"></a> 异步处理</h4>
<p>异步 也是一种常见的高并发设计方法，我们在很多文章和演讲中都能听到这个名词，与之共同出现的还有它的反义词：同步。比如，分布式服务框架 Dubbo 中有同步方法调用和异步方法调用，IO 模型中有同步 IO 和异步 IO。</p>
<p>那么什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。</p>
<p>异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。</p>
<p>异步调用在大规模高并发系统中被大量使用，比如我们熟知的 12306 网站。 当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。在 12306 系统中查询余票、下单和更改余票状态都是比较耗时的操作，可能涉及多个内部系统的互相调用，如果是同步调用就会像 12306 刚刚上线时那样，高峰期永远不可能下单成功。</p>
<p>而采用异步的方式，后端处理时会把请求丢到消息队列中，同时快速响应用户，告诉用户我们正在排队处理，然后释放出资源来处理更多的请求。订票请求处理完之后，再通知用户订票成功或者失败。</p>
<p>处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801015445.png"></p>
<p>建议一般系统的演进过程应该遵循下面的思路：</p>
<ol>
<li>最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。</li>
<li>随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。</li>
<li>当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。</li>
</ol>
<h3 id="架构分层"><a class="markdownIt-Anchor" href="#架构分层"></a> 架构分层</h3>
<p>软件架构分层在软件工程中是一种常见的设计方式，它是将整体系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能。</p>
<p>分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。想象一下，如果你要设计一款网络程序却没有分层，该是一件多么痛苦的事情。而有了分层的设计，你只需要专注设计应用层的程序就可以了，其他的，都可以交给下面几层来完成。再有，分层之后可以做到很高的复用。最后一点，分层架构可以让我们更容易做横向扩展。</p>
<p>我们可以将原先的三层架构细化成下面的样子：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801020223.png"></p>
<p>这个分层架构中的每一层的作用：</p>
<ul>
<li>
<p>终端显示层：<br>
各端模板渲染并执行显示的层。当前主要是 Velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。</p>
</li>
<li>
<p>开放接口层：<br>
将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。</p>
</li>
<li>
<p>Web 层：<br>
主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。</p>
</li>
<li>
<p>Service 层：业务逻辑层。</p>
</li>
<li>
<p>Manager 层：<br>
通用业务处理层。这一层主要有两个作用：<br>
其一，你可以将原先 Service 层的一些通用能力下沉到这一层，比如 与缓存和存储交互策略，中间件的接入；<br>
其二，你也可以在这一层 封装对第三方接口的调用，比如调用支付服务，调用审核服务等。<br>
DAO 层：</p>
</li>
<li>
<p>数据访问层，与底层 MySQL、Oracle、Hbase 等进行数据交互。</p>
</li>
<li>
<p>外部接口或第三方平台：<br>
包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。</p>
</li>
</ul>
<p>在这个分层架构中 主要增加了 Manager 层，它与 Service 层的关系是：</p>
<ol>
<li>Manager 层提供原子的服务接口</li>
<li>Service 层负责依据业务逻辑来编排原子接口。</li>
</ol>
<p>以上面的例子来说，Manager 层提供 创建用户 和 获取用户信息 的接口，而 Service 层负责将这两个接口组装起来。这样就把原先散布在表现层的业务逻辑都统一到了 Service 层，每一层的边界就非常清晰了。</p>
<blockquote>
<p><strong>分层架构需要考虑的另一个因素，是层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转</strong>。</p>
</blockquote>
<p>我们还是以三层架构为例，数据从表示层进入之后一定要流转到逻辑层，做业务逻辑处理，然后流转到数据访问层来和数据库交互。</p>
<p><strong>分层架构的不足</strong><br>
任何事物都不可能是尽善尽美的，分层架构虽有优势也会有缺陷，它最主要的一个缺陷就是增加了代码的复杂度，性能上会有损耗</p>
<h3 id="系统设计目标高性能-高可用-可扩展"><a class="markdownIt-Anchor" href="#系统设计目标高性能-高可用-可扩展"></a> 系统设计目标：高性能、高可用、可扩展</h3>
<p>高并发系统设计的三大目标：高性能、高可用、可扩展</p>
<h4 id="高并发"><a class="markdownIt-Anchor" href="#高并发"></a> 高并发</h4>
<p><strong>高并发</strong>， 是指运用设计手段让系统能够处理更多的用户并发请求，也就是承担更大的流量。它是一切架构设计的背景和前提，脱离了它去谈性能和可用性是没有意义的。很显然嘛，你在每秒一次请求和每秒一万次请求，两种不同的场景下，分别做到毫秒级响应时间和五个九（99.999%）的可用性，无论是设计难度还是方案的复杂度，都不是一个级别的。</p>
<p>而<strong>性能和可用性</strong>， 是我们实现高并发系统设计必须考虑的因素。</p>
<p>性能反应了系统的使用体验，想象一下，同样承担每秒一万次请求的两个系统，一个响应时间是毫秒级，一个响应时间在秒级别，它们带给用户的体验肯定是不同的。</p>
<p>可用性则表示系统可以正常服务用户的时间。我们再类比一下，还是两个承担每秒一万次的系统，一个可以做到全年不停机、无故障，一个隔三差五宕机维护，如果你是用户，你会选择使用哪一个系统呢？答案不言而喻。</p>
<p>另一个耳熟能详的名词叫 可扩展性 ，它同样是高并发系统设计需要考虑的因素。为什么呢？我来举一个具体的例子。</p>
<p>流量分为 <code>平时流量</code> 和 <code>峰值流量</code> 两种，峰值流量可能会是平时流量的几倍甚至几十倍，在应对峰值流量的时候，我们通常需要在架构和方案上做更多的准备。这就是淘宝会花费大半年的时间准备双十一，也是在面对「明星离婚」等热点事件时，看起来无懈可击的微博系统还是会出现服务不可用的原因。 而易于扩展的系统能在短时间内迅速完成扩容，更加平稳地承担峰值流量。</p>
<p>高性能、高可用和可扩展，是我们在做高并发系统设计时追求的三个目标，下面进一步了解在高并发大流量下如何设计高性能、高可用和易于扩展的系统。</p>
<p><strong>性能优化原则</strong></p>
<ol>
<li>性能优化一定不能盲目，一定是问题导向的<br>
脱离了问题，盲目地提早优化会增加系统的复杂度，浪费开发人员的时间，也因为某些优化可能会对业务上有些折中的考虑，所以也会损伤业务。</li>
<li>性能优化也遵循「八二原则」<br>
即你可以用 20% 的精力解决 80% 的性能问题。所以我们在优化过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点。</li>
<li>性能优化也要有数据支撑<br>
在优化过程中，你要时刻了解你的优化让响应时间减少了多少，提升了多少的吞吐量。</li>
<li>性能优化的过程是持续的</li>
</ol>
<p><strong>性能的度量指标</strong><br>
一般来说，度量性能的指标是 <code>系统接口的响应时间</code>，但是单次的响应时间是没有意义的，你需要知道一段时间的性能情况是什么样的。所以，我们需要收集这段时间的响应时间数据，然后依据一些统计方法计算出 特征值，这些特征值就能够代表这段时间的性能情况。我们常见的特征值有以下几类。</p>
<ol>
<li>平均值</li>
<li>最大值</li>
<li>分位值<br>
分位值有很多种，比如 90 分位、95 分位、75 分位。以 90 分位为例，我们把这段时间请求的 响应时间从小到大排序，假如一共有 100 个请求，那么排在第 90 位的响应时间就是 90 分位值。分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。</li>
</ol>
<p>在我来看，分位值是最适合作为时间段内，响应时间统计值来使用的，在实际工作中也应用最多。除此之外，平均值也可以作为一个参考值来使用。</p>
<p>我在上面提到，脱离了并发来谈性能是没有意义的，我们通常使用 吞吐量 或者 同时在线用户数 来度量并发和流量，使用吞吐量的情况会更多一些。但是你要知道，这两个指标是呈倒数关系的。</p>
<p>这很好理解，响应时间 1s 时，吞吐量是每秒 1 次，响应时间缩短到 10ms，那么吞吐量就上升到每秒 100 次。所以，一般我们度量性能时都会同时兼顾吞吐量和响应时间，比如我们设立性能优化的目标时通常会这样表述：在每秒 1 万次的请求量下，响应时间 99 分位值在 10ms 以下。</p>
<p>那么，响应时间究竟控制在多长时间比较合适呢？这个不能一概而论。</p>
<p>从用户使用体验的角度来看：</p>
<ul>
<li>
<p>200ms 是第一个分界点：<br>
接口的响应时间在 200ms 之内，用户是感觉不到延迟的，就像是瞬时发生的一样。</p>
</li>
<li>
<p>1s 是另外一个分界点：<br>
接口的响应时间在 1s 之内时，虽然用户可以感受到一些延迟，但却是可以接受的</p>
</li>
<li>
<p>超过 1s 之后用户就会有明显等待的感觉，等待时间越长，用户的使用体验就越差。</p>
</li>
</ul>
<p>所以，健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。</p>
<p><strong>高并发下的性能优化</strong><br>
假如说，你现在有一个系统，这个系统中处理核心只有一个，执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次。那么我们如何来优化性能从而提高系统的并发能力呢？主要有两种思路：</p>
<ol>
<li>一种是提高系统的处理核心数</li>
<li>一种是减少单次任务的响应时间。</li>
</ol>
<h5 id="提高系统的处理核心数"><a class="markdownIt-Anchor" href="#提高系统的处理核心数"></a> 提高系统的处理核心数</h5>
<p>提高系统的处理核心数就是 <code>增加系统的并行处理能力</code>，这个思路是优化性能最简单的途径。拿上一个例子来说，你可以把系统的处理核心数增加为两个，并且增加一个进程，让这两个进程跑在不同的核心上。这样从理论上，你系统的吞吐量可以增加一倍。当然了，在这种情况下，吞吐量和响应时间就不是倒数关系了，而是：<code>吞吐量 = 并发进程数 / 响应时间</code>。</p>
<p>计算机领域的阿姆达尔定律（Amdahl’s law）是吉恩·阿姆达尔在 1967 年提出的。它描述了并发进程数与响应时间之间的关系，含义是在固定负载下，并行计算的加速比，也就是并行化之后效率提升情况，可以用下面公式来表示：<code>(Ws + Wp) / (Ws + Wp/s)</code></p>
<p>其中，<code>Ws</code> 表示任务中的串行计算量，<code>Wp</code> 表示任务中的并行计算量，<code>s</code> 表示并行进程数。从这个公式我们可以推导出另外一个公式：<code>1/(1-p+p/s)</code></p>
<p>其中，<code>s</code> 还是表示并行进程数，<code>p</code> 表示任务中并行部分的占比。当 <code>p</code> 为 1 时，也就是完全并行时，加速比与并行进程数相等；当 <code>p</code> 为 0 时，即完全串行时，加速比为 1，也就是说完全无加速；当 <code>s</code> 趋近于无穷大的时候，加速比就等于 <code>1/(1-p)</code>，你可以看到它完全和 <code>p</code> 成正比。特别是，当 p 为 1 时，加速比趋近于无穷大。</p>
<blockquote>
<p><strong>随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的 拐点模型</strong>。</p>
</blockquote>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801022321.png"></p>
<p>从图中你可以发现：</p>
<ul>
<li>并发用户数处于轻压力区时，响应时间平稳，吞吐量和并发用户数线性相关。</li>
<li>当并发用户数处于重压力区时，系统资源利用率到达极限，吞吐量开始有下降的趋势，响应时间也会略有上升。</li>
<li>这个时候，再对系统增加压力，系统就进入拐点区，处于超负荷状态，吞吐量下降，响应时间大幅度上升。</li>
</ul>
<p>所以我们在评估系统性能时通常需要做压力测试，目的就是找到系统的「拐点」，从而知道系统的承载能力，也便于找到系统的瓶颈，持续优化系统性能。</p>
<p>说完了提升并行能力，我们再看看优化性能的另一种方式：减少单次任务响应时间。</p>
<h5 id="减少单次任务响应时间"><a class="markdownIt-Anchor" href="#减少单次任务响应时间"></a> 减少单次任务响应时间</h5>
<p>想要减少任务的响应时间，首先要看你的系统是 CPU 密集型 还是 IO 密集型 的，因为不同类型的系统性能优化方式不尽相同。</p>
<p><strong>CPU 密集型系统</strong><br>
CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。比方说，如果系统的主要任务是计算 Hash 值，那么这时选用更高性能的 Hash 算法就可以大大提升系统的性能。发现这类问题的主要方式，是通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块，比如 Linux 的 perf、eBPF 等。</p>
<p><strong>IO 密集型系统</strong><br>
IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。我们熟知的系统大部分都属于 IO 密集型，比如数据库系统、缓存系统、Web 系统。这类系统的性能瓶颈可能出在系统内部，也可能是依赖的其他系统，而发现这类性能瓶颈的手段主要有两类。</p>
<ol>
<li>
<p>采用工具<br>
Linux 的工具集很丰富，完全可以满足你的优化需要，比如网络协议栈、网卡、磁盘、文件系统、内存，等等。这些工具的用法很多，你可以在排查问题的过程中逐渐积累。除此之外呢，一些开发语言还有针对语言特性的分析工具，比如说 Java 语言就有其专属的内存分析工具。</p>
</li>
<li>
<p>通过 监控 来发现性能问题。<br>
在监控中我们可以对任务的每一个步骤做分时的统计，从而找到任务的哪一步消耗了更多的时间。这一部分在演进篇中会有专门的介绍，这里就不再展开了。</p>
</li>
</ol>
<p>那么找到了系统的瓶颈点，我们要如何优化呢？优化方案会随着问题的不同而不同。比方说，如果是数据库访问慢，那么就要看是不是有锁表的情况、是不是有全表扫描、索引加得是否合适、是否有 JOIN 操作、需不需要加缓存，等等；如果是网络的问题，就要看网络的参数是否有优化的空间，抓包来看是否有大量的超时重传，网卡是否有大量丢包等。</p>
<h4 id="高可用"><a class="markdownIt-Anchor" href="#高可用"></a> 高可用</h4>
<p>高可用性（High Availability，HA），它指的是系统具备较高的无故障运行的能力。<br>
可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。</p>
<p><strong>MTBF</strong>(<strong>Mean Time Between Failure</strong>)是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。</p>
<p><strong>MTTR</strong>(<strong>Mean Time To Repair</strong>)表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。</p>
<p>可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：</p>
<blockquote>
<p><code>Availability = MTBF / (MTBF + MTTR)</code></p>
</blockquote>
<p>这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801023138.png"></p>
<p><strong>高可用系统设计的思路</strong></p>
<h5 id="系统设计"><a class="markdownIt-Anchor" href="#系统设计"></a> 系统设计</h5>
<p><strong>Design for failure</strong> 是我们做高可用系统设计时秉持的第一原则。在承担百万 QPS 的高并发系统中，集群中机器的数量成百上千台，单机的故障是常态，几乎每一天都有发生故障的可能。</p>
<p>未雨绸缪才能决胜千里。我们在做系统设计的时候，要把发生故障作为一个重要的考虑点，预先考虑如何自动化地发现故障，发生故障之后要如何解决。当然了，除了要有未雨绸缪的思维之外，我们还需要掌握一些具体的优化方法，比如<strong>failover（故障转移）、超时控制以及降级和限流</strong>。</p>
<p><strong>failover（故障转移）</strong><br>
一般来说，发生 failover 的节点可能有两种情况：</p>
<ol>
<li>是在 完全对等 的节点之间做 failover。</li>
<li>是在 不对等 的节点之间，即系统中存在主节点也存在备节点。</li>
</ol>
<p>在对等节点之间做 failover 相对来说简单些。在这类系统中所有节点都承担读写流量，并且节点中不保存状态，每个节点都可以作为另一个节点的镜像。在这种情况下，如果访问某一个节点失败，那么简单地随机访问另一个节点就好了。<br>
举个例子，Nginx 可以配置当某一个 Tomcat 出现大于 500 的请求的时候，重试请求另一个 Tomcat 节点，就像下面这样：</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801100734.png"></p>
<p>针对不对等节点的 failover 机制会复杂很多。比方说我们有一个主节点，有多台备用节点，这些备用节点可以是热备（同样在线提供服务的备用节点），也可以是冷备（只作为备份使用），那么我们就需要在代码中控制如何检测主备机器是否故障，以及如何做主备切换。</p>
<p>使用最广泛的故障检测机制是「心跳」。你可以在客户端上定期地向主节点发送心跳包，也可以从备份节点上定期发送心跳包。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。</p>
<p>选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比方说 Paxos，Raft。</p>
<p><strong>调用超时控制</strong><br>
除了故障转移以外，对于系统间调用超时的控制也是高可用系统设计的一个重要考虑方面。</p>
<p>复杂的高并发系统通常会有很多的系统模块组成，同时也会依赖很多的组件和服务，比如说缓存组件，队列服务等等。<strong>它们之间的调用最怕的就是延迟而非失败</strong> ，因为失败通常是瞬时的，可以通过重试的方式解决。而一旦调用某一个模块或者服务发生比较大的延迟，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。</p>
<p>在系统开发的初期，超时控制通常不被重视，或者是没有方式来确定正确的超时时间。</p>
<blockquote>
<p>模块之间通过 RPC 框架来调用，超时时间是默认的 30 秒。平时系统运行得非常稳定，可是一旦遇到比较大的流量，RPC 服务端出现一定数量慢请求的时候，RPC 客户端线程就会大量阻塞在这些慢请求上长达 30 秒，造成 RPC 客户端用尽调用线程而挂掉。后面我们在故障复盘的时候发现这个问题后，调整了 RPC，数据库，缓存以及调用第三方服务的超时时间，这样在出现慢请求的时候可以触发超时，就不会造成整体系统雪崩。</p>
</blockquote>
<p>既然要做超时控制，那么我们怎么来确定超时时间呢？这是一个比较困难的问题。</p>
<blockquote>
<p>超时时间短了，会造成大量的超时错误，对用户体验产生影响；超时时间长了，又起不到作用。 我<strong>建议你通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间</strong>。 如果没有调用的日志，那么你只能按照经验值来指定超时时间。不过，无论你使用哪种方式，超时时间都不是一成不变的，需要在后面的系统维护过程中不断地修改。</p>
</blockquote>
<p>超时控制实际上就是不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用。这对于用户来说是有损的，但是却是必要的，因为它牺牲了少量的请求却保证了整体系统的可用性。而我们还有另外两种有损的方案能保证系统的高可用，它们就是降级和限流。</p>
<p><strong>降级</strong><br>
<strong>降级是为了保证核心服务的稳定而牺牲非核心服务的做法</strong>。 比方说我们发一条微博会先经过反垃圾服务检测，检测内容是否是广告，通过后才会完成诸如写数据库等逻辑。</p>
<p>反垃圾的检测是一个相对比较重的操作，因为涉及到非常多的策略匹配，在日常流量下虽然会比较耗时却还能正常响应。但是当并发较高的情况下，它就有可能成为瓶颈，而且它也不是发布微博的主体流程，所以我们可以暂时关闭反垃圾服务检测，这样就可以保证主体的流程更加稳定。</p>
<p><strong>限流</strong><br>
<strong>限流完全是另外一种思路</strong>， 它通过对并发的请求进行限速来保护系统。</p>
<p>比如对于 Web 应用，我限制单机只能处理每秒 1000 次的请求，超过的部分直接返回错误给客户端。虽然这种做法损害了用户的使用体验，但是它是在极端并发下的无奈之举，是短暂的行为，因此是可以接受的。</p>
<p>实际上，无论是降级还是限流，在细节上还有很多可供探讨的地方，我会在后面的课程中，随着系统的不断演进深入地剖析，在基础篇里就不多说了。</p>
<h5 id="系统运维"><a class="markdownIt-Anchor" href="#系统运维"></a> 系统运维</h5>
<p>在系统设计阶段为了保证系统的可用性可以采取上面的几种方法，那在系统运维的层面又能做哪些事情呢？其实，我们可以从 <strong>灰度发布、故障演练</strong> 两个方面来考虑如何提升系统的可用性。</p>
<p>你应该知道，在业务平稳运行过程中，系统是很少发生故障的，90% 的故障是发生在上线变更阶段的。比方说，你上了一个新的功能，由于设计方案的问题，数据库的慢请求数翻了一倍，导致系统请求被拖慢而产生故障。</p>
<p>如果没有变更，数据库怎么会无缘无故地产生那么多的慢请求呢？因此，为了提升系统的可用性，重视变更管理尤为重要。而除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外， 另一个主要的手段就是灰度发布。</p>
<p><strong>灰度发布</strong><br>
灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。一般情况下，灰度发布是以机器维度进行的。比方说，我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。</p>
<p>灰度发布给了开发和运维同学绝佳的机会，让他们能在线上流量上观察变更带来的影响，是保证系统高可用的重要关卡。</p>
<p>灰度发布是在系统正常运行条件下，保证系统高可用的运维手段，那么我们如何知道发生故障时系统的表现呢？这里就要依靠另外一个手段： 故障演练。</p>
<p><strong>故障演练</strong><br>
故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。</p>
<p>一个复杂的高并发系统依赖了太多的组件，比方说磁盘，数据库，网卡等，这些组件随时随地都可能会发生故障，而一旦它们发生故障，会不会如蝴蝶效应一般造成整体服务不可用呢？我们并不知道，因此，故障演练尤为重要。</p>
<p>在我来看， <strong>故障演练和时下比较流行的“混沌工程”的思路如出一辙</strong>， 作为混沌工程的鼻祖，Netfix 在 2010 年推出的 <strong>Chaos Monkey</strong> 工具就是故障演练绝佳的工具。它通过在线上系统上随机地关闭线上节点来模拟故障，让工程师可以了解，在出现此类故障时会有什么样的影响。</p>
<p>当然，这一切是以你的系统可以抵御一些异常情况为前提的。如果你的系统还没有做到这一点，那么 我建议你 另外搭建一套和线上部署结构一模一样的线下系统，然后在这套系统上做故障演练，从而避免对生产系统造成影响。</p>
<p>说了这么多，你可以看到从开发和运维角度上来看，提升可用性的方法是不同的：</p>
<ul>
<li>开发 注重的是如何处理故障，关键词是 冗余和取舍。<br>
冗余指的是有备用节点，集群来顶替出故障的服务，比如文中提到的故障转移，还有多活架构等等；取舍指的是丢卒保车，保障主体服务的安全。<br>
 </li>
<li>从 运维角度 来看则更偏保守，注重的是如何避免故障的发生<br>
比如更关注变更管理以及如何做故障的演练。</li>
</ul>
<p><strong>你还需要注意的是</strong>，提高系统的可用性有时候是以牺牲用户体验或者是牺牲系统性能为前提的，也需要大量人力来建设相应的系统，完善机制。所以我们要把握一个度，不该做过度的优化。就像我在文中提到的，核心系统四个九的可用性已经可以满足需求，就没有必要一味地追求五个九甚至六个九的可用性。</p>
<p>另外，一般的系统或者组件都是追求极致的性能的，那么有没有不追求性能，只追求极致的可用性的呢？答案是有的。比如配置下发的系统，它只需要在其它系统启动时提供一份配置即可，所以秒级返回也可，十秒钟也 OK，无非就是增加了其它系统的启动速度而已。但是，它对可用性的要求是极高的，甚至会到六个九，原因是配置可以获取的慢，但是不能获取不到。我给你举这个例子是想让你了解， 可用性和性能有时候是需要做取舍的，但如何取舍就要视不同的系统而定，不能一概而论了。</p>
<h4 id="易于扩展"><a class="markdownIt-Anchor" href="#易于扩展"></a> 易于扩展</h4>
<p>从架构设计上来说，高可扩展性是一个设计的指标，<strong>它表示可以通过增加机器的方式来线性提高系统的处理能力，从而承担更高的流量和并发</strong>。</p>
<p>你可能会问：在架构设计之初，为什么不预先考虑好使用多少台机器，支持现有的并发呢？<br>
答案 <strong>是峰值的流量不可控</strong>。</p>
<p>一般来说，基于成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高，我们还以微博为例。</p>
<p>鹿晗和关晓彤互圈公布恋情，大家会到两个人的微博下面，或围观，或互动，微博的流量短时间内增长迅速，微博信息流也短暂出现无法刷出新的消息的情况。</p>
<p>那我们要如何应对突发的流量呢？架构的改造已经来不及了，最快的方式就是堆机器。不过我们需要保证，扩容了三倍的机器之后，相应的我们的系统也能支撑三倍的流量。有的人可能会产生疑问：这不是显而易见的吗？很简单啊。真的是这样吗？我们来看看做这件事儿难在哪儿。</p>
<p><strong>为什么提升扩展性会很复杂</strong><br>
在上一讲中，我提到可以在单机系统中通过增加处理核心的方式，来增加系统的并行处理能力，但这个方式并不总生效。因为当并行的任务数较多时，系统会因为争抢资源而达到性能上的拐点，系统处理能力不升反降。</p>
<p>而对于由多台机器组成的集群系统来说也是如此。集群系统中，不同的系统分层上可能存在一些 「瓶颈点」，这些瓶颈点制约着系统的横线扩展能力。这句话比较抽象，我举个例子你就明白了。</p>
<p>比方说，你系统的流量是每秒 1000 次请求，对数据库的请求量也是每秒 1000 次。如果流量增加 10 倍，虽然系统可以通过扩容正常服务，数据库却成了瓶颈。再比方说，单机网络带宽是 50Mbps，那么如果扩容到 30 台机器，前端负载均衡的带宽就超过了千兆带宽的限制，也会成为瓶颈点。那么，我们的系统中存在哪些服务会成为制约系统扩展的重要因素呢？</p>
<p>其实，无状态的服务和组件更易于扩展，而像 MySQL 这种存储服务是有状态的，就比较难以扩展。因为向存储集群中增加或者减少机器时，会涉及大量数据的迁移，而一般传统的关系型数据库都不支持。这就是为什么提升系统扩展性会很复杂的主要原因。</p>
<p>除此之外，从例子中你可以看到，我们需要站在整体架构的角度，而不仅仅是业务服务器的角度来考虑系统的扩展性 。 所以说，<strong>数据库、缓存、依赖的第三方、负载均衡、交换机带宽</strong>等等 都是系统扩展时需要考虑的因素。我们要知道系统并发到了某一个量级之后，哪一个因素会成为我们的瓶颈点，从而针对性地进行扩展。</p>
<p>针对这些复杂的扩展性问题，我提炼了一些系统设计思路，供你了解。</p>
<p><strong>高可扩展性的设计思路</strong><br>
<strong>拆分</strong> 是提升系统扩展性最重要的一个思路，它会把庞杂的系统拆分成独立的，有单一职责的模块。相对于大系统来说，考虑一个一个小模块的扩展性当然会简单一些。将复杂的问题简单化，这就是我们的思路。</p>
<p>但对于不同类型的模块，我们在拆分上遵循的原则是不一样的。我给你举一个简单的例子，假如你要设计一个社区，那么社区会有几个模块呢？可能有 5 个模块。</p>
<ol>
<li>用户：负责维护社区用户信息，注册，登陆等；</li>
<li>关系：用户之间关注、好友、拉黑等关系的维护；</li>
<li>内容：社区发的内容，就像朋友圈或者微博的内容；</li>
<li>评论、赞：用户可能会有的两种常规互动操作；</li>
<li>搜索：用户的搜索，内容的搜索。</li>
</ol>
<p>而部署方式遵照最简单的三层部署架构，负载均衡负责请求的分发，应用服务器负责业务逻辑的处理，数据库负责数据的存储落地。这时，所有模块的业务代码都混合在一起了，数据也都存储在一个库里。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801104931.png"></p>
<h5 id="存储层的扩展性"><a class="markdownIt-Anchor" href="#存储层的扩展性"></a> 存储层的扩展性</h5>
<p>无论是存储的数据量，还是并发访问量，不同的业务模块之间的量级相差很大，比如说成熟社区中，关系的数据量是远远大于用户数据量的，但是用户数据的访问量却远比关系数据要大。所以假如存储目前的瓶颈点是容量，那么我们只需要针对关系模块的数据做拆分就好了，而不需要拆分用户模块的数据。 所以<strong>存储拆分首先考虑的维度是业务维度</strong>。</p>
<p>拆分之后，这个简单的社区系统就有了用户库、内容库、评论库、点赞库和关系库。这么做还能隔离故障，某一个库「挂了」不会影响到其它的数据库。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105052.png"></p>
<p><strong>按照业务拆分，在一定程度上提升了系统的扩展性</strong>，但系统运行时间长了之后，单一的业务数据库在容量和并发请求量上仍然会超过单机的限制。 这时，<strong>我们就需要针对数据库做第二次拆分</strong>。</p>
<p><strong>这次拆分是按照数据特征做水平的拆分</strong> ，比如说我们可以给用户库增加两个节点，然后按照某些算法将用户的数据拆分到这三个库里面，具体的算法我会在后面讲述数据库分库分表时和你细说。</p>
<p>水平拆分之后，我们就可以让数据库突破单机的限制了。但这里要注意，我们不能随意地增加节点，因为一旦增加节点就需要手动地迁移数据，成本还是很高的。所以基于长远的考虑，<strong>我们最好一次性增加足够的节点以避免频繁地扩容</strong>。</p>
<p>当数据库按照业务和数据维度拆分之后，我们 <strong>尽量不要使用事务</strong>。因为当一个事务中同时更新不同的数据库时，需要使用二阶段提交，来协调所有数据库要么全部更新成功，要么全部更新失败。这个协调的成本会随着资源的扩展不断升高，最终达到无法承受的程度。</p>
<p>说完了存储层的扩展性，我们来看看业务层是如何做到易于扩展的。</p>
<h5 id="业务层的扩展性"><a class="markdownIt-Anchor" href="#业务层的扩展性"></a> 业务层的扩展性</h5>
<p>我们一般会从三个维度考虑业务层的拆分方案，它们分别是：<strong>业务纬度 ，重要性纬度 和 请求来源纬度</strong>。</p>
<p>首先，我们需要<strong>把相同业务的服务拆分成单独的业务池</strong>，比方说上面的社区系统中，我们可以按照业务的维度拆分成用户池、内容池、关系池、评论池、点赞池和搜索池。</p>
<p>每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源。这样当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方就可以了，这样就大大减少了扩容的复杂度。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105411.png"></p>
<p>除此之外，我们还可以<strong>根据业务接口的重要程度，把业务分为核心池和非核心池</strong> （池子就是一组机器组成的集群） 。打个比方，就关系池而言，关注、取消关注接口相对重要一些，可以放在核心池里面；拉黑和取消拉黑的操作就相对不那么重要，可以放在非核心池里面。这样，我们可以优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105504.png"></p>
<p>最后，你还可以根据接入客户端类型的不同做业务池的拆分。比如说，服务于客户端接口的业务可以定义为外网池，服务于小程序或者 HTML5 页面的业务可以定义为 H5 池，服务于内部其它部门的业务可以定义为内网池，等等。</p>
<p>了解了提升系统扩展性的复杂度以及系统拆分的思路。拆分看起来比较简单，可是什么时候做拆分，如何做拆分还是有很多细节考虑的。</p>
<p>未做拆分的系统虽然可扩展性不强，但是却足够简单，无论是系统开发还是运行维护都不需要投入很大的精力。拆分之后，需求开发需要横跨多个系统多个小团队，排查问题也需要涉及多个系统，运行维护上，可能每个子系统都需要有专人来负责，对于团队是一个比较大的考验。这个考验是我们必须要经历的一个大坎，需要我们做好准备。</p>
<h3 id="番外memcahed组件实现原理"><a class="markdownIt-Anchor" href="#番外memcahed组件实现原理"></a> 番外：Memcahed组件实现原理</h3>
<p>分享一个真实案例。在之前的一个项目中，我们使用 Memcached 作为缓存组件来提升数据的读取性能。在使用的过程中，我们发现一个存储用户认证信息的缓存的命中率极低，只有 20%。</p>
<p>因为这个认证信息只有极少数的用户会有，大部分的用户在数据库中是没有这个数据的，所以最初我认为是因为查询数据库的时候，没有査询到数据导致没有设置到缓存，所以每次查询缓存的时候就不会命中。</p>
<p>于是，我增加了「<code>从数据库中查询到空数据后也回中缓存</code>」的逻辑，但是上线之后效果并不明显。这时，我查看了一下 Memcached 节点的统计信息，发现单个节点 2G 的内存空间仅仅被使用了 300M，而且缓存 tem 剔除数非常得高，达到了几十亿。</p>
<p>我们知道 Memcached 内部采用的是名为 <code>Slab Allocator</code> 的机制来分配和管理内存的，主要为了解决內存分配碎片的问题。这种机制会预先分配若干组内存区域，每一组称为一个 <code>slab class</code>，每个 <code>slab class</code> 下的各个内存区域大小是相同的，每个内存区域称之为 <code>chunk</code>。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801114354.png"></p>
<p>当存储一个数据时，先要看这个数据大小是多少，要存储在哪一个 <code>slab class</code> 下。如果这个 <code>slab class</code> 没有足够的空间了，那么会查找更大的 <code>slab class</code> 直到找到合适的为止。</p>
<p>于是，我考虑是不是因为缓存用户认证信息时没有找到合适的<code>slab class</code>，才导致数据不断地被剔除出缓存，从而造成缓存命中率低。所以我看了一下 <code>slab</code> 的统计信息，发现 <code>slab class5</code> 占用了 2G 内存中的 1.9G，而用户认证信息会被存放在 <code>slab class6</code> 下，而这个 <code>slab class</code> 的剔除数量非常高。再抓取这个 <code>slab class</code> 下的一小部分数据，发现确实都是用户认证信息数据，此时，我才找到问题的根本原因。</p>
<p>你看，如果不了解 Memcached 的内存分配原理，你可能永远都无法彻底解决这个问题。</p>
<p>所以，在面试的过程中，当你被问到组件的实现原理时，面试官其实想要了解你，是否对于实现原理中涉及的基础知识有足够的了解？在实际开发中，你是否能够运用这些基础知识来设计合理的方案？以及，当这些组件发生问题的时候，你是否有思路解决？</p>
<p>所以，其实你无需对组件达到源代码级别的了解，只需要深入了解它的实现原理，再结合一些基础知识，如算法、网络、操作系统等等，就足够应对 80% 的面试问题。</p>
<h2 id="数据库"><a class="markdownIt-Anchor" href="#数据库"></a> 数据库</h2>
<h3 id="池化技术"><a class="markdownIt-Anchor" href="#池化技术"></a> 池化技术</h3>
<p>如何减少频繁创建数据库连接的性能损耗？</p>
<p>单纯地讲解理论，讲解方案会比较枯燥，所以我将用一个虚拟的系统作为贯穿整个课程的主线，说明当这个系统到达某一个阶段时，我们会遇到什么问题，然后要采用什么样的方案应对，应对的过程中又涉及哪些技术点。通过这样的讲述方式，力求以案例引出问题，能够让你了解遇到不同问题时，解决思路是怎样的。</p>
<p>你公司看到了一个新的商业机会，希望你能带领一名兄弟，迅速研发出一套面向某个垂直领域的电商系统。</p>
<p>在人手紧张，时间不足的情况下，为了能够完成任务，你毫不犹豫地采用了 最简单的架构 ：前端一台 Web 服务器运行业务代码，后端一台数据库服务器存储业务数据。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801115650.png"></p>
<p>这个架构图是我们每个人最熟悉的，最简单的架构原型，很多系统在一开始都是长这样的，只是随着业务复杂度的提高，架构做了叠加，然后看起来就越来越复杂了。</p>
<p>再说回我们的垂直电商系统，系统一开始上线之后，虽然用户量不大，但运行平稳，你很有成就感，不过 CEO 觉得用户量太少了，所以紧急调动运营同学做了一次全网的流量推广。</p>
<p>这一推广很快带来了一大波流量， 但这时，系统的访问速度开始变慢。</p>
<p>分析程序的日志之后，你发现系统慢的原因 出现在和数据库的交互上 。因为你们数据库的调用方式是先获取数据库的连接，然后依靠这条连接从数据库中查询数据，最后关闭连接释放数据库资源。这种调用方式下，每次执行 SQL 都需要重新建立连接，所以你怀疑， <strong>是不是频繁地建立数据库连接耗费时间长导致了访问慢的问题</strong>。</p>
<p><strong>那么为什么频繁创建连接会造成响应时间慢呢？来看一个实际的测试</strong>。<br>
我用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># -i: 指定网卡</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">tcpdump -i bond0 -nn -tttt port 4490</span></pre></td></tr></table></figure>
<p>命令抓取了线上 MySQL 建立连接的网络包来做分析，从抓包结果来看，整个 MySQL 的连接过程可以分为两部分：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801120009.png"></p>
<ul>
<li>
<p>第一部分是前三个数据包<br>
第一个数据包是客户端向服务端发送的一个 SYN 包，<br>
第二个包是服务端回给客户端的 ACK 包以及一个 SYN 包，<br>
第三个包是客户端回给服务端的 ACK 包，熟悉 TCP 协议的同学可以看出这是一个 TCP 的三次握手过程。</p>
</li>
<li>
<p>第二部分是 MySQL 服务端校验客户端密码的过程。<br>
其中第一个包是服务端发给客户端要求认证的报文，<br>
第二和第三个包是客户端将加密后的密码发送给服务端的包，<br>
最后两个包是服务端回给客户端认证 OK 的报文。</p>
</li>
</ul>
<p>从图中，你可以看到整个连接过程大概消耗了 4ms（969012-964904）。</p>
<p>那么单条 SQL 执行时间是多少呢？我们统计了一段时间的 SQL 执行时间，发现 SQL 的平均执行时间大概是 1ms，也就是说相比于 SQL 的执行，MySQL 建立连接的过程是比较耗时的。这在请求量小的时候其实影响不大，因为无论是建立连接还是执行 SQL，耗时都是毫秒级别的。可是请求量上来之后，如果按照原来的方式建立一次连接只执行一条 SQL 的话，1s 只能执行 200 次数据库的查询，而数据库建立连接的时间占了其中 4/5。</p>
<p>一番谷歌搜索之后，你发现解决方案也很简单，只要使用连接池将数据库连接预先建立好，这样在使用的时候就不需要频繁地创建连接了。调整之后，你发现 1s 就可以执行 1000 次的数据库查询，查询性能大大的提升了。</p>
<h4 id="用连接池预先建立数据库连接"><a class="markdownIt-Anchor" href="#用连接池预先建立数据库连接"></a> 用连接池预先建立数据库连接</h4>
<p>在开发过程中我们会用到很多的连接池，像是数据库连接池、HTTP 连接池、Redis 连接池等等。而连接池的管理是连接池设计的核心， 我就以数据库连接池为例，来说明一下连接池管理的关键点。</p>
<p>数据库连接池有两个最重要的配置： <strong>最小连接数和最大连接数</strong>， 它们控制着从连接池中获取连接的流程</p>
<ul>
<li>如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；</li>
<li>如果连接池中有空闲连接则复用空闲连接；</li>
<li>如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；</li>
<li>如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（C3P0 的连接池配置是 checkoutTimeout）+ 等待旧的连接可用；</li>
<li>如果等待超过了这个设定时间则向用户抛出错误。</li>
</ul>
<p>对于数据库连接池，根据我的经验，一般在线上我<strong>建议最小连接数控制在 10 左右</strong>，<strong>最大连接数控制在 20～30 左右即可</strong>。</p>
<p>在这里，你需要注意池子中连接的维护问题:</p>
<ol>
<li>
<p>数据库的域名对应的 IP 发生了变更，池子的连接还是使用旧的 IP，当旧的 IP 下的数据库服务关闭后，再使用这个连接查询就会发生错误；</p>
</li>
<li>
<p>MySQL 有个参数是 wait_timeout，控制着当数据库连接闲置多长时间后，数据库会主动的关闭这条连接。这个机制对于数据库使用方是无感知的，所以当我们使用这个被关闭的连接时就会发生错误。</p>
</li>
</ol>
<p>那么，怎么保证你启动着的数据库一定是可用的呢？</p>
<ol>
<li>
<p>启动一个线程来定期检测连接池中的连接是否可用，比如使用连接发送 <code>select 1</code> 的命令给数据库看是否会抛出异常，如果抛出异常则将这个连接从连接池中移除，并且尝试关闭。目前 C3P0 连接池可以采用这种方式来检测连接是否可用， 也是我比较推荐的方式。</p>
</li>
<li>
<p>在获取到连接之后，先校验连接是否可用，如果可用才会执行 SQL 语句。比如 DBCP 连接池的 testOnBorrow 配置项，就是控制是否开启这个验证。这种方式在获取连接时会引入多余的开销， 在线上系统中还是尽量不要开启，在测试服务上可以使用。</p>
</li>
</ol>
<p>至此，你彻底搞清楚了连接池的工作原理。可是，当你刚想松一口气的时候，CEO 又提出了一个新的需求。你分析了一下这个需求，发现在一个非常重要的接口中，你需要访问 3 次数据库。根据经验判断，你觉得这里未来肯定会成为系统瓶颈。</p>
<p>进一步想，你觉得可以创建多个线程来并行处理与数据库之间的交互，这样速度就能快了。不过，因为有了上次数据库的教训，你想到在高并发阶段，频繁创建线程的开销也会很大，于是顺着之前的思路继续想，猜测到了线程池。</p>
<h4 id="用线程池预先创建线程"><a class="markdownIt-Anchor" href="#用线程池预先创建线程"></a> 用线程池预先创建线程</h4>
<p>JDK 1.5 中引入的 ThreadPoolExecutor 就是一种线程池的实现，它有两个重要的参数：coreThreadCount 和 maxThreadCount，这两个参数控制着线程池的执行过程。</p>
<ul>
<li>如果线程池中的线程数少于 coreThreadCount 时，处理新的任务时会创建新的线程；</li>
<li>如果线程数大于 coreThreadCount 则把任务丢到一个队列里面，由当前空闲的线程执行；</li>
<li>当队列中的任务堆积满了的时候，则继续创建线程，直到达到 maxThreadCount；</li>
<li>当线程数达到 maxTheadCount 时还有新的任务提交，那么我们就不得不将它们丢弃了。</li>
</ul>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801123011.png"></p>
<p>这个任务处理流程看似简单，实际上有很多坑，你在使用的时候一定要注意。</p>
<p>首先， JDK 实现的这个线程池优 先把任务放入队列暂存起来，而不是创建更多的线程 ，它比较适用于执行 CPU 密集型的任务，也就是需要执行大量 CPU 运算的任务。这是为什么呢？因为执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了，多了反而会造成线程上下文切换，降低任务执行效率。所以当当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。</p>
<p>但是，我们平时开发的 Web 系统通常都有大量的 IO 操作，比方说查询数据库、查询缓存等等。任务在执行 IO 操作的时候 CPU 就空闲了下来，这时如果增加执行任务的线程数而不是把任务暂存在队列中，就可以在单位时间内执行更多的任务，大大提高了任务执行的吞吐量。所以你看 Tomcat 使用的线程池就不是 JDK 原生的线程池，而是做了一些改造，当线程数超过 coreThreadCount 之后会优先创建线程，直到线程数到达 maxThreadCount，这样就比较适合于 Web 系统大量 IO 操作的场景了，你在实际运用过程中也可以参考借鉴。</p>
<p>其次，<strong>线程池中使用的队列的堆积量也是我们需要监控的重要指标</strong> ，对于实时性要求比较高的任务来说，这个指标尤为关键。</p>
<p>我在实际项目中就曾经遇到过任务被丢给线程池之后，长时间都没有被执行的诡异问题。 最初，我认为这是代码的 Bug 导致的，后来经过排查发现，是因为线程池的 coreThreadCount 和 maxThreadCount 设置的比较小，导致任务在线程池里面大量的堆积，在调大了这两个参数之后问题就解决了。跳出这个坑之后，我就把重要线程池的队列任务堆积量 ，作为一个重要的监控指标放到了系统监控大屏上。</p>
<p>最后， 如果你使用线程池请一定记住 <strong>不要使用无界队列</strong>（<strong>即没有设置固定大小的队列</strong>） 。也许你会觉得使用了无界队列后，任务就永远不会被丢弃，只要任务对实时性要求不高，反正早晚有消费完的一天。但是，大量的任务堆积会占用大量的内存空间，一旦内存空间被占满就会频繁地触发 Full GC，造成服务不可用，我之前排查过的一次 GC 引起的宕机，起因就是系统中的一个线程池使用了无界队列。</p>
<p>回顾一下这两种技术，会发现它们都有一个 共同点：</p>
<blockquote>
<p>它们所管理的对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源 。<br>
所以，我们把它们放在一个池子里统一管理起来，以达到提升性能和资源复用的目的 。</p>
</blockquote>
<p>这是一种常见的软件设计思想，叫做<strong>池化技术</strong>， 它的<strong>核心思想是空间换时间</strong>，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本，总之是好处多多。</p>
<p>池化技术也存在一些缺陷，比方说存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费。再比方说，池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。</p>
<p>可这些缺陷相比池化技术的优势来说就比较微不足道了，只要我们确认要使用的对象在创建时确实比较耗时或者消耗资源，并且这些对象也确实会被频繁地创建和销毁，我们就可以使用池化技术来优化。</p>
<p>在遇到数据库查询性能下降的问题时，我们使用数据库连接池解决了频繁创建连接带来的性能问题，后面又使用线程池提升了并行查询数据库的性能。</p>
<h4 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h4>
<p>其实，连接池和线程池你并不陌生，不过你可能对它们的原理和使用方式上还存在困惑或者误区，我在面试时，就发现有很多的同学对线程池的基本使用方式都不了解。借用这节课，我想再次强调的重点是：</p>
<ol>
<li>池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。</li>
<li>池子中的对象需要在使用之前预先初始化完成，这叫做 <strong>池子的预热</strong> ，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。</li>
<li>池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。</li>
</ol>
<h3 id="数据库优化方案"><a class="markdownIt-Anchor" href="#数据库优化方案"></a> 数据库优化方案</h3>
<h4 id="主从分离"><a class="markdownIt-Anchor" href="#主从分离"></a> 主从分离</h4>
<p>我们用池化技术解决了数据库连接复用的问题，这时，你的垂直电商系统虽然整体架构上没有变化，但是和数据库交互的过程有了变化，在你的 Web 工程和数据库之间增加了数据库连接池，减少了频繁创建连接的成本，从上节课的测试来看性能上可以提升 80%。现在的架构图如下所示：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801132328.png"></p>
<p>你的数据库还是单机部署，依据一些云厂商的 Benchmark 的结果，在 4 核 8G 的机器上运 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS。这时，运营负责人说正在准备双十一活动，并且公司层面会继续投入资金在全渠道进行推广，这无疑会引发查询量骤然增加的问题。那么今天，我们就一起来看看当查询请求增加时，应该如何做主从分离来解决问题。</p>
<p><strong>主从读写分离</strong><br>
其实，大部分系统的访问模型是 读多写少，读写请求量的差距可能达到几个数量级。</p>
<p>这很好理解，刷朋友圈的请求量肯定比发朋友圈的量大，淘宝上一个商品的浏览量也肯定远大于它的下单量。因此，我们优先考虑数据库如何抗住更高的查询请求，那么首先你需要把读写流量区分开，因为这样才方便针对读流量做单独的扩展，这就是我们所说的主从读写分离。</p>
<p>它其实是个流量分离的问题，就好比道路交通管制一样，一个四车道的大马路划出三个车道给领导外宾通过，另外一个车道给我们使用，优先保证领导先行，就是这个道理。</p>
<p>这个方法本身是一种常规的做法，即使在一个大的项目中，它也是一个应对数据库突发读流量的有效方法。</p>
<p>我目前的项目中就曾出现过前端流量突增导致从库负载过高的问题，DBA 兄弟会优先做一个从库扩容上去，这样对数据库的读流量就会落入到多个从库上，从库的负载就降了下来，然后研发同学再考虑使用什么样的方案将流量挡在数据库层之上。</p>
<p><strong>主从读写的两个技术关键点</strong><br>
一般来说在主从读写分离机制中，我们将一个数据库的数据拷贝为一份或者多份，并且写入到其它的数据库服务器中，原始的数据库我们称为 主库，主要负责数据的写入，拷贝的目标数据库称为 从库，主要负责支持数据查询。可以看到，主从读写分离有两个技术上的关键点：</p>
<ol>
<li>数据的拷贝，我们称为主从复制；</li>
<li>在主从分离的情况下，我们<strong>如何屏蔽主从分离带来的访问数据库方式的变化</strong>，让开发同学像是在使用单一数据库一样。</li>
</ol>
<h5 id="主从复制"><a class="markdownIt-Anchor" href="#主从复制"></a> 主从复制</h5>
<p>MySQL 的主从复制是依赖于 binlog 的，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件。<strong>主从复制就是将 binlog 中的数据从主库传输到从库上</strong> ，一般这个过程是异步的，即主库上的操作不会等待 binlog 同步的完成。</p>
<p><strong>主从复制的过程</strong></p>
<ol>
<li>首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中</li>
<li>主库也会创建一个 log dump 线程来发送 binlog 给从库；</li>
<li>同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。</li>
</ol>
<p>这是一种比较常见的主从复制方式。</p>
<p>在这个方案中，使用独立的 log dump 线程是一种异步的方式，可以避免对主库的主体更新流程产生影响，而从库在接收到信息后并不是写入从库的存储中，是写入一个 relay log，是避免写入从库实际存储会比较耗时，最终造成从库和主库延迟变长。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801132935.png"></p>
<p>你会发现，基于性能的考虑，主库的写入流程并没有等待主从同步完成就会返回结果，那么在极端的情况下，比如说主库上 binlog 还没有来得及刷新到磁盘上就出现了磁盘损坏或者机器掉电，就会导致 binlog 的丢失，最终造成主从数据的不一致。 不过，<strong>这种情况出现的概率很低，对于互联网的项目来说是可以容忍的</strong>。</p>
<p>做了主从复制之后，我们就可以在写入时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响到读请求的执行。同时呢，在读流量比较大的情况下，我们可以部署多个从库共同承担读流量，这就是所说的 <strong>一主多从</strong> 部署方式，在你的垂直电商项目中就可以通过这种方式来抵御较高的并发读流量。另外，从库也可以当成一个备库来使用，以避免主库故障导致数据丢失。</p>
<p>那么你可能会说，是不是我<strong>无限制地增加从库的数量就可以抵抗大量的并发呢</strong>？ 实际上并不是的。因为随着从库数量增加，从库连接上来的 IO 线程比较多，主库也需要创建同样多的 log dump 线程来处理复制的请求，对于主库资源消耗比较高，同时受限于主库的网络带宽，所以在实际使用中，<strong>一般一个主库最多挂 3～5 个从库</strong>。</p>
<p>当然，主从复制也有一些缺陷， 除了带来了部署上的复杂度，还有就是会带来一定的主从同步的延迟，这种延迟有时候会对业务产生一定的影响，我举个例子你就明白了。</p>
<p>在发微博的过程中会有些同步的操作，像是更新数据库的操作，也有一些异步的操作，比如说将微博的信息同步给审核系统，所以我们在更新完主库之后，会将微博的 ID 写入消息队列，再由队列处理机依据 ID 在从库中获取微博信息再发送给审核系统。 此时如果主从数据库存在延迟，会导致在从库中获取不到微博信息，整个流程会出现异常。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801133231.png"></p>
<p>这个问题解决的思路有很多，核心思想就是<strong>尽量不去从库中查询信息</strong> ，纯粹以上面的例子来说，我就有三种解决方案：</p>
<ul>
<li>
<p>第一种方案是数据的冗余。<br>
你可以在发送消息队列时不仅仅发送微博 ID，而是发送队列处理机需要的所有微博信息，借此避免从数据库中重新查询数据。<br>
 </p>
</li>
<li>
<p>第二种方案是使用缓存。<br>
我可以在同步写数据库的同时，也把微博的数据写入到 Memcached 缓存里面，这样队列处理机在获取微博信息的时候会优先查询缓存，这样也可以保证数据的一致性。<br>
 </p>
</li>
<li>
<p>最后一种方案是查询主库。<br>
我可以在队列处理机中不查询从库而改为查询主库。不过，这种方式使用起来要慎重，要明确查询的量级不会很大，是在主库的可承受范围之内，否则会对主库造成比较大的压力。<br>
 </p>
</li>
</ul>
<p>我会优先考虑第一种方案，因为这种方式足够简单， <strong>不过可能造成单条消息比较大，从而增加了消息发送的带宽和时间</strong> 。</p>
<p>缓存的方案比较 <strong>适合新增数据的场景</strong>，在更新数据的场景下， 先更新缓存可能会造成数据的不一致 ，比方说两个线程同时更新数据：</p>
<ol>
<li>线程 A 把缓存中的数据更新为 1</li>
<li>此时另一个线程 B 把缓存中的数据更新为 2，然后线程 B 又更新数据库中的数据为 2，</li>
<li>此时线程 A 更新数据库中的数据为 1，这样数据库中的值（1）和缓存中的值（2）就不一致了。</li>
</ol>
<p>最后，若<strong>非万不得已的情况下，我不会使用第三种方案</strong>。原因是这种方案要提供一个查询主库的接口，在团队开发的过程中，你很难保证其他同学不会滥用这个方法，而一旦主库承担了大量的读请求导致崩溃，那么对于整体系统的影响是极大的。</p>
<p>所以对这三种方案来说，你要有所取舍，根据实际项目情况做好选择。</p>
<p>另外，<strong>主从同步的延迟</strong>，是我们排查问题时很容易忽略的一个问题。 有时候我们遇到从数据库中获取不到信息的诡异问题时，会纠结于代码中是否有一些逻辑会把之前写入的内容删除，但是你又会发现，过了一段时间再去查询时又可以读到数据了，这基本上就是主从延迟在作怪。</p>
<blockquote>
<p>所以，一般我们会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。</p>
</blockquote>
<h5 id="如何访问数据库"><a class="markdownIt-Anchor" href="#如何访问数据库"></a> 如何访问数据库</h5>
<p>我们已经使用主从复制的技术将数据复制到了多个节点，也实现了数据库读写的分离，这时，对于数据库的使用方式发生了变化。以前只需要使用一个数据库地址就好了，现在需要使用一个主库地址和多个从库地址，并且需要区分写入操作和查询操作，如果结合下一节课中要讲解的内容 分库分表，复杂度会提升更多。 为了降低实现的复杂度，业界涌现了很多数据库中间件来解决数据库的访问问题，这些中间件可以分为两类。</p>
<ol>
<li>
<p>第一类以淘宝的 TDDL（ Taobao Distributed Data Layer）为代表，以代码形式内嵌运行在应用程序内部。<br>
你可以把它看成是一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。</p>
<p>这一类中间件的优点是简单易用，没有多余的部署成本，因为它是植入到应用程序内部，与应用程序一同运行的，所以比较适合运维能力较弱的小团队使用；缺点是缺乏多语言的支持，目前业界这一类的主流方案除了 TDDL，还有早期的网易 DDB，它们都是 Java 语言开发的，无法支持其他的语言。另外，版本升级也依赖使用方更新，比较困难。<br>
 </p>
</li>
<li>
<p>另一类是单独部署的代理层方案<br>
这一类方案代表比较多，如早期阿里巴巴开源的 Cobar，基于 Cobar 开发出来的 Mycat，360 开源的 Atlas，美团开源的基于 Atlas 开发的 DBProxy 等等。</p>
</li>
</ol>
<p>第2类中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。</p>
<p>它一般使用标准的 MySQL 通信协议，所以可以很好地支持多语言。由于它是独立部署的，所以也比较方便进行维护升级，比较适合有一定运维能力的大中型团队使用。它的缺陷是所有的 SQL 语句都需要跨两次网络：从应用到代理层和从代理层到数据源，所以在性能上会有一些损耗。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801134036.png"><br>
这些中间件，对你而言，可能并不陌生，但是我想让你注意到是， <strong>在使用任何中间件的时候一定要保证对于中间件有足够深入的了解</strong>，否则一旦出了问题没法快速地解决就悲剧了。</p>
<h5 id="小结-2"><a class="markdownIt-Anchor" href="#小结-2"></a> 小结</h5>
<p>了解了查询量增加时，我们如何通过<strong>主从分离</strong>和<strong>一主多从</strong>部署抵抗增加的数据库流量的，你除了掌握主从复制的技术之外，还需要 <strong>了解主从分离会带来什么问题以及它们的解决办法</strong> 。</p>
<ol>
<li>主从读写分离以及部署一主多从可以解决突发的数据库读流量，是一种数据库 <code>横向扩展</code> 的方法；</li>
<li>读写分离后，<strong>主从的延迟是一个关键的监控指标</strong>，可能会造成写入数据之后立刻读的时候读取不到的情况；</li>
<li>业界有很多的方案可以屏蔽主从分离之后数据库访问的细节，让开发人员像是访问单一数据库一样，包括有像 TDDL、Sharding-JDBC 这样的嵌入应用内部的方案，也有像 Mycat 这样的独立部署的代理方案。</li>
</ol>
<p>其实，<strong>我们可以把主从复制引申为存储节点之间互相复制存储数据的技术</strong> ，它可以实现数据的冗余，以达到备份和提升横向扩展能力的作用。在使用主从复制这个技术点时，你一般会考虑两个问题：</p>
<ol>
<li>主从的一致性和写入性能的权衡<br>
如果你要保证所有从节点都写入成功，那么写入性能一定会受影响；<br>
如果你只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致， 而在互联网的项目中，我们一般会<strong>优先考虑性能而不是数据的强一致性</strong>。<br>
 </li>
<li>主从的延迟问题<br>
很多诡异的读取不到数据的问题都可能会和它有关，如果你遇到这类问题不妨先看看主从延迟的数据。</li>
</ol>
<p>我们采用的很多组件都会使用到这个技术，比如</p>
<ol>
<li>Redis 也是通过主从复制实现读写分离；</li>
<li>Elasticsearch 中存储的索引分片也可以被复制到多个节点中；</li>
<li>写入到 HDFS 中文件也会被复制到多个 DataNode 中。</li>
</ol>
<p>只是不同的组件对于复制的一致性、延迟要求不同，采用的方案也不同。 但是这种设计的思想是通用的，是你需要了解的，这样你在学习其他存储组件的时候就能够触类旁通了。</p>
<h4 id="分库分表"><a class="markdownIt-Anchor" href="#分库分表"></a> 分库分表</h4>
<p>我们学习了在高并发下数据库的一种优化方案：读写分离，它就是依靠主从复制的技术使得数据库实现了数据复制为多份，增强了抵抗 大量并发读请求的能力，提升了数据库的查询性能的同时，也提升了数据的安全性，当某一个数据库节点，无论是主库还是从库发生故障时，我们还有其他的节点中存储着全量的数据，保证数据不会丢失。此时，你的电商系统的架构图变成了下面这样：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801135310.png"></p>
<p>运营推广持续带来了流量，你所设计的电商系统的订单量突破了五千万，订单数据都是单表存储的，你的压力倍增，因为无论是数据库的查询还是写入性能都在下降，数据库的磁盘空间也在报警。所以，你主动分析现阶段自己需要考虑的问题，并寻求高效的解决方式，以便系统能正常运转下去。你考虑的问题主要有以下几点：</p>
<ol>
<li>系统正在持续不断地的发展<br>
注册的用户越来越多，产生的订单越来越多，数据库中存储的数据也越来越多，单个表的数据量超过了千万甚至到了亿级别。这时即使你使用了索引，索引占用的空间也随着数据量的增长而增大，数据库就无法缓存全量的索引信息，那么就需要从磁盘上读取索引数据，就会影响到查询的性能了。 那么这时你要如何提升查询性能呢？<br>
 </li>
<li>数据量的增加也占据了磁盘的空间，数据库在备份和恢复的时间变长， 你如何让数据库系统支持如此大的数据量呢？<br>
 </li>
<li>不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响， 那么如何做到不同模块的故障隔离呢？<br>
 </li>
<li>你已经知道了，在 4 核 8G 的云服务器上对 MySQL5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS，你可以看到数据库对于写入性能要弱于数据查询的能力，那么随着系统写入请求量的增长， 数据库系统如何来处理更高的并发写入请求呢？</li>
</ol>
<p>这些问题你可以归纳成，<strong>数据库的写入请求量大造成的性能和可用性方面的问题</strong> ，要解决这些问题，你所采取的措施就是 对数据进行分片 ，对数据进行分片，可以很好地分摊数据库的读写压力，也可以突破单机的存储瓶颈，而常见的一种方式是对数据库做 <strong>分库分表</strong> 。</p>
<p>分库分表是一个很常见的技术方案，但以我过往的经验来看，不少人会在分库分表这里踩坑，主要体现在：</p>
<ol>
<li>
<p>对如何使用正确的分库分表方式一知半解，没有明白使用场景和方法。<br>
比如，一些同学会在查询时不使用分区键；</p>
</li>
<li>
<p>分库分表引入了一些问题后，没有找到合适的解决方案。比如，会在查询时使用大量连表查询等等。</p>
</li>
</ol>
<h5 id="如何对数据库做垂直拆分"><a class="markdownIt-Anchor" href="#如何对数据库做垂直拆分"></a> 如何对数据库做垂直拆分</h5>
<p>分库分表是一种常见的将数据分片的方式，它的基本思想是依照某一种策略将数据尽量平均的分配到多个数据库节点或者多个表中。</p>
<p>不同于主从复制时数据是全量地被拷贝到多个节点，分库分表后，每个节点只保存部分的数据，这样可以有效地减少单个数据库节点和单个数据表中存储的数据量，在<strong>解决了数据存储瓶颈的同时也能有效的提升数据查询的性能</strong> 。同时，因为数据被分配到多个数据库节点上，那么数据的写入请求也从请求单一主库变成了请求多个数据分片节点，在一定程度上也会提升并发写入的性能。</p>
<p>数据库分库分表的方式有两种：一种是<strong>垂直拆分</strong>，另一种是<strong>水平拆分</strong>。这两种方式，在我看来，掌握拆分方式是关键，理解拆分原理是内核。所以你在学习时，最好可以结合自身业务来思考。</p>
<p>垂直拆分，顾名思义就是对数据库竖着拆分，也就是将数据库的 <strong>表拆分到多个不同的数据库中</strong>。</p>
<blockquote>
<p>垂直拆分的原则一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中<br>
<strong>把不同的业务的数据分拆到不同的数据库节点上，这样一旦数据库发生故障时只会影响到某一个模块的功能，不会影响到整体功能，从而实现了数据层面的故障隔离</strong>。</p>
</blockquote>
<p>我还是以微博系统为例来给你说明一下。</p>
<p>在微博系统中有和用户相关的表，有和内容相关的表，有和关系相关的表，这些表都存储在主库中。在拆分后，我们期望用户相关的表分拆到用户库中，内容相关的表分拆到内容库中，关系相关的表分拆到关系库中。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801144513.png"></p>
<p>对数据库进行垂直拆分是一种偏常规的方式，这种方式其实你会比较常用，不过拆分之后，虽然可以暂时缓解存储容量的瓶颈，但并不是万事大吉，因为数据库垂直拆分后依然不能解决某一个业务模块的数据大量膨胀的问题，一旦你的系统遭遇某一个业务库的数据量暴增，在这个情况下，你还需要继续寻找可以弥补的方式。</p>
<p>比如微博关系量早已经过了千亿，单一的数据库或者数据表已经远远不能满足存储和查询的需求了， <strong>这个时候，你需要将数据拆分到多个数据库和数据表中，也就是对数据库和数据表做水平拆分了</strong> 。</p>
<h5 id="如何对数据库做水平拆分"><a class="markdownIt-Anchor" href="#如何对数据库做水平拆分"></a> 如何对数据库做水平拆分</h5>
<p>和垂直拆分的关注点不同：</p>
<ul>
<li>垂直拆分的关注点在于 <strong>业务相关性</strong>，</li>
<li>水平拆分指的是将<strong>单一数据表按照某一种规则拆分到多个数据库和多个数据表中</strong>，关注点在<strong>数据的特点</strong>。</li>
</ul>
<p>拆分的规则有下面这两种：</p>
<ol>
<li>
<p>按照某一个字段的 <code>哈希值</code> 做拆分<br>
这种拆分规则比较适用于实体表，比如说用户表，内容表，我们一般按照这些实体表的 ID 字段来拆分。比如说我们想把用户表拆分成 16 个库，64 张表，那么可以先对用户 ID 做哈希，哈希的目的是将 ID 尽量打散，然后再对 16 取余，这样就得到了分库后的索引值；对 64 取余，就得到了分表后的索引值。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801144922.png"></p>
</li>
<li>
<p>另一种比较常用的是按照某一个字段的 区间 来拆分，比较常用的是时间字段。<br>
你知道在内容表里面有「创建时间」的字段，而我们也是按照时间来查看一个人发布的内容。我们可能会要看昨天的内容，也可能会看一个月前发布的内容，这时就可以按照创建时间的区间来分库分表，比如说可以把一个月的数据放入一张表中，这样在查询时就可以根据创建时间先定位数据存储在哪个表里面，再按照查询条件来查询。</p>
<p>一般来说，列表数据可以使用这种拆分方式，比如一个人一段时间的订单，一段时间发布的内容。但是这种方式可能会存在明显的热点，这很好理解嘛，你当然会更关注最近我买了什么，发了什么，所以查询的 QPS 也会更多一些，对性能有一定的影响。另外，使用这种拆分规则后，数据表要提前建立好，否则如果时间到了 2020 年元旦，DBA（Database Administrator，数据库管理员）却忘记了建表，那么 2020 年的数据就没有库表可写了，就会发生故障了。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801145039.png"></p>
</li>
</ol>
<p>数据库在分库分表之后，数据的访问方式也有了极大的改变，<strong>原先只需要根据查询条件到从库中查询数据即可，现在则需要先确认数据在哪一个库表中，再到那个库表中查询数据</strong> 。这种复杂度也可以通过数据库中间件来解决。</p>
<h5 id="解决分库分表引入的问题"><a class="markdownIt-Anchor" href="#解决分库分表引入的问题"></a> 解决分库分表引入的问题</h5>
<p>分库分表引入的一个最大的问题就是 <code>引入了分库分表键</code>，也叫做<code>分区键</code>， 也就是我们对数据库做分库分表所依据的字段。</p>
<p>从分库分表规则中你可以看到，无论是哈希拆分还是区间段的拆分，我们首先都需要选取一个数据库字段，这带来一个问题是：我们之后所有的查询都需要带上这个字段，才能找到数据所在的库和表，否则就只能向所有的数据库和数据表发送查询命令。如果像上面说的要拆分成 16 个库和 64 张表，那么一次数据的查询会变成 16*64=1024 次查询，查询的性能肯定是极差的。</p>
<p>当然，<strong>方法总比问题多</strong>， 针对这个问题，我们也会有一些相应的解决思路。比如，在用户库中我们使用 ID 作为分区键，这时如果需要按照昵称来查询用户时，你可以按照昵称作为分区键再做一次拆分，但是这样会极大的增加存储成本，如果以后我们还需要按照注册时间来查询时要怎么办呢，再做一次拆分吗？</p>
<p>所以<strong>最合适的思路是你要建立一个昵称和 ID 的映射表</strong>，在查询的时候要先通过昵称查询到 ID，再通过 ID 查询完整的数据，这个表也可以是分库分表的，也需要占用一定的存储空间，但是因为表中只有两个字段，所以相比重新做一次拆分还是会节省不少的空间的。</p>
<p><strong>分库分表引入的另外一个问题是一些数据库的特性在实现时可能变得很困难</strong>。 比如说多表的 join 在单库时是可以通过一个 SQL 语句完成的，但是拆分到多个数据库之后就无法跨库执行 SQL 了，不过好在我们对于 join 的需求不高，即使有也一般是把两个表的数据取出后在业务代码里面做筛选，复杂是有一些，不过是可以实现的。再比如说在未分库分表之前查询数据总数时只需要在 SQL 中执行 count() 即可，现在数据被分散到多个库表中，我们可能要考虑其他的方案，比方说将计数的数据单独存储在一张表中或者记录在 Redis 里面。</p>
<p>当然，虽然分库分表会对我们使用数据库带来一些不便，但是相比它所带来的扩展性和性能方面的提升，我们还是需要做的，因为，经历过分库分表后的系统，才能够突破单机的容量和请求量的瓶颈 ，就比如说，我在开篇提到的我们的电商系统，它正是经历了分库分表，才会解决订单表数据量过大带来的性能衰减和容量瓶颈。</p>
<h5 id="小结-3"><a class="markdownIt-Anchor" href="#小结-3"></a> 小结</h5>
<p>总的来说，在面对数据库容量瓶颈和写并发量大的问题时，你可以采用垂直拆分和水平拆分来解决，不过你要注意，这两种方式虽然能够解决问题，但是也会引入诸如查询数据必须带上分区键，列表总数需要单独冗余存储等问题。</p>
<p>而且，你需要了解的是在实现分库分表过程中，数据从单库单表迁移多库多表是一件即繁杂又容易出错的事情，而且如果我们初期没有规划得当，后面要继续增加数据库数或者表数时，我们还要经历这个迁移的过程。所以，从我的经验出发，对于分库分表的原则主要有以下几点：</p>
<ol>
<li>如果在性能上没有瓶颈点那么就尽量不做分库分表；<br>
 </li>
<li>如果要做，就尽量一次到位，比如说 16 库 64 表就基本能够满足为了几年内你的业务的需求。<br>
 </li>
<li>很多的 NoSQL 数据库，例如 Hbase，MongoDB 都提供 auto sharding 的特性，如果你的团队内部对于这些组件比较熟悉，有较强的运维能力，那么也可以考虑使用这些 NoSQL 数据库替代传统的关系型数据库。</li>
</ol>
<p>其实，在我看来，有很多人并没有真正从根本上搞懂为什么要拆分，拆分后会带来哪些问题，只是一味地学习大厂现有的拆分方法，从而导致问题频出。<strong>所以，你在使用一个方案解决一个问题的时候一定要弄清楚原理，搞清楚这个方案会带来什么问题，要如何来解决，要知其然也知其所以然，这样才能在解决问题的同时避免踩坑</strong>。</p>
<h3 id="发号器"><a class="markdownIt-Anchor" href="#发号器"></a> 发号器</h3>
<p>如何保证分库分表后 ID 的全局唯一性？</p>
<p>前面已经了解了分布式存储两个核心问题：数据冗余和数据分片，以及在传统关系型数据库中是如何解决的。</p>
<p>当我们面临高并发的查询数据请求时，可以使用主从读写分离的方式，部署多个从库分摊读压力；</p>
<p>当存储的数据量达到瓶颈时，我们可以将数据分片存储在多个节点上，降低单个存储节点的存储压力，此时我们的架构变成了下面这个样子：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801150736.png"></p>
<p>你可以看到，我们通过分库分表和主从读写分离的方式解决了数据库的扩展性问题，但是数据库在分库分表之后，我们在使用数据库时存在的许多限制，比方说查询的时候必须带着分区键；一些聚合类的查询（像是 count()）性能较差，需要考虑使用计数器等其它的解决方案，其实分库分表还有一个问题，就是 <strong>主键的全局唯一性的问题</strong> 。本节课，我将带你一起来了解，在分库分表后如何生成全局唯一的数据库主键。</p>
<p>不过，在探究这个问题之前，你需要对「使用什么字段作为主键」这个问题有所了解，这样才能为我们后续探究如何生成全局唯一的主键做好铺垫。</p>
<h4 id="数据库的主键要如何选择"><a class="markdownIt-Anchor" href="#数据库的主键要如何选择"></a> 数据库的主键要如何选择</h4>
<p>数据库中的每一条记录都需要有一个唯一的标识，依据数据库的第二范式，数据库中每一个表中都需要有一个唯一的主键，其他数据元素和主键一一对应。</p>
<p>那么关于主键的选择就成为一个关键点了， 一般来讲，你有两种选择方式：</p>
<ol>
<li>使用业务字段作为主键，比如说对于用户表来说，可以使用手机号，email 或者身份证号作为主键。</li>
<li>使用生成的唯一 ID 作为主键。</li>
</ol>
<p>我更倾向于<strong>使用生成的 ID 作为数据库的主键</strong>。 不单单是因为它的唯一性，更是因为一旦生成就不会变更，可以随意引用。</p>
<p>在单库单表的场景下，我们可以使用数据库的自增字段作为 ID，因为这样最简单，对于开发人员来说也是透明的。但是当数据库分库分表后，使用自增字段就无法保证 ID 的全局唯一性了。</p>
<p>想象一下，当我们分库分表之后，同一个逻辑表的数据被分布到多个库中，这时如果使用数据库自增字段作为主键，那么只能保证在这个库中是唯一的，无法保证全局的唯一性。那么假如你来设计用户系统的时候，使用自增 ID 作为用户 ID，就可能出现两个用户有两个相同的 ID，这是不可接受的，那么你要怎么做呢？我建议你搭建发号器服务来生成全局唯一的 ID。</p>
<h4 id="基于-snowflake-算法搭建发号器"><a class="markdownIt-Anchor" href="#基于-snowflake-算法搭建发号器"></a> 基于 Snowflake 算法搭建发号器</h4>
<p>从我历年所经历的项目中，我主要使用的是 变种的 Snowflake 算法来生成业务需要的 ID 的 ，本讲的重点，也是运用它去解决 ID 全局唯一性的问题。搞懂这个算法，知道它是怎么实现的，就足够你应用它来设计一套分布式发号器了，不过你可能会说了：「那你提全局唯一性，怎么不提 UUID 呢？」</p>
<p>没错，UUID（Universally Unique Identifier，通用唯一标识码）不依赖于任何第三方系统，所以在性能和可用性上都比较好，我一般会使用它<strong>生成 Request ID 来标记单次请求</strong>， 但是如果用它来作为数据库主键，它会存在以下几点问题。</p>
<p>首先，生成的 ID 做好具有单调递增性，也就是有序的，而 UUID 不具备这个特点。为什么 ID 要是有序的呢？ 因为在系统设计时，<strong>ID 有可能成为排序的字段</strong>。 我给你举个例子。</p>
<p>比如，你要实现一套评论的系统时，你一般会设计两个表，一张评论表，存储评论的详细信息，其中有 ID 字段，有评论的内容，还有评论人 ID，被评论内容的 ID 等等，以 ID 字段作为分区键；另一个是评论列表，存储着内容 ID 和评论 ID 的对应关系，以内容 ID 为分区键。</p>
<p>我们在获取内容的评论列表时，需要按照时间序倒序排列，因为 ID 是时间上有序的，所以我们就可以按照评论 ID 的倒序排列。而如果评论 ID 不是在时间上有序的话，我们就需要在评论列表中再存储一个多余的创建时间的列用作排序，假设内容 ID、评论 ID 和时间都是使用 8 字节存储，我们就要多出 50% 的存储空间存储时间字段，造成了存储空间上的浪费。</p>
<p>另一个原因在于 <strong>ID 有序也会提升数据的写入性能</strong>。</p>
<p>我们知道 MySQL InnoDB 存储引擎使用  <code>B+</code> 树 存储索引数据，而主键也是一种索引。索引数据在  <code>B+</code> 树 中是有序排列的，就像下面这张图一样，图中 2，10，26 都是记录的 ID，也是索引数据。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801152942.png"><br>
这时，当插入的下一条记录的 ID 是递增的时候，比如插入 30 时，数据库只需要把它追加到后面就好了。但是如果插入的数据是无序的，比如 ID 是 13，那么数据库就要查找 13 应该插入的位置，再挪动 13 后面的数据，这就造成了多余的数据移动的开销。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801153004.png"></p>
<p>我们知道机械磁盘在完成随机的写时，需要先做 「寻道」找到要写入的位置，也就是让磁头找到对应的磁道，这个过程是非常耗时的。而<strong>顺序写就不需要寻道，会大大提升索引的写入性能</strong> 。</p>
<p>UUID 不能作为 ID 的另一个原因是它不具备业务含义， 其实现实世界中使用的 ID 中都包含有一些有意义的数据，这些数据会出现在 ID 的固定的位置上。比如说我们使用的身份证的前六位是地区编号；7～14 位是身份证持有人的生日；不同城市电话号码的区号是不同的；你从手机号码的的前三位就可以看出这个手机号隶属于哪一个运营商。而如果生成的 ID 可以被反解，那么从反解出来的信息中我们可以对 ID 来做验证，我们可以从中知道这个 ID 的生成时间，从哪个机房的发号器中生成的，为哪个业务服务的，对于问题的排查有一定的帮助。</p>
<p>最后，UUID 是由 32 个 16 进制数字组成的字符串，如果作为数据库主键使用比较耗费空间。</p>
<p>你能看到，UUID 方案有很大的局限性，也是我不建议你用它的原因，而 twitter 提出的 Snowflake 算法完全可以弥补 UUID 存在的不足，因为它不仅算法简单易实现，也满足 ID 所需要的全局唯一性，单调递增性，还包含一定的业务上的意义。</p>
<p><strong>Snowflake</strong><br>
Snowflake 的核心思想是将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。它的标准算法是这样的：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801153146.png"><br>
从上面这张图中我们可以看到，41 位的时间戳大概可以支撑 <code>pow(2,41)/1000/60/60/24/365</code> 年，约等于 69 年，对于一个系统是足够了。</p>
<p>如果你的系统部署在多个机房，那么 10 位的机器 ID 可以继续划分为 2～3 位的 IDC 标示（可以支撑 4 个或者 8 个 IDC 机房）和 7～8 位的机器 ID（支持 128-256 台机器）；12 位的序列号代表着每个节点每毫秒最多可以生成 4096 的 ID。</p>
<p>不同公司也会依据自身业务的特点对 Snowflake 算法做一些改造，比如说减少序列号的位数增加机器 ID 的位数以支持单 IDC 更多的机器，也可以在其中加入业务 ID 字段来区分不同的业务。 比方说我现在使用的发号器的组成规则就是： 1 位兼容位恒为 0 + 41 位时间信息 + 6 位 IDC 信息（支持 64 个 IDC）+ 6 位业务信息（支持 64 个业务）+ 10 位自增信息（每毫秒支持 1024 个号）</p>
<p>我选择这个组成规则，主要是因为我在单机房只部署一个发号器的节点，并且使用 KeepAlive 保证可用性。业务信息指的是项目中哪个业务模块使用，比如用户模块生成的 ID，内容模块生成的 ID，把它加入进来，一是希望不同业务发出来的 ID 可以不同，二是因为在出现问题时可以反解 ID，知道是哪一个业务发出来的 ID。</p>
<p>那么了解了 Snowflake 算法的原理之后，我们如何把它工程化，来为业务生成全局唯一的 ID 呢？ 一般来说我们会有两种算法的实现方式：</p>
<ol>
<li>嵌入到业务代码里，也就是分布在业务服务器中。 这种方案的好处是业务代码在使用的时候不需要跨网络调用，性能上会好一些，但是就需要更多的机器 ID 位数来支持更多的业务服务器。另外，由于业务服务器的数量很多，我们很难保证机器 ID 的唯一性，所以就需要引入 ZooKeeper 等分布式一致性组件来保证每次机器重启时都能获得唯一的机器 ID。</li>
<li>作为独立的服务部署，这也就是我们常说的发号器服务。 业务在使用发号器的时候就需要多一次的网络调用，但是内网的调用对于性能的损耗有限，却可以减少机器 ID 的位数，如果发号器以主备方式部署，同时运行的只有一个发号器，那么机器 ID 可以省略，这样可以留更多的位数给最后的自增信息位。即使需要机器 ID，因为发号器部署实例数有限，那么就可以把机器 ID 写在发号器的配置文件里，这样即可以保证机器 ID 唯一性，也无需引入第三方组件了。 微博和美图都是使用独立服务的方式来部署发号器的，性能上单实例单 CPU 可以达到两万每秒。</li>
</ol>
<p>Snowflake 算法设计的非常简单且巧妙，性能上也足够高效，同时也能够生成 具有<code>全局唯一性</code>、<code>单调递增性</code>和<code>有业务含义的 ID</code> ，但是它也有一些缺点，其中最大的缺点就是它依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。所以如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止。</p>
<blockquote>
<p><code>如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀</code>。</p>
</blockquote>
<p>这一点，也是我在实际项目中踩过的坑，而解决办法主要有两个：</p>
<ol>
<li>时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均。</li>
<li>生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。</li>
</ol>
<p>我在开头提到，自己的实际项目中采用的是变种的 Snowflake 算法，也就是说对 Snowflake 算法进行了一定的改造，从上面的内容中你可以看出，这些改造：</p>
<ul>
<li>一是要让算法中的 ID 生成规则符合自己业务的特点；</li>
<li>二是为了解决诸如时间回拨等问题。</li>
</ul>
<p>其实，大厂除了采取 Snowflake 算法之外，还会选用一些其他的方案，比如滴滴和美团都有提出基于数据库生成 ID 的方案。这些方法根植于公司的业务，同样能解决分布式环境下 ID 全局唯一性的问题。对你而言，可以多角度了解不同的方法，这样能够寻找到更适合自己业务目前场景的解决方案，不过我想说的是， 方案不在多，而在精，方案没有最好，只有最适合，真正弄懂方法背后的原理，并将它落地，才是你最佳的选择。</p>
<p><strong>小结</strong><br>
结合自己的项目经历带你了解了如何使用 Snowflake 算法解决分库分表后数据库 ID 的全局唯一的问题，在这个问题中，又延伸性地带你了解了生成的 ID 需要满足单调递增性，以及要具有一定业务含义的特性。当然，我们重点的内容是讲解如何将 Snowflake 算法落地，以及在落地过程中遇到了哪些坑，带你去解决它。</p>
<p>Snowflake 的算法并不复杂，你在使用的时候可以不考虑独立部署的问题，先想清楚按照自身的业务场景，需要如何设计 Snowflake 算法中的每一部分占的二进制位数。比如你的业务会部署几个 IDC，应用服务器要部署多少台机器，每秒钟发号个数的要求是多少等等，然后在业务代码中实现一个简单的版本先使用，等到应用服务器数量达到一定规模，再考虑独立部署的问题就可以了。这样可以避免多维护一套发号器服务，减少了运维上的复杂度。</p>
<h3 id="nosql"><a class="markdownIt-Anchor" href="#nosql"></a> NoSQL</h3>
<p>在高并发场景下，数据库和NoSQL如何做到互补？<br>
前几节课，我带你了解了在你的垂直电商项目中，如何将传统的关系型数据库改造成分布式存储服务，以抵抗高并发和大流量的冲击。</p>
<p>对于存储服务来说，我们一般会从两个方面对它做改造：</p>
<ol>
<li>提升它的读写性能，尤其是读性能，因为我们面对的多是一些读多写少的产品。比方说，你离不开的微信朋友圈、微博和淘宝，都是查询 QPS 远远大于写入 QPS。</li>
<li>增强它在存储上的扩展能力，从而应对大数据量的存储需求。</li>
</ol>
<p>我之前带你学习的读写分离和分库分表就是从这两方面出发，改造传统的关系型数据库的，但仍有一些问题无法解决。</p>
<p>比如，在微博项目中关系的数据量达到了千亿，那么即使分隔成 1024 个库表，每张表的数据量也达到了亿级别，并且关系的数据量还在以极快的速度增加，即使你分隔成再多的库表，数据量也会很快增加到瓶颈。这个问题用传统数据库很难根本解决，因为它在扩展性方面是很弱的，这时，就可以利用 NoSQL，因为它有着天生分布式的能力，能够提供优秀的读写性能，可以很好地补充传统关系型数据库的短板。那么它是如何做到的呢？</p>
<p>这节课，我就还是以你的垂直电商系统为例，带你掌握如何用 NoSQL 数据库和关系型数据库互补 ，共同承担高并发和大流量的冲击。</p>
<p>首先，我们先来了解一下 NoSQL 数据库。</p>
<p>NoSQL 数据库发展到现在，十几年间，出现了多种类型，我来给你举几个例子：</p>
<ul>
<li>Redis、LevelDB 这样的 KV 存储。这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用。</li>
<li>Hbase、Cassandra 这样的 列式存储数据库。这种数据库的特点是数据不像传统数据库以行为单位来存储，而是以列来存储，适用于一些离线数据统计的场景。</li>
<li>像 MongoDB、CouchDB 这样的文档型数据库。这种数据库的特点是 Schema Free（模式自由），数据表中的字段可以任意扩展，比如说电商系统中的商品有非常多的字段，并且不同品类的商品的字段也都不尽相同，使用关系型数据库就需要不断增加字段支持，而用文档型数据库就简单很多了。</li>
</ul>
<p>在 NoSQL 数据库刚刚被应用时，它被认为是可以替代关系型数据库的银弹，在我看来，也许因为以下几个方面的原因：</p>
<ul>
<li>弥补了传统数据库在性能方面的不足；</li>
<li>数据库变更方便，不需要更改原先的数据结构；</li>
<li>适合互联网项目常见的大数据量的场景；</li>
</ul>
<p>不过，这种看法是个误区，因为慢慢地我们发现在业务开发的场景下还是需要利用 SQL 语句的强大的查询功能以及传统数据库事务和灵活的索引等功能，NoSQL 只能作为一些场景的补充。</p>
<p>那么接下来，我就带你了解 NoSQL 数据库是如何做到与关系数据库互补的。 了解这部分内容，你可以在实际项目中更好地使用 NoSQL 数据库补充传统数据库的不足。</p>
<p>首先，我们来关注一下数据库的写入性能。</p>
<h4 id="使用-nosql-提升写入性能"><a class="markdownIt-Anchor" href="#使用-nosql-提升写入性能"></a> 使用 NoSQL 提升写入性能</h4>
<p>数据库系统大多使用的是传统的机械磁盘，对于机械磁盘的访问方式有两种：</p>
<ul>
<li>一种是随机 IO</li>
</ul>
<p>随机 IO 就需要花费时间做昂贵的磁盘寻道，一般来说，它的读写效率要比顺序 IO 小两到三个数量级，所以我们想要提升写入的性能就要尽量减少随机 IO</p>
<ul>
<li>另一种是顺序 IO</li>
</ul>
<p>以 MySQL 的 InnoDB 存储引擎来说，更新 binlog、redolog、undolog 都是在做顺序 IO，而更新 datafile 和索引文件则是在做随机 IO，而为了减少随机 IO 的发生，关系数据库已经做了很多的优化，比如说写入时先写入内存，然后批量刷新到磁盘上，但是随机 IO 还是会发生。</p>
<p>索引在 InnoDB 引擎中是以<code>B+</code>树方式来组织的，而 MySQL 主键是聚簇索引（一种索引类型，数据与索引数据放在一起），既然数据和索引数据放在一起，那么在数据插入或者更新的时候，我们需要找到要插入的位置，再把数据写到特定的位置上，这就产生了随机的 IO。而且一旦发生了页分裂，就不可避免会做数据的移动，也会极大地损耗写入性能。</p>
<p><strong>NoSQL 数据库是怎么解决这个问题的呢？</strong><br>
它们有多种的解决方式，这里我给你讲一种最常见的方案，就是很多 NoSQL 数据库都在使用的 基于 <strong>LSM</strong> 树的存储引擎， 这种算法使用最多，所以在这里着重剖析一下。</p>
<h5 id="lsm"><a class="markdownIt-Anchor" href="#lsm"></a> LSM</h5>
<p>LSM 树（Log-Structured Merge Tree）牺牲了一定的读性能来换取写入数据的高性能，Hbase、Cassandra、LevelDB 都是用这种算法作为存储的引擎。</p>
<p>它的思想很简单，数据首先会写入到一个叫做 MemTable 的内存结构中，在 MemTable 中数据是按照写入的 Key 来排序的。为了防止 MemTable 里面的数据因为机器掉电或者重启而丢失，一般会通过写 Write Ahead Log 的方式将数据备份在磁盘上。</p>
<p>MemTable 在累积到一定规模时，它会被刷新生成一个新的文件，我们把这个文件叫做 SSTable（Sorted String Table）。当 SSTable 达到一定数量时，我们会将这些 SSTable 合并，减少文件的数量，因为 SSTable 都是有序的，所以合并的速度也很快。</p>
<p>当从 LSM 树里面读数据时，我们首先从 MemTable 中查找数据，如果数据没有找到，再从 SSTable 中查找数据。因为存储的数据都是有序的，所以查找的效率是很高的，只是因为数据被拆分成多个 SSTable，所以读取的效率会低于 B+ 树索引。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801165824.png"></p>
<p>和 LSM 树类似的算法有很多，比如说 TokuDB 使用的名为 Fractal tree 的索引结构，它们的<strong>核心思想就是将随机 IO 变成顺序的 IO，从而提升写入的性能</strong>。</p>
<p>在后面的缓存篇中，我也将给你着重介绍我们是如何使用 KV 型 NoSQL 存储来提升读性能的。所以你看，NoSQL 数据库补充关系型数据库的第一种方式就是提升读写性能。</p>
<h4 id="场景补充"><a class="markdownIt-Anchor" href="#场景补充"></a> 场景补充</h4>
<p>除了可以提升性能之外，NoSQL 数据库还可以在某些场景下作为传统关系型数据库的补充，来看一个具体的例子。</p>
<p>假设某一天，CEO 找到你并且告诉你，他正在为你的垂直电商项目规划搜索的功能，需要支持按照商品的名称模糊搜索到对应的商品，希望你尽快调研出解决方案。</p>
<p>一开始，你认为这非常的简单，不就是在数据库里面执行一条类似：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> product <span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">like</span> ‘%***%’</span></pre></td></tr></table></figure>
<p>的语句吗？可是在实际执行的过程中，却发现了问题。</p>
<p>你发现这类语句并不是都能使用到索引，只有后模糊匹配的语句才能使用索引。比如语句</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> product <span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">like</span> ‘% 电冰箱’</span></pre></td></tr></table></figure>
<p>就没有使用到字段 name 上的索引，而</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> product <span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">like</span> ‘索尼 %’</span></pre></td></tr></table></figure>
<p>就使用了 name 上的索引。而一旦没有使用索引就会扫描全表的数据，在性能上是无法接受的。</p>
<p>于是你在谷歌上搜索了一下解决方案，发现大家都在使用开源组件 Elasticsearch 来支持搜索的请求，它本身是基于“倒排索引”来实现的， 那么什么是倒排索引呢？</p>
<p><strong>倒排索引</strong><br>
倒排索引是指将记录中的某些列做分词，然后形成的分词与记录 ID 之间的映射关系。比如说，你的垂直电商项目里面有以下记录：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801170748.png"><br>
那么，我们将商品名称做简单的分词，然后建立起分词和商品 ID 的对应关系，就像下面展示的这样：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801170817.png"></p>
<p>这样，如果用户搜索电冰箱，就可以给他展示商品 ID 为 1 和 3 的两件商品了。</p>
<p>而 Elasticsearch 作为一种常见的 NoSQL 数据库， 就以倒排索引作为核心技术原理，为你提供了分布式的全文搜索服务，这在传统的关系型数据库中使用 SQL 语句是很难实现的。 所以你看，NoSQL 可以在某些业务场景下代替传统数据库提供数据存储服务。</p>
<h4 id="提升扩展性"><a class="markdownIt-Anchor" href="#提升扩展性"></a> 提升扩展性</h4>
<p>另外，在扩展性方面，很多 NoSQL 数据库也有着先天的优势。还是以你的垂直电商系统为例，你已经为你的电商系统增加了评论系统，开始你的评估比较乐观，觉得电商系统的评论量级不会增长很快，所以就为它分了 8 个库，每个库拆分成 16 张表。</p>
<p>但是评论系统上线之后，存储量级增长的异常迅猛，你不得不将数据库拆分成更多的库表，而数据也要重新迁移到新的库表中，过程非常痛苦，而且数据迁移的过程也非常容易出错。</p>
<p>这时，你考虑是否可以考虑使用 NoSQL 数据库来彻底解决扩展性的问题，经过调研你发现它们在设计之初就考虑到了分布式和大数据存储的场景， 比如像 MongoDB 就有三个扩展性方面的特性。</p>
<ul>
<li>Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。同时呢，Replica 还可以分担读请求。Replica 中有主节点来承担写请求，并且把对数据变动记录到 oplog 里（类似于 binlog）；从节点接收到 oplog 后就会修改自身的数据以保持和主节点的一致。一旦主节点挂掉，MongoDB 会从从节点中选取一个节点成为主节点，可以继续提供写数据服务。<br>
 </li>
<li>Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。MongoDB 的 Sharding 特性一般需要三个角色来支持，一个是 Shard Server，它是实际存储数据的节点，是一个独立的 Mongod 进程；二是 Config Server，也是一组 Mongod 进程，主要存储一些元信息，比如说哪些分片存储了哪些数据等；最后是 Route Server，它不实际存储数据，仅仅作为路由使用，它从 Config Server 中获取元信息后，将请求路由到正确的 Shard Server 中。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801171216.png"><br>
 </li>
<li>负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。当我们的 Shard Server 存储空间不足需要扩容时，数据会自动被移动到新的 Shard Server 上，减少了数据迁移和验证的成本。</li>
</ul>
<p>你可以看到，NoSQL 数据库中内置的扩展性方面的特性可以让我们不再需要对数据库做分库分表和主从分离，也是对传统数据库一个良好的补充。</p>
<p>你可能会觉得，NoSQL 已经成熟到可以代替关系型数据库了，但是就目前来看，NoSQL 只能作为传统关系型数据库的补充而存在，弥补关系型数据库在性能、扩展性和某些场景下的不足，所以你在使用或者选择时要结合自身的场景灵活地运用。</p>
<h4 id="小结-4"><a class="markdownIt-Anchor" href="#小结-4"></a> 小结</h4>
<p>了解了 NoSQL 数据库在性能、扩展性上的优势，以及它的一些特殊功能特性，主要有以下几点：</p>
<ol>
<li>
<p>在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；</p>
</li>
<li>
<p>在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；</p>
</li>
<li>
<p>在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。</p>
</li>
</ol>
<p>这些都让它成为传统关系型数据库的良好的补充，你需要了解的是， NoSQL 可供选型的种类很多，每一个组件都有各自的特点。你在做选型的时候需要对它的实现原理有比较深入的了解，最好在运维方面对它有一定的熟悉，这样在出现问题时才能及时找到解决方案。 否则，盲目跟从地上了一个新的 NoSQL 数据库，最终可能导致会出了故障无法解决，反而成为整体系统的拖累。</p>
<p>我在之前的项目中曾经使用 Elasticsearch 作为持久存储，支撑社区的 feed 流功能，初期开发的时候确实很爽，你可以针对 feed 中的任何字段做灵活高效地查询，业务功能迭代迅速，代码也简单易懂。可是到了后期流量上来之后，由于缺少对于 Elasticsearch 成熟的运维能力，造成故障频出，尤其到了高峰期就会出现节点不可用的问题，而由于业务上的巨大压力又无法分出人力和精力对 Elasticsearch 深入的学习和了解，最后不得不做大的改造切回熟悉的 MySQL。 所以，对于开源组件的使用，不能只停留在只会 hello world 的阶段，而应该对它有足够的运维上的把控能力。</p>
<p>这些都让它成为传统关系型数据库的良好的补充，你需要了解的是， <strong>NoSQL 可供选型的种类很多</strong>，<strong>每一个组件都有各自的特点</strong>。你在做选型的时候需要对它的实现原理有比较深入的了解，最好在运维方面对它有一定的熟悉，这样在出现问题时才能及时找到解决方案。 否则，盲目跟从地上了一个新的 NoSQL 数据库，最终可能导致会出了故障无法解决，反而成为整体系统的拖累。</p>
<p>我在之前的项目中曾经使用 Elasticsearch 作为持久存储，支撑社区的 feed 流功能，初期开发的时候确实很爽，你可以针对 feed 中的任何字段做灵活高效地查询，业务功能迭代迅速，代码也简单易懂。可是到了后期流量上来之后，由于缺少对于 Elasticsearch 成熟的运维能力，造成故障频出，尤其到了高峰期就会出现节点不可用的问题，而由于业务上的巨大压力又无法分出人力和精力对 Elasticsearch 深入的学习和了解，最后不得不做大的改造切回熟悉的 MySQL。 所以，对于开源组件的使用，不能只停留在只会 hello world 的阶段，而应该对它有足够的运维上的把控能力。</p>
<h2 id="缓存"><a class="markdownIt-Anchor" href="#缓存"></a> 缓存</h2>
<p>通过前面数据库篇的学习，你已经了解了在高并发大流量下，数据库层的演进过程以及库表设计上的考虑点。你的垂直电商系统在完成了对数据库的主从分离和分库分表之后，已经可以支撑十几万 DAU 了，整体系统的架构也变成了下面这样：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801173226.png"></p>
<p>从整体上看，数据库分了主库和从库，数据也被切分到多个数据库节点上。但随着并发的增加，存储数据量的增多，数据库的磁盘 IO 逐渐成了系统的瓶颈，我们需要一种访问更快的组件来降低请求响应时间，提升整体系统性能。这时我们就会使用缓存。 那么什么是缓存，我们又该如何将它的优势最大化呢？</p>
<h3 id="缓存定义"><a class="markdownIt-Anchor" href="#缓存定义"></a> 缓存定义</h3>
<p>缓存，是一种存储数据的组件，它的作用是让对数据的请求更快地返回。</p>
<p>我们经常会把缓存放在内存中来存储， 所以有人就把内存和缓存画上了等号，这完全是外行人的见解。作为业内人士，你要知道在某些场景下我们可能还会使用 SSD 作为冷数据的缓存。比如说 360 开源的 Pika 就是使用 SSD 存储数据解决 Redis 的容量瓶颈的。</p>
<p>实际上，<strong>凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存</strong> 。那么说到这儿我们就需要知道常见硬件组件的延时情况是什么样的了，这样在做方案的时候可以对延迟有更直观的印象。幸运的是，业内已经有人帮我们总结出这些数据了，我将这些数据整理了一下，你可以看一下。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801173704.png"></p>
<p>从这些数据中，你可以看到，做一次内存寻址大概需要 100ns，而做一次磁盘的查找则需要 10ms。如果我们将做一次内存寻址的时间类比为一个课间，那么做一次磁盘查找相当于度过了大学的一个学期。可见，我们使用内存作为缓存的存储介质相比于以磁盘作为主要存储介质的数据库来说，性能上会提高多个数量级，同时也能够支撑更高的并发量。所以，内存是最常见的一种缓存数据的介质。</p>
<p>缓存作为一种常见的 <strong>空间换时间的性能优化手段</strong>，在很多地方都有应用，我们先来看几个例子，相信你一定不会陌生。</p>
<h4 id="缓存案例"><a class="markdownIt-Anchor" href="#缓存案例"></a> 缓存案例</h4>
<p>Linux 内存管理是通过一个叫做 MMU（Memory Management Unit）的硬件，来实现从虚拟地址到物理地址的转换的，但是如果每次转换都要做这么复杂计算的话，无疑会造成性能的损耗，所以我们会借助一个叫做 TLB（Translation Lookaside Buffer）的组件来缓存最近转换过的虚拟地址，和物理地址的映射。TLB 就是一种缓存组件，缓存复杂运算的结果，就好比你做一碗色香味俱全的面条可能比较复杂，那么我们把做好的面条油炸处理一下做成方便面，你做方便面的话就简单多了，也快速多了。这个缓存组件比较底层，这里你只需要了解一下就可以了。</p>
<p>我们熟知的 <strong>HTTP 协议也是有缓存机制的</strong>。当我们第一次请求静态的资源时，比如一张图片，服务端除了返回图片信息，在响应头里面还有一个 Etag 的字段。浏览器会缓存图片信息以及这个字段的值。当下一次再请求这个图片的时候，浏览器发起的请求头里面会有一个 If-None-Match 的字段，并且把缓存的 Etag 的值写进去发给服务端。服务端比对图片信息是否有变化，如果没有，则返回浏览器一个 304 的状态码，浏览器会继续使用缓存的图片信息。通过这种缓存协商的方式，可以减少网络传输的数据大小，从而提升页面展示的性能。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801174534.png"></p>
<h4 id="缓存与缓冲区"><a class="markdownIt-Anchor" href="#缓存与缓冲区"></a> 缓存与缓冲区</h4>
<p>讲了这么多缓存案例，想必你对缓存已经有了一个直观并且形象的了解了。除了缓存，我们在日常开发过程中还会经常听见一个相似的名词—— 缓冲区 ，那么，什么是缓冲区呢？缓冲和缓存只有一字之差，它们有什么区别呢？</p>
<p>我们知道，缓存可以提高低速设备的访问速度，或者减少复杂耗时的计算带来的性能问题。理论上说，我们可以通过缓存解决所有关于「慢」的问题，比如从磁盘随机读取数据慢，从数据库查询数据慢，只是不同的场景消耗的存储成本不同。</p>
<p><strong>缓冲区则是一块临时存储数据的区域</strong>，<strong>这些数据后面会被传输到其他设备上</strong>。 缓冲区更像「消息队列篇」中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差 。比如，我们将数据写入磁盘时并不是直接刷盘，而是写到一块缓冲区里面，内核会标识这个缓冲区为脏。当经过一定时间或者脏缓冲区比例到达一定阈值时，由单独的线程把脏块刷新到硬盘。这样避免了每次写数据都要刷盘带来的性能问题。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801174209.png"></p>
<h4 id="缓存分类"><a class="markdownIt-Anchor" href="#缓存分类"></a> 缓存分类</h4>
<p>在我们日常开发中，常见的缓存主要就是 <strong>静态缓存</strong>、<strong>分布式缓存</strong>和<strong>热点本地缓存</strong> 这三种。</p>
<p>静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态 HTML 文件来实现静态缓存，在 Nginx 上部署静态缓存可以减少对于后台应用服务器的压力。例如，我们在做一些内容管理系统的时候，后台会录入很多的文章，前台在网站上展示文章内容，就像新浪，网易这种门户网站一样。</p>
<p>每篇文章在录入的时候渲染成静态页面，放置在所有的前端 Nginx 或者 Squid 等 Web 服务器上，这样用户在访问的时候会优先访问 Web 服务器上的静态页面，在对旧的文章执行一定的清理策略后，依然可以保证 99% 以上的缓存命中率。</p>
<p>这种缓存只能针对静态数据来缓存，对于动态请求就无能为力了。那么我们如何针对动态请求做缓存呢？ 这时你就需要分布式缓存了。</p>
<p>分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。它们性能强劲，通过一些分布式的方案组成集群可以突破单机的限制。所以在整体架构中，分布式缓存承担着非常重要的角色（接下来的课程我会专门针对分布式缓存，带你了解分布式缓存的使用技巧以及高可用的方案，让你能在工作中对分布式缓存运用自如）。</p>
<p>对于静态的资源的缓存你可以选择静态缓存，对于动态的请求你可以选择分布式缓存， 那么什么时候要考虑热点本地缓存呢？</p>
<blockquote>
<p>答案是当我们遇到极端的热点数据查询的时候。 热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于分布式缓存节点或者数据库的压力。</p>
</blockquote>
<p>比如某一位明星在微博上有了热点话题，「吃瓜群众」会到他 (她) 的微博首页围观，这就会引发这个用户信息的热点查询。这些查询通常会命中某一个缓存节点或者某一个数据库分区，短时间内会形成极高的热点查询。</p>
<p>那么我们会在代码中使用一些本地缓存方案，如 HashMap，Guava Cache 或者是 Ehcache 等，它们和应用程序部署在同一个进程中，优势是不需要跨网络调度，速度极快，所以可以来阻挡短时间内的热点查询。</p>
<p>看个例子，你的垂直电商系统的首页有一些推荐的商品，这些商品信息是由编辑在后台录入和变更。你分析编辑录入新的商品或者变更某个商品的信息后，在页面的展示是允许有一些延迟的，比如说 30 秒的延迟，并且首页请求量最大，即使使用分布式缓存也很难抗住，所以你决定使用 Guava Cache 来将所有的推荐商品的信息缓存起来，并且设置每隔 30 秒重新从数据库中加载最新的所有商品。</p>
<p>首先，我们初始化 Guava 的 Loading Cache：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">CacheBuilder&lt;String, List&lt;Product&gt;&gt; cacheBuilder = CacheBuilder.newBuilder().maximumSize(maxSize).recordStats(); <span class="comment">// 设置缓存最大值</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">cacheBuilder = cacheBuilder.refreshAfterWrite(<span class="number">30</span>, TimeUnit.Seconds); <span class="comment">// 设置刷新间隔</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"> </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">LoadingCache&lt;String, List&lt;Product&gt;&gt; cache = cacheBuilder.build(<span class="keyword">new</span> CacheLoader&lt;String, List&lt;Product&gt;&gt;() &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    <span class="meta">@Override</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Product&gt; <span class="title">load</span><span class="params">(String k)</span> <span class="keyword">throws</span> Exception </span>&#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">return</span> productService.loadAll(); <span class="comment">// 获取所有商品</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    &#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">&#125;);</span></pre></td></tr></table></figure>
<p>这样，你在获取所有商品信息的时候可以调用 <code>Loading Cache</code> 的 <code>get</code> 方法，就可以优先从本地缓存中获取商品信息，如果本地缓存不存在，会使用 CacheLoader 中的逻辑从数据库中加载所有的商品。</p>
<p>由于本地缓存是部署在应用服务器中，而我们应用服务器通常会部署多台，当数据更新时，我们不能确定哪台服务器本地中了缓存，更新或者删除所有服务器的缓存不是一个好的选择，所以我们通常会等待缓存过期。因此，这种缓存的有效期很短，通常为分钟或者秒级别，以避免返回前端脏数据。</p>
<h4 id="缓存的不足"><a class="markdownIt-Anchor" href="#缓存的不足"></a> 缓存的不足</h4>
<p>通过了解上面的内容，你不难发现，缓存的主要作用是提升访问速度，从而能够抗住更高的并发。那么，缓存是不是能够解决一切问题？显然不是。事物都是具有两面性的，缓存也不例外，我们要了解它的优势的同时也需要了解它有哪些不足，从而扬长避短，将它的作用发挥到最大。</p>
<ul>
<li>
<p>首先，<strong>缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性</strong>。 这是因为缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率。比如说类似微博、朋友圈这种 20% 的内容会占到 80% 的流量。所以，一旦当业务场景读少写多时或者没有明显热点时，比如在搜索的场景下，每个人搜索的词都会不同，没有明显的热点，那么这时缓存的作用就不明显了。</p>
</li>
<li>
<p>其次，<strong>缓存会给整体系统带来复杂度，并且会有数据不一致的风险</strong>。 当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据。对于这种场景，我们可以考虑使用较短的过期时间或者手动清理的方式来解决。</p>
</li>
<li>
<p>再次，<strong>之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的</strong>。 因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。</p>
</li>
<li>
<p>最后，<strong>缓存会给运维也带来一定的成本</strong>， 运维需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。</p>
</li>
</ul>
<p>虽然有这么多的不足，但是缓存对于性能的提升是毋庸置疑的，我们在做架构设计的时候也需要把它考虑在内，只是在做具体方案的时候需要对缓存的设计有更细致的思考，才能最大化的发挥缓存的优势。</p>
<h4 id="小结-5"><a class="markdownIt-Anchor" href="#小结-5"></a> 小结</h4>
<p>了解了缓存的定义，常见缓存的分类以及缓存的不足。我想跟你强调的重点有以下几点：</p>
<ul>
<li>缓存可以有多层，比如上面提到的静态缓存处在负载均衡层，分布式缓存处在应用层和数据库层之间，本地缓存处在应用层。我们需要将请求尽量挡在上层，因为越往下层，对于并发的承受能力越差；</li>
<li>缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高。</li>
</ul>
<p>你还需要理解的是，缓存不仅仅是一种组件的名字，更是一种设计思想，你可以认为任何能够加速读请求的组件和设计方案都是缓存思想的体现。而这种加速通常是通过两种方式来实现：</p>
<ul>
<li>使用更快的介质，比方说课程中提到的内存；</li>
<li>缓存复杂运算的结果，比方说前面 TLB 的例子就是缓存地址转换的结果。</li>
</ul>
<p>那么，当你在实际工作中碰到“慢”的问题时，缓存就是你第一时间需要考虑的。</p>
<h3 id="缓存的使用"><a class="markdownIt-Anchor" href="#缓存的使用"></a> 缓存的使用</h3>
<h4 id="如何选择缓存的读写策略"><a class="markdownIt-Anchor" href="#如何选择缓存的读写策略"></a> 如何选择缓存的读写策略</h4>
<p>你可能觉得缓存的读写很简单，只需要优先读缓存，缓存不命中就从数据库查询，查询到了就回种缓存。实际上，针对不同的业务场景，缓存的读写策略也是不同的。</p>
<p>而我们在选择策略时也需要考虑诸多的因素，比如说，缓存中是否有可能被写入脏数据，策略的读写性能如何，是否存在缓存命中率下降的情况等等。接下来，我就以标准的 缓存 + 数据库 的场景为例，带你剖析经典的缓存读写策略以及它们适用的场景。这样一来，你就可以在日常的工作中根据不同的场景选择不同的读写策略。</p>
<h5 id="cache-aside旁路缓存策略"><a class="markdownIt-Anchor" href="#cache-aside旁路缓存策略"></a> Cache Aside（旁路缓存）策略</h5>
<p>我们来考虑一种最简单的业务场景，比方说在你的电商系统中有一个用户表，表中只有 ID 和年龄两个字段，缓存中我们以 ID 为 Key 存储用户的年龄信息。那么当我们要把 ID 为 1 的用户的年龄从 19 变更为 20，要如何做呢？</p>
<p>你可能会产生这样的思路： 先更新数据库中 ID 为 1 的记录，再更新缓存中 Key 为 1 的数据。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801213850.png"></p>
<p><strong>这个思路会造成缓存和数据库中的数据不一致</strong>。 比如，A 请求将数据库中 ID 为 1 的用户年龄从 19 变更为 20，与此同时，请求 B 也开始更新 ID 为 1 的用户数据，它把数据库中记录的年龄变更为 21，然后变更缓存中的用户年龄为 21。紧接着，A 请求开始更新缓存数据，它会把缓存中的年龄变更为 20。此时，数据库中用户年龄是 21，而缓存中的用户年龄却是 20。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801213950.png"><br>
为什么产生这个问题呢？ <strong>因为变更数据库和变更缓存是两个独立的操作，而我们并没有对操作做任何的并发控制</strong>。那么当两个线程并发更新它们的时候，就会因为写入顺序的不同造成数据的不一致。</p>
<p>另外，直接更新缓存还存在另外一个问题就是丢失更新。还是以我们的电商系统为例，假如电商系统中的账户表有三个字段：ID、户名和金额，这个时候缓存中存储的就不只是金额信息，而是完整的账户信息了。当更新缓存中账户金额时，你需要从缓存中查询完整的账户数据，把金额变更后再写入到缓存中。</p>
<p>这个过程中也会有并发的问题，比如说原有金额是 20，A 请求从缓存中读到数据，并且把金额加 1，变更成 21，在未写入缓存之前又有请求 B 也读到缓存的数据后把金额也加 1，也变更成 21，两个请求同时把金额写回缓存，这时缓存里面的金额是 21，但是我们实际上预期是金额数加 2，这也是一个比较大的问题。</p>
<p>那我们要如何解决这个问题呢？ 其实，我们可以在<strong>更新数据时不更新缓存，而是删除缓存中的数据</strong>，在读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801214139.png"></p>
<p>这个策略就是我们使用缓存最常见的策略，Cache Aside 策略（也叫旁路缓存策略），这个策略数据 <strong>以数据库中的数据为准，缓存中的数据是按需加载的</strong>。它可以分为读策略和写策略。</p>
<p>读策略的步骤是：</p>
<ol>
<li>从缓存中读取数据；</li>
<li>如果缓存命中，则直接返回数据；</li>
<li>如果缓存不命中，则从数据库中查询数据；</li>
<li>查询到数据后，将数据写入到缓存中，并且返回给用户。</li>
</ol>
<p>写策略的步骤是：</p>
<ol>
<li>更新数据库中的记录；</li>
<li>删除缓存记录。</li>
</ol>
<p>你也许会问了，在写策略中，能否先删除缓存，后更新数据库呢？ 答案是不行的， 因为这样也有可能出现缓存数据不一致的问题，我以用户表的场景为例解释一下。</p>
<p>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21，这就造成了缓存和数据库的不一致。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801214331.png"></p>
<p>那么像 Cache Aside 策略这样先更新数据库，后删除缓存就没有问题了吗？其实在理论上还是有缺陷的。假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中，造成缓存和数据库数据不一致。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801214434.png"></p>
<p><strong>不过这种问题出现的几率并不高，原因是缓存的写入通常远远快于数据库的写入</strong> 。所以在实际中很难出现请求 B 已经更新了数据库并且清空了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 清空缓存之前更新了缓存，那么接下来的请求就会因为缓存为空而从数据库中重新加载数据，所以不会出现这种不一致的情况。</p>
<p><strong>Cache Aside 策略是我们日常开发中最经常使用的缓存策略</strong>，不过我们在使用时也要学会依情况而变。 比如说当新注册一个用户，按照这个更新策略，你要写数据库，然后清理缓存（当然缓存中没有数据给你清理）。可当我注册用户后立即读取用户信息，并且数据库主从分离时 ，会出现因为主从延迟所以读不到用户信息的情况。</p>
<p>而解决这个问题的办法 恰恰是在插入新数据到数据库之后写入缓存，这样后续的读请求就会从缓存中读到数据了。并且因为是新注册的用户，所以不会出现并发更新用户信息的情况 。</p>
<p>Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。 如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：</p>
<ol>
<li>一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；</li>
</ol>
<blockquote>
<p>对缓存命中率有要求，根本原因是写入频繁，加锁单线程更新就能保证了？</p>
<p>这里细说一下： 数据更新：发送更新缓存指令给 缓存组件，由缓存组件对同一个 key 是加锁更新的，它可以进行一个时间窗口的优化很厚再更新</p>
<p>读数据：发现没有缓存? 则发送读缓存指令给缓存，然后自己这边等待缓存数据的更新，直到读到后或则超时返回。</p>
</blockquote>
<ol start="2">
<li>另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快地过期，对业务的影响也是可以接受。</li>
</ol>
<h5 id="readwrite-through读穿-写穿策略"><a class="markdownIt-Anchor" href="#readwrite-through读穿-写穿策略"></a> Read/Write Through（读穿 / 写穿）策略</h5>
<p>这个策略的<strong>核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据</strong> 。</p>
<p>Write Through 的策略是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做 Write Miss（写失效）。</p>
<p>一般来说，我们可以选择两种 Write Miss 方式：</p>
<ul>
<li>
<p>Write Allocate（按写分配）<br>
做法是写入缓存相应位置，再由缓存组件同步更新到数据库中；</p>
</li>
<li>
<p>No-write allocate（不按写分配）<br>
做法是不写入缓存中，而是直接更新到数据库中</p>
</li>
</ul>
<p>在 Write Through 策略中，我们一般选择 No-write allocate 方式，原因是无论采用哪种 Write Miss 方式，我们都需要同步将数据更新到数据库中，而 No-write allocate 方式相比 Write Allocate 还减少了一次缓存的写入，能够提升写入的性能。</p>
<p>Read Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库中同步加载数据。</p>
<p>下面是 Read Through/Write Through 策略的示意图：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801215759.png"></p>
<p>Read Through/Write Through 策略的特点是 <strong>由缓存节点而非用户来和数据库打交道</strong>，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有 Read Through 策略的影子。</p>
<p>我们看到 Write Through 策略中写数据库是同步的 ，这对于性能来说会有比较大的影响，因为相比于写缓存，同步写数据库的延迟就要高很多了。那么我们可否异步地更新数据库？这就是我们接下来要提到的 Write Back 策略。</p>
<h5 id="write-back写回策略"><a class="markdownIt-Anchor" href="#write-back写回策略"></a> Write Back（写回）策略</h5>
<p>这个策略的<strong>核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为 「脏」 的。而脏块儿只有被再次使用时才会将其中的数据写入到后端存储中</strong>。</p>
<p>需要注意的是， 在 Write Miss 的情况下，我们采用的是 Write Allocate 的方式，也就是在写入后端存储的同时要写入缓存，这样我们在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了，我将 Write back 策略的示意图放在了下面：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801220108.png"></p>
<p>如果使用 Write Back 策略的话，读的策略也有一些变化了：</p>
<ol>
<li>我们在读取缓存时如果发现缓存命中则直接返回缓存数据。</li>
<li>如果缓存不命中则寻找一个可用的缓存块儿</li>
</ol>
<p>如果这个缓存块儿是 「脏」的，就把缓存块儿中之前的数据写入到后端存储中，并且从后端存储加载数据到缓存块儿。<br>
如果不是脏的，则由缓存组件将后端存储中的数据加载到缓存中，最后我们将缓存设置为不是脏的，返回数据就好了。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801220237.png"></p>
<blockquote>
<p>发现了吗？ 其实这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 <code>Page Cache</code>，还是日志的异步刷盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸置疑，它避免了直接写磁盘造成的随机写问题，毕竟写内存和写磁盘的随机 I/O 的延迟相差了几个数量级呢。</p>
</blockquote>
<p>但因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏块儿数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 <code>Page Cache</code> 还没有来得及刷盘造成的。</p>
<blockquote>
<p>计算机体系结构中的策略，它的完整读策略是这样的：如果缓存命中，则直接返回；如果缓存不命中，则重新找一个缓存块儿，如果这个缓存块儿是脏的，那么写入后端存储，并且把后端存储中的数据加载到缓存中；如果不是脏的，那么就把后端存储中的数据加载到缓存，然后标记缓存非脏<br>
所以说这里介绍的，不要看成是普通的一个 key。 而是对应这个 key 应该有的缓存数据</p>
</blockquote>
<p>当然，<strong>你依然可以在一些场景下使用这个策略，在使用时，我想给你的落地建议是</strong>： 你在向低速设备写入数据的时候，可以在内存里先暂存一段时间的数据，甚至做一些统计汇总，然后定时地刷新到低速设备上。比如说，你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监控系统收集日志后再做统计。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间的响应时间暂存起来，经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地打印到日志中。</p>
<h5 id="小结-6"><a class="markdownIt-Anchor" href="#小结-6"></a> 小结</h5>
<ol>
<li>Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。</li>
<li>Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；</li>
<li>Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。</li>
</ol>
<h4 id="缓存如何做到高可用"><a class="markdownIt-Anchor" href="#缓存如何做到高可用"></a> 缓存如何做到高可用</h4>
<p>了解了缓存的原理、分类以及常用缓存的使用技巧。我们开始用缓存承担大部分的读压力，从而缓解数据库的查询压力，在提升性能的同时保证系统的稳定性。这时，你的电商系统整体的架构演变成下图的样子：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801220900.png"></p>
<p>我们在 Web 层和数据库层之间增加了缓存层，请求会首先查询缓存，只有当缓存中没有需要的数据时才会查询数据库。</p>
<p>在这里，你需要关注缓存命中率这个指标（缓存命中率 = 命中缓存的请求数 / 总请求数）。一般来说，在你的电商系统中，核心缓存的命中率需要维持在 99% 甚至是 99.9%，哪怕下降 1%，系统都会遭受毁灭性的打击。</p>
<p>这绝不是危言耸听，我们来计算一下。假设系统的 QPS 是 10000/s，每次调用会访问 10 次缓存或者数据库中的数据，那么当缓存命中率仅仅减少 1%，数据库每秒就会增加 10000 * 10 * 1% = 1000 次请求。而一般来说我们单个 MySQL 节点的读请求量峰值就在 1500/s 左右，增加的这 1000 次请求很可能会给数据库造成极大的冲击。</p>
<p>命中率仅仅下降 1% 造成的影响就如此可怕，更不要说缓存节点故障了。而图中单点部署的缓存节点就成了整体系统中最大的隐患，那我们要如何来解决这个问题，提升缓存的可用性呢？</p>
<p>我们可以通过部署多个节点，同时设计一些方案让这些节点互为备份。这样，当某个节点故障时，它的备份节点可以顶替它继续提供服务。 而这些方案就是我们本节课的重点：<strong>分布式缓存的高可用方案</strong>。</p>
<p>在项目中，我主要选择的方案有 <code>客户端方案</code>、<code>中间代理层方案</code>和<code>服务端方案</code> 三大类：</p>
<ul>
<li>客户端方案 就是在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。</li>
<li>中间代理层方案 是在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。</li>
<li>服务端方案 就是 Redis 2.4 版本后提出的 Redis Sentinel 方案。</li>
</ul>
<p>掌握这些方案可以帮助你，抵御部分缓存节点故障导致的，缓存命中率下降的影响，增强你的系统的鲁棒性。</p>
<h5 id="客户端方案"><a class="markdownIt-Anchor" href="#客户端方案"></a> 客户端方案</h5>
<p>在客户端方案中，你需要关注缓存的写和读两个方面：</p>
<ul>
<li>写数据时，需要把被写入缓存的数据分散到多个节点中，即进行数据分片；</li>
<li>读数据时，可以利用多组的缓存来做容错，提升缓存系统的可用性。<br>
关于读数据，这里可以使用主从和多副本两种策略，两种策略是为了解决不同的问题而提出的。</li>
</ul>
<h6 id="缓存数据如何分片"><a class="markdownIt-Anchor" href="#缓存数据如何分片"></a> 缓存数据如何分片</h6>
<p>单一的缓存节点受到机器内存、网卡带宽和单节点请求量的限制，不能承担比较高的并发，因此我们考虑将数据分片，依照分片算法将数据打散到多个不同的节点上，每个节点上存储部分数据。</p>
<p>这样在某个节点故障的情况下，其他节点也可以提供服务，保证了一定的可用性。这就好比不要把鸡蛋放在同一个篮子里，这样一旦一个篮子掉在地上，摔碎了，别的篮子里还有没摔碎的鸡蛋，不至于一个不剩。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801223102.png"></p>
<p>这个算法最大的优点就是简单易理解，缺点是当增加或者减少缓存节点时，缓存总的节点个数变化造成计算出来的节点发生变化，从而造成缓存失效不可用。 所以我建议你， 如果采用这种方法，最好建立在你对于这组缓存命中率下降不敏感，比如下面还有另外一层缓存来兜底的情况下。</p>
<p>当然了，<strong>用一致性 Hash 算法可以很好地解决增加和删减节点时，命中率下降的问题</strong>。 在这个算法中，我们将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上 行走，遇到的第一个缓存节点就是要访问的节点。比方说下面这张图里面，Key 1 和 Key 2 会落入到 Node 1 中，Key 3、Key 4 会落入到 Node 2 中，Key 5 落入到 Node 3 中，Key 6 落入到 Node 4 中。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801223333.png"></p>
<p>这时如果在 Node 1 和 Node 2 之间增加一个 Node 5，你可以看到原本命中 Node 2 的 Key 3 现在命中到 Node 5，而其它的 Key 都没有变化；同样的道理，如果我们把 Node 3 从集群中移除，那么只会影响到 Key 5 。所以你看， 在增加和删除节点时，只有少量的 Key 会「漂移」到其它节点上， 而大部分的 Key 命中的节点还是会保持不变，从而可以保证命中率不会大幅下降。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801223412.png"></p>
<p>不过，事物总有两面性。虽然这个算法对命中率的影响比较小，但它还是存在问题：</p>
<ul>
<li>缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大；当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成压力。</li>
<li>一致性 Hash 算法的脏数据问题。</li>
</ul>
<p>极端情况下，比如一个有三个节点 A、B、C 承担整体的访问，每个节点的访问量平均，A 故障后，B 将承担双倍的压力（A 和 B 的全部请求），当 B 承担不了流量 Crash 后，C 也将因为要承担原先三倍的流量而 Crash，这就造成了整体缓存系统的雪崩。</p>
<p>说到这儿，你可能觉得很可怕，但也不要太担心， 我们程序员就是要能够创造性地解决各种问题，所以你可以<strong>在一致性 Hash 算法中引入虚拟节点的概念</strong>。</p>
<p>它将一个缓存节点计算多个 Hash 值分散到圆环的不同位置，这样既实现了数据的平均，而且当某一个节点故障或者退出的时候，它原先承担的 Key 将以更加平均的方式分配到其他节点上，从而避免雪崩的发生。</p>
<p>其次，就是<strong>一致性 Hash 算法的脏数据问题</strong>。为什么会产生脏数据呢？ 比方说，在集群中有两个节点 A 和 B，客户端初始写入一个 Key 为 k，值为 3 的缓存数据到 Cache A 中。这时如果要更新 k 的值为 4，但是缓存 A 恰好和客户端连接出现了问题，那这次写入请求会写入到 Cache B 中。接下来缓存 A 和客户端的连接恢复，当客户端要获取 k 的值时，就会获取到存在 Cache A 中的脏数据 3，而不是 Cache B 中的 4。</p>
<p>所以，在<strong>使用一致性 Hash 算法时一定要设置缓存的过期时间， 这样当发生漂移时，之前存储的脏数据可能已经过期，就可以减少存在脏数据的几率</strong>。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801223813.png"></p>
<p>很显然，数据分片最大的优势就是缓解缓存节点的存储和访问压力，但同时它也让缓存的使用更加复杂。在 MultiGet（批量获取）场景下，单个节点的访问量并没有减少，同时节点数太多会造成缓存访问的 SLA（即「服务等级协议」，SLA 代表了网站服务可用性）得不到很好的保证，因为根据木桶原则，SLA 取决于最慢、最坏的节点的情况，节点数过多也会增加出问题的概率， 因此我推荐 4 到 6 个节点为佳。</p>
<h6 id="memcached-的主从机制"><a class="markdownIt-Anchor" href="#memcached-的主从机制"></a> Memcached 的主从机制</h6>
<p>Redis 本身支持主从的部署方式，但是 Memcached 并不支持，所以我们今天主要来了解一下 Memcached 的主从机制是如何在客户端实现的。</p>
<p>在之前的项目中，我就遇到了单个主节点故障导致数据穿透的问题，这时我为每一组 Master 配置一组 Slave，更新数据时主从同步更新。读取时，优先从 Slave 中读数据，如果读取不到数据就穿透到 Master 读取，并且将数据回种到 Slave 中以保持 Slave 数据的热度。</p>
<p>主从机制最大的优点就是当某一个 Slave 宕机时，还会有 Master 作为兜底，不会有大量请求穿透到数据库的情况发生，提升了缓存系统的高可用性。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801224100.png"></p>
<h6 id="多副本"><a class="markdownIt-Anchor" href="#多副本"></a> 多副本</h6>
<p>其实，主从方式已经能够解决大部分场景的问题，但是对于极端流量的场景下，一组 Slave 通常来说并不能完全承担所有流量，Slave 网卡带宽可能成为瓶颈。</p>
<p>为了解决这个问题，我们考虑在 Master/Slave 之前增加一层副本层，整体架构是这样的：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801224140.png"></p>
<p>在这个方案中，当客户端发起查询请求时，请求首先会先从多个副本组中选取一个副本组发起查询，如果查询失败，就继续查询 Master/Slave，并且将查询的结果回种到所有副本组中，避免副本组中脏数据的存在。</p>
<p>基于成本的考虑，每一个副本组容量比 Master 和 Slave 要小，因此它只存储了更加热的数据。在这套架构中，Master 和 Slave 的请求量会大大减少，为了保证它们存储数据的热度，在实践中我们会把 Master 和 Slave 作为一组副本组使用。</p>
<h5 id="中间代理层方案"><a class="markdownIt-Anchor" href="#中间代理层方案"></a> 中间代理层方案</h5>
<p>虽然客户端方案已经能解决大部分的问题，但是只能在单一语言系统之间复用。例如微博使用 Java 语言实现了这么一套逻辑，我使用 PHP 就难以复用，需要重新写一套，很麻烦。 而中间代理层的方案就可以解决这个问题。 你可以将客户端解决方案的经验移植到代理层中，通过通用的协议（如 Redis 协议）来实现在其他语言中的复用。</p>
<p>如果你来自研缓存代理层，你就可以将客户端方案中的高可用逻辑封装在代理层代码里面，这样用户在使用你的代理层的时候就不需要关心缓存的高可用是如何做的，只需要依赖你的代理层就好了。</p>
<p>除此以外，业界也有很多中间代理层方案，比如 Facebook 的 Mcrouter (opens new window)，Twitter 的 Twemproxy (opens new window)，豌豆荚的 Codis (opens new window)。它们的原理基本上可以由一张图来概括：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801224405.png"></p>
<p>看这张图你有什么发现吗？ 所有缓存的 读写请求 都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用的逻辑，不同的开源中间代理层方案中使用的高可用策略各有不同。比如在 Twemproxy 中，Proxy 保证在某一个 Redis 节点挂掉之后会把它从集群中移除，后续的请求将由其他节点来完成；而 Codis 的实现略复杂，它提供了一个叫 Codis Ha 的工具来实现自动从节点提主节点，在 3.2 版本之后换做了 Redis Sentinel 方式，从而实现 Redis 节点的高可用。</p>
<h6 id="服务端方案"><a class="markdownIt-Anchor" href="#服务端方案"></a> 服务端方案</h6>
<p>Redis 在 2.4 版本中提出了 Redis Sentinel 模式来解决主从 Redis 部署时的高可用问题，它可以在主节点挂了以后自动将从节点提升为主节点，保证整体集群的可用性，整体的架构如下图所示：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801231029.png"></p>
<p>Redis Sentinel 也是集群部署的，这样可以避免 Sentinel 节点挂掉造成无法自动故障恢复的问题，每一个 Sentinel 节点都是无状态的。在 Sentinel 中会配置 Master 的地址，Sentinel 会时刻监控 Master 的状态，当发现 Master 在配置的时间间隔内无响应，就认为 Master 已经挂了，Sentinel 会从从节点中选取一个提升为主节点，并且把所有其他的从节点作为新主的从节点。Sentinel 集群内部在仲裁的时候，会根据配置的值来决定当有几个 Sentinel 节点认为主挂掉可以做主从切换的操作，也就是集群内部需要对缓存节点的状态达成一致才行。</p>
<p>Redis Sentinel 不属于代理层模式，因为对于缓存的写入和读取请求不会经过 Sentinel 节点。Sentinel 节点在架构上和主从是平级的，是作为管理者存在的， 所以可以认为是在服务端提供的一种高可用方案。</p>
<h6 id="小结-7"><a class="markdownIt-Anchor" href="#小结-7"></a> 小结</h6>
<p>分布式缓存的高可用方案主要有三种，首先是客户端方案，一般也称为 Smart Client。我们通过制定一些数据分片和数据读写的策略，可以实现缓存高可用。这种方案的好处是性能没有损耗，缺点是客户端逻辑复杂且在多语言环境下不能复用。</p>
<p>其次，中间代理方案在客户端和缓存节点之间增加了中间层，在性能上会有一些损耗，在代理层会有一些内置的高可用方案，比如 Codis 会使用 Codis Ha 或者 Sentinel。</p>
<p>最后，服务端方案依赖于组件的实现，Memcached 就只支持单机版没有分布式和 HA 的方案，而 Redis 在 2.4 版本提供了 Sentinel 方案可以自动进行主从切换。服务端方案会在运维上增加一些复杂度。</p>
<p>总体而言，分布式缓存的三种方案各有所长，有些团队可能在开发过程中已经积累了 Smart Client 上的一些经验；而有些团队在 Redis 运维上经验丰富，就可以推进 Sentinel 方案；有些团队在存储研发方面有些积累，就可以推进中间代理层方案，甚至可以自研适合自己业务场景的代理层组件，具体的选择还是要看团队的实际情况而定。</p>
<h4 id="缓存穿透了怎么办"><a class="markdownIt-Anchor" href="#缓存穿透了怎么办"></a> 缓存穿透了怎么办</h4>
<p>对于缓存来说，命中率是它的生命线。</p>
<p>在低缓存命中率的系统中，大量查询商品信息的请求会穿透缓存到数据库，因为数据库对于并发的承受能力是比较脆弱的。一旦数据库承受不了用户大量刷新商品页面、定向搜索衣服信息，就会导致查询变慢，导致大量的请求阻塞在数据库查询上，造成应用服务器的连接和线程资源被占满，最终导致你的电商系统崩溃。</p>
<p>一般来说，我们的核心缓存的命中率要保持在 <code>99%</code> 以上，非核心缓存的命中率也要尽量保证在 <code>90%</code>，如果低于这个标准，那么你可能就需要优化缓存的使用方式了。</p>
<p>既然缓存的穿透会带来如此大的影响，那么我们该如何减少它的发生呢？本节课，我就带你全面探知，面对缓存穿透时，我们到底有哪些应对措施。不过在此之前，你需要了解「到底什么是缓存穿透」，只有这样，才能更好地考虑如何设计方案解决它。</p>
<h5 id="什么是缓存穿透"><a class="markdownIt-Anchor" href="#什么是缓存穿透"></a> 什么是缓存穿透</h5>
<p>缓存穿透其实是指从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。你可以把数据库比喻为手机，它是经受不了太多的划痕和磕碰的，所以你需要给它贴个膜再套个保护壳，就能对手机起到一定的保护作用了。</p>
<p>不过，少量的缓存穿透不可避免，对系统也是没有损害的，主要有几点原因：</p>
<ul>
<li>一方面，互联网系统通常会面临极大数据量的考验，而缓存系统在容量上是有限的，不可能存储系统所有的数据，那么在查询未缓存数据的时候就会发生缓存穿透。<br>
 </li>
<li>另一方面，互联网系统的数据访问模型一般会遵从 80/20 原则。80/20 原则 又称为帕累托法则，是意大利经济学家帕累托提出的一个经济学的理论。它是指在一组事物中，最重要的事物通常只占 20%，而剩余的 80% 的事物确实不重要的。把它应用到数据访问的领域，就是我们会经常访问 20% 的热点数据，而另外的 80% 的数据则不会被经常访问。比如你买了很多衣服，很多书，但是其实经常穿的，经常看的，可能也就是其中很小的一部分。</li>
</ul>
<p>既然缓存的容量有限，并且大部分的访问只会请求 20% 的热点数据，那么理论上说，我们只需要在有限的缓存空间里存储 20% 的热点数据就可以有效地保护脆弱的后端系统了，也就可以放弃缓存另外 80% 的非热点数据了。所以，这种少量的缓存穿透是不可避免的，但是对系统是没有损害的。</p>
<p>那么什么样的缓存穿透对系统有害呢？答案是<strong>大量的穿透请求超过了后端系统的承受范围，造成了后端系统的崩溃</strong>。如果把少量的请求比作毛毛细雨，那么一旦变成倾盆大雨，引发洪水，冲倒房屋，肯定就不行了。</p>
<p>产生这种大量穿透请求的场景有很多，接下来，我就带你解析这几种场景以及相应的解决方案。</p>
<h5 id="缓存穿透的解决方案"><a class="markdownIt-Anchor" href="#缓存穿透的解决方案"></a> 缓存穿透的解决方案</h5>
<p>先来考虑这样一种场景：在你的电商系统的用户表中，我们需要通过用户 ID 查询用户的信息，缓存的读写策略采用 Cache Aside 策略。</p>
<p>那么，如果要读取一个用户表中未注册的用户，会发生什么情况呢？按照这个策略，我们会先读缓存，再穿透读数据库。由于用户并不存在，所以缓存和数据库中都没有查询到数据，因此也就不会向缓存中回种数据（也就是向缓存中设置值的意思），这样当再次请求这个用户数据的时候还是会再次穿透到数据库。在这种场景下，缓存并不能有效地阻挡请求穿透到数据库上，它的作用就微乎其微了。</p>
<p>那如何解决缓存穿透呢？一般来说我们会有两种解决方案： 回种空值以及使用布隆过滤器。</p>
<p>我们先来看看第一种方案。</p>
<h6 id="回种空值"><a class="markdownIt-Anchor" href="#回种空值"></a> 回种空值</h6>
<p>回顾上面提到的场景，你会发现最大的问题在于数据库中并不存在用户的数据，这就造成无论查询多少次，数据库中永远都不会存在这个用户的数据，穿透永远都会发生。</p>
<p>类似的场景还有一些： 比如由于代码的 bug 导致查询数据库的时候抛出了异常，这样可以认为从数据库查询出来的数据为空，同样不会回种缓存。</p>
<p>那么，当我们从数据库中查询到空值或者发生异常时，我们可以向缓存中回种一个空值。但是因为空值并不是准确的业务数据，并且会占用缓存的空间，所以我们会给这个空值加一个比较短的过期时间，让空值在短时间之内能够快速过期淘汰。 下面是这个流程的伪代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">Object nullValue = <span class="keyword">new</span> Object();</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">  Object valueFromDB = getFromDB(uid); <span class="comment">// 从数据库中查询数据</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">  <span class="keyword">if</span> (valueFromDB == <span class="keyword">null</span>) &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">    cache.set(uid, nullValue, <span class="number">10</span>);   <span class="comment">// 如果从数据库中查询到空值，就把空值写入缓存，设置较短的超时时间</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">  &#125; <span class="keyword">else</span> &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    cache.set(uid, valueFromDB, <span class="number">1000</span>);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">  &#125;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">&#125; <span class="keyword">catch</span>(Exception e) &#123;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">  cache.set(uid, nullValue, <span class="number">10</span>);</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">&#125;</span></pre></td></tr></table></figure>
<p>回种空值虽然能够阻挡大量穿透的请求，但如果有大量获取未注册用户信息的请求，缓存内就会有有大量的空值缓存，也就会浪费缓存的存储空间，如果缓存空间被占满了，还会剔除掉一些已经被缓存的用户信息反而会造成缓存命中率的下降。</p>
<p>所以这个方案，我建议你在使用的时候应该评估一下缓存容量是否能够支撑。 如果需要大量的缓存节点来支持，那么就无法通过通过回种空值的方式来解决，这时你可以考虑使用布隆过滤器。</p>
<h6 id="使用布隆过滤器"><a class="markdownIt-Anchor" href="#使用布隆过滤器"></a> 使用布隆过滤器</h6>
<p>1970 年布隆提出了一种布隆过滤器的算法，用来判断一个元素是否在一个集合中。这种算法由一个二进制数组和一个 Hash 算法组成。 它的基本思路如下：</p>
<p>我们把集合中的每一个值按照提供的 Hash 算法算出对应的 Hash 值，然后将 Hash 值对数组长度取模后得到需要计入数组的索引值，并且将数组这个位置的值从 0 改成 1。在判断一个元素是否存在于这个集合中时，你只需要将这个元素按照相同的算法计算出索引值，如果这个位置的值为 1 就认为这个元素在集合中，否则则认为不在集合中。</p>
<p>下图是布隆过滤器示意图，我来带你分析一下图内的信息。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801232025.png"><br>
A、B、C 等元素组成了一个集合，元素 D 计算出的 Hash 值所对应的的数组中值是 1，所以可以认为 D 也在集合中。而 F 在数组中的值是 0，所以 F 不在数组中。</p>
<p><strong>那么我们如何使用布隆过滤器来解决缓存穿透的问题呢</strong>？</p>
<p>还是以存储用户信息的表为例进行讲解。首先，我们初始化一个很大的数组，比方说长度为 20 亿的数组，接下来我们选择一个 Hash 算法，然后我们将目前现有的所有用户的 ID 计算出 Hash 值并且映射到这个大数组中，映射位置的值设置为 1，其它值设置为 0。</p>
<p>新注册的用户除了需要写入到数据库中之外，它也需要依照同样的算法更新布隆过滤器的数组中，相应位置的值。那么当我们需要查询某一个用户的信息时，我们首先查询这个 ID 在布隆过滤器中是否存在，如果不存在就直接返回空值，而不需要继续查询数据库和缓存，这样就可以极大地减少异常查询带来的缓存穿透。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801235001.png"></p>
<p>布隆过滤器拥有极高的性能，无论是写入操作还是读取操作，时间复杂度都是 O(1)，是常量值。在空间上，相对于其他数据结构它也有很大的优势，比如，20 亿的数组需要 2000000000/8/1024/1024 = 238M 的空间，而如果使用数组来存储，假设每个用户 ID 占用 4 个字节的空间，那么存储 20 亿用户需要 2000000000 * 4 / 1024 / 1024 = 7600M 的空间，是布隆过滤器的 32 倍。</p>
<p>不过，任何事物都有两面性，布隆过滤器也不例外， 它主要有两个缺陷：</p>
<ol>
<li>它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中；</li>
<li>不支持删除元素。</li>
</ol>
<p><strong>关于第一个缺陷，主要是 Hash 算法的问题</strong>。 因为布隆过滤器是由一个二进制数组和一个 Hash 算法组成的，Hash 算法存在着一定的碰撞几率。Hash 碰撞的含义是不同的输入值经过 Hash 运算后得到了相同的 Hash 结果。</p>
<p>本来，Hash 的含义是不同的输入，依据不同的算法映射成独一无二的固定长度的值，也就是我输入字符串 1，根据 CRC32 算法，值是 2212294583。但是现实中 Hash 算法的输入值是无限的，输出值的值空间却是固定的，比如 16 位的 Hash 值的值空间是 65535，那么它的碰撞几率就是 1/65535，即如果输入值的个数超过 65535 就一定会发生碰撞。</p>
<p>布隆过滤器的误判有一个特点，就是它只会出现 <strong>false positive</strong> 的情况。这是什么意思呢？当<strong>布隆过滤器判断元素在集合中时，这个元素可能不在集合中</strong>。但是一旦<strong>布隆过滤器判断这个元素不在集合中时，它一定不在集合中</strong>。 这一点非常适合解决缓存穿透的问题。 为什么呢？</p>
<p>布隆过滤器虽然存在误判的情况，但是还是会减少缓存穿透的情况发生，只是我们需要尽量减少误判的几率，这样布隆过滤器的判断正确的几率更高，对缓存的穿透也更少。 一个解决方案是：</p>
<p><strong>使用多个 Hash 算法为元素计算出多个 Hash 值，只有所有 Hash 值对应的数组中的值都为 1 时，才会认为这个元素在集合中</strong>。</p>
<p>布隆过滤器不支持删除元素的缺陷也和 Hash 碰撞有关。 给你举一个例子，假如两个元素 A 和 B 都是集合中的元素，它们有相同的 Hash 值，它们就会映射到数组的同一个位置。这时我们删除了 A，数组中对应位置的值也从 1 变成 0，那么在判断 B 的时候发现值是 0，也会判断 B 是不在集合中的元素，就会得到错误的结论。</p>
<p><strong>那么我是怎么解决这个问题的呢</strong>？ 我会让数组中不再只有 0 和 1 两个值，而是存储一个计数。比如如果 A 和 B 同时命中了一个数组的索引，那么这个位置的值就是 2，如果 A 被删除了就把这个值从 2 改为 1。这个方案中的数组不再存储 bit 位，而是存储数值，也就会增加空间的消耗。所以，你要依据业务场景来选择是否能够使用布隆过滤器， 比如像是注册用户的场景下，因为用户删除的情况基本不存在，所以还是可以使用布隆过滤器来解决缓存穿透的问题的。</p>
<p>讲了这么多，关于布隆过滤器的使用上，我也给你几个建议：</p>
<ol>
<li>选择多个 Hash 函数计算多个 Hash 值，这样可以减少误判的几率；</li>
<li>布隆过滤器会消耗一定的内存空间，所以在使用时需要评估你的业务场景下需要多大的内存，存储的成本是否可以接受。</li>
</ol>
<p>总的来说，<strong>回种空值</strong>和<strong>布隆过滤器</strong>是解决缓存穿透问题的两种最主要的解决方案，但是它们也有各自的适用场景，并不能解决所有问题。比方说当有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力，我们把这个场景叫做 dog-pile effect（狗桩效应）。</p>
<p>这是典型的缓存并发穿透的问题， 那么，我们如何来解决这个问题呢？ 解决狗桩效应的思路是尽量地减少缓存穿透后的并发，方案也比较简单：</p>
<ol>
<li>在代码中，控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。</li>
<li>通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。</li>
</ol>
<p>分布式锁的方式也比较简单，比方说 ID 为 1 的用户是一个热点用户，当他的用户信息缓存失效后，我们需要从数据库中重新加载数据时，先向 Memcached 中写入一个 Key 为 lock.1 的缓存项，然后去数据库里面加载数据，当数据加载完成后再把这个 Key 删掉。这时，如果另外一个线程也要请求这个用户的数据，它发现缓存中有 Key 为“ lock.1 的缓存，就认为目前已经有线程在加载数据库中的值到缓存中了，它就可以重新去缓存中查询数据，不再穿透数据库了。</p>
<h5 id="小结-8"><a class="markdownIt-Anchor" href="#小结-8"></a> 小结</h5>
<p>了解了一些解决缓存穿透的方案，你可以在发现自己的缓存系统命中率下降时，从中得到一些借鉴的思路。我想让你明确的重点是：</p>
<ol>
<li>
<p>回种空值是一种最常见的解决思路，实现起来也最简单，如果评估空值缓存占据的缓存空间可以接受，那么可以优先使用这种方案；</p>
</li>
<li>
<p>布隆过滤器会引入一个新的组件，也会引入一些开发上的复杂度和运维上的成本。所以只有在存在海量查询数据库中，不存在数据的请求时才会使用，在使用时也要关注布隆过滤器对内存空间的消耗；</p>
</li>
<li>
<p>对于极热点缓存数据穿透造成的 狗桩效应，可以通过设置分布式锁或者后台线程定时加载的方式来解决。</p>
</li>
</ol>
<p>除此之外，你还需要了解的是，数据库是一个脆弱的资源，它无论是在扩展性、性能还是承担并发的能力上，相比缓存都处于绝对的劣势，所以我们解决缓存穿透问题的 <strong>核心目标在于减少对于数据库的并发请求</strong>。 了解了这个核心的思想，也许你还会在日常工作中找到其他更好的解决缓存穿透问题的方案。</p>
<h4 id="cdn静态资源如何加速"><a class="markdownIt-Anchor" href="#cdn静态资源如何加速"></a> CDN：静态资源如何加速</h4>
<p>前面你了解了缓存的定义以及常用缓存的使用姿势，现在，你应该对包括本地缓存、分布式缓存等缓存组件的适用场景和使用技巧有了一定了解了。结合我提到的客户端高可用方案，你会将单个缓存节点扩展为高可用的缓存集群，现在，你的电商系统架构演变成了下面这样：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802002525.png"></p>
<p>在这个架构中我们使用分布式缓存对动态请求数据的读取做了加速，但是在我们的系统中 存在着大量的静态资源请求：</p>
<ol>
<li>对于移动 APP 来说，这些静态资源主要是图片、视频和流媒体信息。</li>
<li>对于 Web 网站来说，则包括了 JavaScript 文件，CSS 文件，静态 HTML 文件等等。</li>
</ol>
<p>具体到你的电商系统来说，商品的图片，介绍商品使用方法的视频等等静态资源，现在都放在了 Nginx 等 Web 服务器上，它们的读请求量极大，并且对访问速度的要求很高，并且占据了很高的带宽，这时会出现访问速度慢，带宽被占满影响动态请求的问题， 那么你就<strong>需要考虑如何针对这些静态资源进行读加速了</strong>。</p>
<h5 id="静态资源加速的考虑点"><a class="markdownIt-Anchor" href="#静态资源加速的考虑点"></a> 静态资源加速的考虑点</h5>
<p>你可能会问：「我们是否也可以使用分布式缓存来解决这个问题呢？」答案是否定的。一般来说，图片和视频的大小会在几兆到几百兆之间不等，如果我们的应用服务器和分布式缓存都部署在北京的机房里，这时一个杭州的用户要访问缓存中的一个视频，那这个视频文件就需要从北京传输到杭州，期间会经过多个公网骨干网络，延迟很高，会让用户感觉视频打开很慢，严重影响到用户的使用体验。</p>
<p>所以，静态资源访问的关键点是<strong>就近访问</strong>， 即北京用户访问北京的数据，杭州用户访问杭州的数据，这样才可以达到性能的最优。</p>
<p>另外，单个视频和图片等静态资源很大，并且访问量又极高，如果使用业务服务器和分布式缓存来承担这些流量，无论是对于内网还是外网的带宽都会是很大的考验。</p>
<p>所以我们考虑在业务服务器的上层，<strong>增加一层特殊的缓存，用来承担绝大部分对于静态资源的访问，这一层特殊缓存的节点需要遍布在全国各地，这样可以让用户选择最近的节点访问</strong>。缓存的命中率也需要一定的保证，尽量减少访问资源存储源站的请求数量（回源请求）。 这一层缓存就是我们这节的重点：CDN。</p>
<h5 id="cdn-的关键技术"><a class="markdownIt-Anchor" href="#cdn-的关键技术"></a> CDN 的关键技术</h5>
<p>CDN（Content Delivery Network/Content Distribution Network，内容分发网络）。简单来说，CDN 就是将静态的资源分发到，位于多个地理位置机房中的服务器上，因此它能很好地解决数据就近访问的问题，也就加快了静态资源的访问速度。</p>
<p>在大中型公司里面，CDN 的应用非常的普遍，大公司为了提供更稳定的 CDN 服务会选择自建 CDN，而大部分公司基于成本的考虑还是会选择专业的 CDN 厂商，网宿、阿里云、腾讯云、蓝汛等等，其中网宿和蓝汛是老牌的 CDN 厂商，阿里云和腾讯云是云厂商提供的服务，如果你的服务部署在云上可以选择相应云厂商的 CDN 服务，这些 CDN 厂商都是现今行业内比较主流的。</p>
<p>对于 CDN 来说，你可能已经从运维的口中听说过，并且也了解了它的作用。但是当让你来配置 CDN 或者是排查 CDN 方面的问题时，你就有可能因为不了解它的原理而束手无策了。</p>
<p>所以，我先来带你了解一下，要搭建一个 CDN 系统需要考虑哪两点：</p>
<ol>
<li>
<p>如何将用户的请求映射到 CDN 节点上；</p>
</li>
<li>
<p>如何根据用户的地理位置信息选择到比较近的节点。</p>
</li>
</ol>
<p>下面我就带你具体了解一下 CDN 系统是如何实现加速用户对于静态资源的请求的。</p>
<h6 id="如何让用户的请求到达-cdn-节点"><a class="markdownIt-Anchor" href="#如何让用户的请求到达-cdn-节点"></a> 如何让用户的请求到达 CDN 节点</h6>
<p>首先，我们考虑一下如何让用户的请求到达 CDN 节点，你可能会觉得，这很简单啊，只需要告诉用户 CDN 节点的 IP 地址，然后请求这个 IP 地址上面部署的 CDN 服务就可以了啊。 但是这样会有一个问题： 就是我们使用的是第三方厂商的 CDN 服务，CDN 厂商会给我们一个 CDN 的节点 IP，比如说这个 IP 地址是「111.202.34.130」，那么我们的电商系统中的图片的地址很可能是这样的：「<a href="http://111.202.34.130/1.jpg%E3%80%8D%EF%BC%8C" target="_blank" rel="noopener">http://111.202.34.130/1.jpg」，</a> 这个地址是要存储在数据库中的。</p>
<p>那么如果这个节点 IP 发生了变更怎么办？或者我们如果更改了 CDN 厂商怎么办？是不是要修改所有的商品的 url 域名呢？这就是一个比较大的工作量了。所以，我们要做的事情是 <strong>将第三方厂商提供的 IP 隐藏起来，给到用户的最好是一个本公司域名的子域名</strong>。</p>
<p>那么如何做到这一点呢？ 这就需要依靠 <code>DNS</code> 来帮我们解决域名映射的问题了</p>
<p><strong>DNS（Domain Name System，域名系统）实际上就是一个存储域名和 IP 地址对应关系的分布式数据库</strong>。而域名解析的结果一般有两种：</p>
<ol>
<li>一种叫做 A 记录，返回的是域名对应的 IP 地址；</li>
<li>另一种是 CNAME 记录，返回的是另一个域名</li>
</ol>
<p>也就是说当前域名的解析要跳转到另一个域名的解析上，实际上 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> 域名的解析结果就是一个 CNAME 记录，域名的解析被跳转到 <a href="http://www.a.shifen.com" target="_blank" rel="noopener">www.a.shifen.com</a> 上了，我们正是利用 CNAME 记录来解决域名映射问题的，具体是怎么解决的呢？我给你举个例子。</p>
<p>比如你的公司的一级域名叫做 <a href="http://example.com" target="_blank" rel="noopener">example.com</a>，那么你可以给你的图片服务的域名定义为 <a href="http://img.example.com" target="_blank" rel="noopener">img.example.com</a>，然后将这个域名的解析结果的 CNAME 配置到 CDN 提供的域名上。比如 uclound 可能会提供一个域名是 <a href="http://80f21f91.cdn.ucloud.com.cn" target="_blank" rel="noopener">80f21f91.cdn.ucloud.com.cn</a> 这个域名。这样你的电商系统使用的图片地址可以是 <a href="http://img.example.com/1.jpg%E3%80%82" target="_blank" rel="noopener">http://img.example.com/1.jpg。</a></p>
<p>用户在请求这个地址时，DNS 服务器会将域名解析到 <a href="http://80f21f91.cdn.ucloud.com.cn" target="_blank" rel="noopener">80f21f91.cdn.ucloud.com.cn</a> 域名上，然后再将这个域名解析为 CDN 的节点 IP，这样就可以得到 CDN 上面的资源数据了。</p>
<p>不过，这里面有一个问题： <strong>因为域名解析过程是分级的，每一级有专门的域名服务器承担解析的职责，所以，域名的解析过程有可能需要跨越公网做多次 DNS 查询，在性能上是比较差的</strong>。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802003646.png"></p>
<p>从 「域名分级解析示意图」中你可以看出 DNS 分为很多种，有根 DNS，顶级 DNS 等等。除此之外还有两种 DNS 需要特别留意：</p>
<ul>
<li>一种是 Local DNS，它是由你的运营商提供的 DNS，一般域名解析的第一站会到这里；</li>
<li>另一种是权威 DNS，它的含义是自身数据库中存储了这个域名对应关系的 DNS。</li>
</ul>
<p>下面我以 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> 这个域名为例给你简单介绍一下域名解析的过程：</p>
<ul>
<li>一开始，域名解析请求先会检查本机的 hosts 文件，查看是否有 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> 对应的 IP；</li>
<li>如果没有的话，就请求 Local DNS 是否有域名解析结果的缓存，如果有就返回，标识是从非权威 DNS 返回的结果；</li>
<li>如果没有，就开始 DNS 的迭代查询：</li>
<li>先请求根 DNS，根 DNS 返回顶级 DNS（.com）的地址；</li>
<li>再请求 .com 顶级 DNS，得到 <a href="http://baidu.com" target="_blank" rel="noopener">baidu.com</a> 的域名服务器地址；</li>
<li>再从 <a href="http://baidu.com" target="_blank" rel="noopener">baidu.com</a> 的域名服务器中查询到 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> 对应的 IP 地址，返回这个 IP 地址的同时，标记这个结果是来自于权威 DNS 的结果，同时写入 Local DNS 的解析结果缓存，这样下一次的解析同一个域名就不需要做 DNS 的迭代查询了。</li>
</ul>
<p>经过了向多个 DNS 服务器做查询之后，整个 DNS 的解析的时间有可能会到秒级别， 那么我们如何来解决这个性能问题呢？</p>
<p><strong>一个解决的思路是</strong>： 在 APP 启动时，对需要解析的域名做预先解析，然后把解析的结果缓存到本地的一个 LRU 缓存里面。这样当我们要使用这个域名的时候，只需要从缓存中直接拿到所需要的 IP 地址就好了，如果缓存中不存在才会走整个 DNS 查询的过程。 同时， 为了避免 DNS 解析结果的变更造成缓存内数据失效，我们可以启动一个定时器，定期地更新缓存中的数据。</p>
<blockquote>
<p>我曾经测试过这种方式， 对于 HTTP 请求的响应时间的提升是很明显的，原先 DNS 解析时间经常会超过 1s，使用这种方式后，DNS 解析时间可以控制在 200ms 之内，整个 HTTP 请求的过程也可以减少大概 80ms～100ms。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802004009.png"></p>
</blockquote>
<p><strong>总结</strong>， 将用户的请求映射到 CDN 服务器上，是使用 CDN 时需要解决的一个核心的问题，而 CNAME 记录在 DNS 解析过程中可以充当一个中间代理层的角色，可以把将用户最初使用的域名代理到正确的 IP 地址上。图片:<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802004109.png"><br>
现在，剩下的一个问题就是如何找到更近的 CDN 节点了，而 GSLB 承担了这个职责。</p>
<h6 id="如何找到离用户最近的-cdn-节点"><a class="markdownIt-Anchor" href="#如何找到离用户最近的-cdn-节点"></a> 如何找到离用户最近的 CDN 节点</h6>
<p>GSLB（Global Server Load Balance，全局负载均衡），它的含义是对于部署在不同地域的服务器之间做负载均衡，下面可能管理了很多的本地负载均衡组件。 它有两方面的作用：</p>
<ul>
<li>一方面，它是一种负载均衡服务器，负载均衡，顾名思义嘛，指的是让流量平均分配使得下面管理的服务器的负载更平均；</li>
<li>另一方面，它还需要保证流量流经的服务器与流量源头在地缘上是比较接近的。</li>
</ul>
<p>GSLB 可以 通过多种策略，来保证返回的 CDN 节点和用户尽量保证在同一地缘区域，比如说可以将用户的 IP 地址按照地理位置划分为若干的区域，然后将 CDN 节点对应到一个区域上，然后根据用户所在区域来返回合适的节点；也可以通过发送数据包测量 RTT 的方式来决定返回哪一个节点。 不过，这些原理不是本节课重点内容， 你了解一下就可以了，我不做详细的介绍。</p>
<p>有了 GSLB 之后，节点的解析过程变成了下图中的样子：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802004259.png"></p>
<p><strong>当然，是否能够从 CDN 节点上获取到资源还取决于 CDN 的同步延时。 一般，我们会通过 CDN 厂商的接口将静态的资源写入到某一个 CDN 节点上</strong> ，再由 CDN 内部的同步机制将资源分散同步到每个 CDN 节点，即使 CDN 内部网络经过了优化，这个同步的过程是有延时的，一旦我们无法从选定的 CDN 节点上获取到数据，我们就不得不从源站获取数据，而用户网络到源站的网络可能会跨越多个主干网，这样不仅性能上有损耗，也会消耗源站的带宽，带来更高的研发成本。所以，我们在使用 CDN 的时候需要关注 CDN 的命中率和源站的带宽情况。</p>
<h5 id="小结-9"><a class="markdownIt-Anchor" href="#小结-9"></a> 小结</h5>
<p>本节课，我主要带你了解了 CDN 对静态资源进行加速的原理和使用的核心技术，这里你需要了解的重点有以下几点：</p>
<ul>
<li>DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上；</li>
<li>DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间；</li>
<li>GSLB 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。</li>
</ul>
<p>作为一个服务端开发人员，你可能会忽略 CDN 的重要性，对于偶尔出现的 CDN 问题嗤之以鼻，觉得这个不是我们应该关心的内容， 这种想法是错的。</p>
<p>CDN 是我们系统的门面，其缓存的静态数据，如图片和视频数据的请求量很可能是接口请求数据的几倍甚至更高，一旦发生故障，对于整体系统的影响是巨大的。另外 CDN 的带宽历来是我们研发成本的大头， 尤其是目前处于小视频和直播风口上， 大量的小视频和直播研发团队都在绞尽脑汁地减少 CDN 的成本。由此看出，CDN 是我们整体系统至关重要的组成部分，而它作为一种特殊的缓存，其命中率和可用性也是我们服务端开发人员需要重点关注的指标。</p>
<h4 id="数据的迁移应该如何做"><a class="markdownIt-Anchor" href="#数据的迁移应该如何做"></a> 数据的迁移应该如何做</h4>
<p>由于 MySQL 不像 MongoDB 那样支持数据的 Auto Sharding（自动分片），所以无论是将 MySQL 单库拆分成多个数据库，还是由于数据存储的瓶颈，不得不将多个数据库拆分成更多的数据库时，你都要考虑如何做数据的迁移。</p>
<p>其实，在实际工作中，不只是对数据库拆分时会做数据迁移， 很多场景都需要你给出数据迁移的方案， 比如说某一天，你的老板想要将应用从自建机房迁移到云上，那么你就要考虑将所有自建机房中的数据，包括 MySQL，Redis，消息队列等组件中的数据，全部迁移到云上，这无论对哪种规模的公司来说都是一项浩瀚的工程，所以你需要在迁移之前，准备完善的迁移方案。</p>
<p>从数据库迁移和缓存迁移两个方面，带你掌握数据迁移的方法，也带你了解数据迁移过程中，需要注意的关键点，尽量让你避免踩坑。</p>
<p><strong>如何平滑地迁移数据库中的数据</strong><br>
你可能会认为：数据迁移无非是将数据从一个数据库拷贝到另一个数据库，可以通过 MySQL 主从同步的方式做到准实时的数据拷贝；也可以通过 mysqldump 工具将源库的数据导出，再导入到新库，这有什么复杂的呢？</p>
<p>其实，这两种方式只能支持单库到单库的迁移，无法支持单库到多库多表的场景。而且即便是单库到单库的迁移，迁移过程也需要满足以下几个目标：</p>
<ol>
<li>迁移应该是在线的迁移，也就是在迁移的同时还会有数据的写入；</li>
<li>数据应该保证完整性，也就是说在迁移之后需要保证新的库和旧的库的数据是一致的；</li>
<li>迁移的过程需要做到可以回滚，这样一旦迁移的过程中出现问题，可以立刻回滚到源库，不会对系统的可用性造成影响。</li>
</ol>
<p>如果你使用 Binlog 同步的方式，在同步完成后再修改代码，将主库修改为新的数据库，这样就不满足可回滚的要求，一旦迁移后发现问题，由于已经有增量的数据写入了新库而没有写入旧库，不可能再将数据库改成旧库。</p>
<p>一般来说，我们有两种方案可以做数据库的迁移</p>
<h5 id="双写方案"><a class="markdownIt-Anchor" href="#双写方案"></a> 双写方案</h5>
<p>双写，其实说起来也很简单，它可以分为以下几个步骤：</p>
<ol>
<li>将新的库配置为源库的从库，用来同步数据；<br>
如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取 Binlog 的增量日志（比如开源工具 Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。</li>
<li>同时，我们需要改造业务代码，在数据写入的时候，不仅要写入旧库，也要写入新库。<br>
当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。 但是，我们需要注意的是， 需要将写入新库失败的数据记录在单独的日志中，这样方便后续对这些数据补写，保证新库和旧库的数据一致性。</li>
<li>然后，我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。</li>
<li>如果一切顺利，我们就可以将读流量切换到新库了。<br>
由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里 <strong>最好采用灰度的方式来切换</strong>， 比如开始切换 10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。</li>
<li>由于有双写的存在，所以在切换的过程中出现任何的问题，都可以将读写流量随时切换到旧库去，保障系统的性能。</li>
<li>在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。</li>
</ol>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802005612.png"></p>
<p>其中，<strong>最容易出问题的步骤就是数据校验的工作</strong>， 所以，我建议你在未开始迁移数据之前先写好数据校验的工具或者脚本，在测试环境上测试充分之后，再开始正式的数据迁移。</p>
<p>如果是将数据从自建机房迁移到云上，你也可以使用这个方案， 只是你需要考虑的一个重要的因素是： 自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候，你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。这样在完成迁移之前，只要将自建机房的应用服务器停掉，并且将写入流量都切到新库就可以了。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802005737.png"></p>
<p>这种方案是一种比较通用的方案，无论是迁移 MySQL 中的数据，还是迁移 Redis 中的数据，甚至迁移消息队列都可以使用这种方式， 你在实际的工作中可以直接拿来使用。</p>
<p>这种方式的 好处是： 迁移的过程可以随时回滚，将迁移的风险降到了最低。 劣势是： 时间周期比较长，应用有改造的成本。</p>
<h5 id="级联同步方案"><a class="markdownIt-Anchor" href="#级联同步方案"></a> 级联同步方案</h5>
<p>这种方案也比较简单，比较适合数据从自建机房向云上迁移的场景。因为迁移上云，最担心云上的环境和自建机房的环境不一致，会导致数据库在云上运行时，因为参数配置或者硬件环境不同出现问题。</p>
<p>所以，我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下：</p>
<ol>
<li>先将新库配置为旧库的从库，用作数据同步；</li>
<li>再将一个备库配置为新库的从库，用作数据的备份；</li>
<li>等到三个库的写入一致后，将数据库的读流量切换到新库；</li>
<li>然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。</li>
</ol>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802005917.png"></p>
<p>这种方案的回滚方案也比较简单， 可以先将读流量切换到备库，再暂停应用的写入，将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802005950.png"></p>
<p>上面的级联迁移方案可以应用在，将 MySQL 从自建机房迁移到云上的场景，也可以应用在将 Redis 从自建机房迁移到云上的场景， 如果你有类似的需求可以直接拿来应用。</p>
<p>这种方案 优势是 简单易实施，在业务上基本没有改造的成本；<br>
<strong>缺点是</strong> 在切写的时候需要短暂的停止写入，对于业务来说是有损的，不过如果在业务低峰期来执行切写，可以将对业务的影响降至最低。</p>
<h5 id="数据迁移时如何预热缓存"><a class="markdownIt-Anchor" href="#数据迁移时如何预热缓存"></a> 数据迁移时如何预热缓存</h5>
<p>另外，在从自建机房向云上迁移数据时，我们也需要考虑缓存的迁移方案是怎样的。那么你可能会说：缓存本来就是作为一个中间的存储而存在的，我只需要在云上部署一个空的缓存节点，云上的请求也会穿透到云上的数据库，然后回种缓存，对于业务是没有影响的。</p>
<p>你说的没错，但是你还需要考虑的是缓存的命中率。</p>
<p>如果你部署一个空的缓存，那么所有的请求就都穿透到数据库，数据库可能因为承受不了这么大的压力而宕机，这样你的服务就会不可用了。 所以，缓存迁移的重点是保持缓存的热度。</p>
<p>刚刚我提到，Redis 的数据迁移可以使用双写的方案或者级联同步的方案，所以在这里我就不考虑 Redis 缓存的同步了，而是以 Memcached 为例来说明。</p>
<h6 id="使用副本组预热缓存"><a class="markdownIt-Anchor" href="#使用副本组预热缓存"></a> 使用副本组预热缓存</h6>
<p>我曾经提到，为了保证缓存的可用性，我们可以部署多个副本组来尽量将请求阻挡在数据库层之上。</p>
<p>数据的写入流程是写入 Master、Slave 和所有的副本组，而在读取数据的时候，会先读副本组的数据，如果读取不到再到 Master 和 Slave 里面加载数据，再写入到副本组中。 那么，我们就可以在云上部署一个副本组， 这样，云上的应用服务器读取云上的副本组，如果副本组没有查询到数据，就可以从自建机房部署的主从缓存上加载数据，回种到云上的副本组上。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802010347.png"></p>
<p>当云上部署的副本组足够热之后，也就是缓存的命中率达到至少 90%，就可以将云机房上的缓存服务器的主从都指向这个副本组，这时迁移也就完成了。</p>
<p><strong>这种方式足够简单，不过有一个致命的问题是</strong>： 如果云上的请求穿透云上的副本组，到达自建机房的主从缓存时，这个过程是需要跨越专线的。</p>
<p>这不仅会占用较多专线的带宽，同时专线的延迟相比于缓存的读取时间是比较大的，一般，即使是本地的不同机房之间的延迟也会达到 2ms～3ms，那么，一次前端请求可能会访问十几次甚至几十次的缓存，一次请求就会平白增加几十毫秒甚至过百毫秒的延迟，会极大地影响接口的响应时间，因此在实际项目中我们很少使用这种方案。</p>
<p><strong>但是，这种方案给了我们思路</strong>，让我们可以通过方案的设计在系统运行中自动完成缓存的预热，所以，我们对副本组的方案做了一些改造，以尽量减少对专线带宽的占用。</p>
<h6 id="改造副本组方案预热缓存"><a class="markdownIt-Anchor" href="#改造副本组方案预热缓存"></a> 改造副本组方案预热缓存</h6>
<p>改造后的方案对读写缓存的方式进行改造，步骤是这样的：</p>
<ol>
<li>在云上部署多组 mc 的副本组，自建机房在接收到写入请求时，会优先写入自建机房的缓存节点，异步写入云上部署的 mc 节点；</li>
<li>在处理自建机房的读请求时，会指定一定的流量，比如 10%，优先走云上的缓存节点，这样虽然也会走专线穿透回自建机房的缓存节点，但是流量是可控的；</li>
<li>当云上缓存节点的命中率达到 90% 以上时，就可以在云上部署应用服务器，让云上的应用服务器完全走云上的缓存节点就可以了。</li>
</ol>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210802010533.png"></p>
<p>使用了这种方式，我们可以实现缓存数据的迁移，又可以尽量控制专线的带宽和请求的延迟情况， 你也可以直接在项目中使用。</p>
<h5 id="小结-10"><a class="markdownIt-Anchor" href="#小结-10"></a> 小结</h5>
<p>以上我提到的数据迁移的方案，都是我在实际项目中，经常用到的、经受过实战考验的方案，希望你能通过这节课的学习，将这些方案运用到你的项目中，解决实际的问题。与此同时，我想再次跟你强调一下本节课的重点内容：</p>
<ol>
<li>
<p>双写的方案是数据库、Redis 迁移的通用方案， 你可以在实际工作中直接加以使用。 双写方案中最重要的，是通过数据校验来保证数据的一致性，这样就可以在迁移过程中随时回滚；</p>
</li>
<li>
<p>如果你需要将自建机房的数据迁移到云上，那么也可以考虑 使用级联复制的方案， 这种方案会造成数据的短暂停写，需要在业务低峰期执行；</p>
</li>
<li>
<p>缓存的迁移重点，是保证云上缓存的命中率，你可以 使用改进版的副本组方式来迁移， 在缓存写入的时候，异步写入云上的副本组，在读取时放少量流量到云上副本组，从而又可以迁移部分数据到云上副本组，又能尽量减少穿透给自建机房造成专线延迟的问题。</p>
</li>
</ol>
<p><strong>如果你作为项目的负责人， 那么在迁移的过程中，你一定要制定周密的计划：如果是数据库的迁移，那么数据的校验应该是你最需要花费时间来解决的问题</strong>。</p>
<p>如果是自建机房迁移到云上，那么专线的带宽一定是你迁移过程中的一个瓶颈点，你需要在迁移之前梳理清楚，有哪些调用需要经过专线，占用带宽的情况是怎样的，带宽的延时是否能够满足要求。你的方案中也需要尽量做到在迁移过程中，同机房的服务，调用同机房的缓存和数据库，尽量减少对于专线带宽资源的占用。</p>
<h2 id="消息队列"><a class="markdownIt-Anchor" href="#消息队列"></a> 消息队列</h2>
<p>高并发系统设计的三个目标：性能、可用性和可扩展性，而在提升系统性能方面，我们一直关注的是系统的查询性能。也用了很多的篇幅去讲解数据库的分布式改造，各类缓存的原理和使用技巧。 究其原因在于， 我们遇到的大部分场景都是读多写少， 尤其是在一个系统的初级阶段。</p>
<p>比如说，一个社区的系统初期一定是只有少量的种子用户在生产内容，而大部分的用户都在「围观」别人在说什么。此时，整体的流量比较小，而写流量可能只占整体流量的百分之一，那么即使整体的 QPS 到了 10000 次 / 秒，写请求也只是到了每秒 100 次，如果要对写请求做性能优化，它的性价比确实不太高。</p>
<p>但是，随着业务的发展，你可能会遇到一些存在 高并发写请求的场景，其中秒杀抢购就是最典型的场景。 假设你的商城策划了一期秒杀活动，活动在第五天的 00:00 开始，仅限前 200 名，那么秒杀即将开始时，后台会显示用户正在疯狂地刷新 APP 或者浏览器来保证自己能够尽量早的看到商品。</p>
<p>这时，你面对的依旧是读请求过高， 那么应对的措施有哪些呢？</p>
<p>因为用户查询的是少量的商品数据，属于 <strong>查询的热点数据</strong> ，你可以采用缓存策略，将请求尽量挡在上层的缓存中，能被静态化的数据，比如说商城里的图片和视频数据，尽量做到静态化，这样就可以命中 CDN 节点缓存 ，减少 Web 服务器的查询量和带宽负担。Web 服务器比如 Nginx 可以直接访问分布式缓存节点，这样可以避免请求到达 Tomcat 等业务服务器。</p>
<p>当然，你可以加上一些限流的策略，比如，对于短时间之内来自某一个用户、某一个 IP 或者某一台设备的重复请求做丢弃处理。</p>
<p>通过这几种方式，你发现自己可以将请求尽量挡在数据库之外了。</p>
<p>稍微缓解了读请求之后，00:00 分秒杀活动准时开始，用户瞬间向电商系统请求生成订单，扣减库存，用户的这些写操作都是不经过缓存直达数据库的。1 秒钟之内，有 1 万个数据库连接同时达到，系统的数据库濒临崩溃，寻找能够应对如此高并发的写请求方案迫在眉睫。这时你想到了消息队列。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Architecture/" rel="tag"><i class="fa fa-tag"></i> Architecture</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/rd/mysql-protocol.html" rel="prev" title="Mysql浅尝辄止">
      <i class="fa fa-chevron-left"></i> Mysql浅尝辄止
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基础篇"><span class="nav-number">1.</span> <span class="nav-text"> 基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#高并发系统它的通用设计方法是什么"><span class="nav-number">1.1.</span> <span class="nav-text"> 高并发系统：它的通用设计方法是什么</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#scale-up-vs-scale-out"><span class="nav-number">1.1.1.</span> <span class="nav-text"> Scale-up vs Scale-out</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存提升性能"><span class="nav-number">1.1.2.</span> <span class="nav-text"> 缓存提升性能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#异步处理"><span class="nav-number">1.1.3.</span> <span class="nav-text"> 异步处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#架构分层"><span class="nav-number">1.2.</span> <span class="nav-text"> 架构分层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#系统设计目标高性能-高可用-可扩展"><span class="nav-number">1.3.</span> <span class="nav-text"> 系统设计目标：高性能、高可用、可扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#高并发"><span class="nav-number">1.3.1.</span> <span class="nav-text"> 高并发</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#提高系统的处理核心数"><span class="nav-number">1.3.1.1.</span> <span class="nav-text"> 提高系统的处理核心数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#减少单次任务响应时间"><span class="nav-number">1.3.1.2.</span> <span class="nav-text"> 减少单次任务响应时间</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高可用"><span class="nav-number">1.3.2.</span> <span class="nav-text"> 高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#系统设计"><span class="nav-number">1.3.2.1.</span> <span class="nav-text"> 系统设计</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#系统运维"><span class="nav-number">1.3.2.2.</span> <span class="nav-text"> 系统运维</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#易于扩展"><span class="nav-number">1.3.3.</span> <span class="nav-text"> 易于扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#存储层的扩展性"><span class="nav-number">1.3.3.1.</span> <span class="nav-text"> 存储层的扩展性</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#业务层的扩展性"><span class="nav-number">1.3.3.2.</span> <span class="nav-text"> 业务层的扩展性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#番外memcahed组件实现原理"><span class="nav-number">1.4.</span> <span class="nav-text"> 番外：Memcahed组件实现原理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据库"><span class="nav-number">2.</span> <span class="nav-text"> 数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#池化技术"><span class="nav-number">2.1.</span> <span class="nav-text"> 池化技术</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#用连接池预先建立数据库连接"><span class="nav-number">2.1.1.</span> <span class="nav-text"> 用连接池预先建立数据库连接</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#用线程池预先创建线程"><span class="nav-number">2.1.2.</span> <span class="nav-text"> 用线程池预先创建线程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小结"><span class="nav-number">2.1.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据库优化方案"><span class="nav-number">2.2.</span> <span class="nav-text"> 数据库优化方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#主从分离"><span class="nav-number">2.2.1.</span> <span class="nav-text"> 主从分离</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#主从复制"><span class="nav-number">2.2.1.1.</span> <span class="nav-text"> 主从复制</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#如何访问数据库"><span class="nav-number">2.2.1.2.</span> <span class="nav-text"> 如何访问数据库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-2"><span class="nav-number">2.2.1.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分库分表"><span class="nav-number">2.2.2.</span> <span class="nav-text"> 分库分表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#如何对数据库做垂直拆分"><span class="nav-number">2.2.2.1.</span> <span class="nav-text"> 如何对数据库做垂直拆分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#如何对数据库做水平拆分"><span class="nav-number">2.2.2.2.</span> <span class="nav-text"> 如何对数据库做水平拆分</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#解决分库分表引入的问题"><span class="nav-number">2.2.2.3.</span> <span class="nav-text"> 解决分库分表引入的问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-3"><span class="nav-number">2.2.2.4.</span> <span class="nav-text"> 小结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#发号器"><span class="nav-number">2.3.</span> <span class="nav-text"> 发号器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据库的主键要如何选择"><span class="nav-number">2.3.1.</span> <span class="nav-text"> 数据库的主键要如何选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于-snowflake-算法搭建发号器"><span class="nav-number">2.3.2.</span> <span class="nav-text"> 基于 Snowflake 算法搭建发号器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nosql"><span class="nav-number">2.4.</span> <span class="nav-text"> NoSQL</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用-nosql-提升写入性能"><span class="nav-number">2.4.1.</span> <span class="nav-text"> 使用 NoSQL 提升写入性能</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#lsm"><span class="nav-number">2.4.1.1.</span> <span class="nav-text"> LSM</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#场景补充"><span class="nav-number">2.4.2.</span> <span class="nav-text"> 场景补充</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#提升扩展性"><span class="nav-number">2.4.3.</span> <span class="nav-text"> 提升扩展性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小结-4"><span class="nav-number">2.4.4.</span> <span class="nav-text"> 小结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缓存"><span class="nav-number">3.</span> <span class="nav-text"> 缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存定义"><span class="nav-number">3.1.</span> <span class="nav-text"> 缓存定义</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存案例"><span class="nav-number">3.1.1.</span> <span class="nav-text"> 缓存案例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存与缓冲区"><span class="nav-number">3.1.2.</span> <span class="nav-text"> 缓存与缓冲区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存分类"><span class="nav-number">3.1.3.</span> <span class="nav-text"> 缓存分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存的不足"><span class="nav-number">3.1.4.</span> <span class="nav-text"> 缓存的不足</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#小结-5"><span class="nav-number">3.1.5.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缓存的使用"><span class="nav-number">3.2.</span> <span class="nav-text"> 缓存的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#如何选择缓存的读写策略"><span class="nav-number">3.2.1.</span> <span class="nav-text"> 如何选择缓存的读写策略</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#cache-aside旁路缓存策略"><span class="nav-number">3.2.1.1.</span> <span class="nav-text"> Cache Aside（旁路缓存）策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#readwrite-through读穿-写穿策略"><span class="nav-number">3.2.1.2.</span> <span class="nav-text"> Read/Write Through（读穿 / 写穿）策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#write-back写回策略"><span class="nav-number">3.2.1.3.</span> <span class="nav-text"> Write Back（写回）策略</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-6"><span class="nav-number">3.2.1.4.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存如何做到高可用"><span class="nav-number">3.2.2.</span> <span class="nav-text"> 缓存如何做到高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#客户端方案"><span class="nav-number">3.2.2.1.</span> <span class="nav-text"> 客户端方案</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#缓存数据如何分片"><span class="nav-number">3.2.2.1.1.</span> <span class="nav-text"> 缓存数据如何分片</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#memcached-的主从机制"><span class="nav-number">3.2.2.1.2.</span> <span class="nav-text"> Memcached 的主从机制</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#多副本"><span class="nav-number">3.2.2.1.3.</span> <span class="nav-text"> 多副本</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#中间代理层方案"><span class="nav-number">3.2.2.2.</span> <span class="nav-text"> 中间代理层方案</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#服务端方案"><span class="nav-number">3.2.2.2.1.</span> <span class="nav-text"> 服务端方案</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#小结-7"><span class="nav-number">3.2.2.2.2.</span> <span class="nav-text"> 小结</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缓存穿透了怎么办"><span class="nav-number">3.2.3.</span> <span class="nav-text"> 缓存穿透了怎么办</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#什么是缓存穿透"><span class="nav-number">3.2.3.1.</span> <span class="nav-text"> 什么是缓存穿透</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缓存穿透的解决方案"><span class="nav-number">3.2.3.2.</span> <span class="nav-text"> 缓存穿透的解决方案</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#回种空值"><span class="nav-number">3.2.3.2.1.</span> <span class="nav-text"> 回种空值</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#使用布隆过滤器"><span class="nav-number">3.2.3.2.2.</span> <span class="nav-text"> 使用布隆过滤器</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-8"><span class="nav-number">3.2.3.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#cdn静态资源如何加速"><span class="nav-number">3.2.4.</span> <span class="nav-text"> CDN：静态资源如何加速</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#静态资源加速的考虑点"><span class="nav-number">3.2.4.1.</span> <span class="nav-text"> 静态资源加速的考虑点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#cdn-的关键技术"><span class="nav-number">3.2.4.2.</span> <span class="nav-text"> CDN 的关键技术</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#如何让用户的请求到达-cdn-节点"><span class="nav-number">3.2.4.2.1.</span> <span class="nav-text"> 如何让用户的请求到达 CDN 节点</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#如何找到离用户最近的-cdn-节点"><span class="nav-number">3.2.4.2.2.</span> <span class="nav-text"> 如何找到离用户最近的 CDN 节点</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-9"><span class="nav-number">3.2.4.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据的迁移应该如何做"><span class="nav-number">3.2.5.</span> <span class="nav-text"> 数据的迁移应该如何做</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#双写方案"><span class="nav-number">3.2.5.1.</span> <span class="nav-text"> 双写方案</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#级联同步方案"><span class="nav-number">3.2.5.2.</span> <span class="nav-text"> 级联同步方案</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据迁移时如何预热缓存"><span class="nav-number">3.2.5.3.</span> <span class="nav-text"> 数据迁移时如何预热缓存</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#使用副本组预热缓存"><span class="nav-number">3.2.5.3.1.</span> <span class="nav-text"> 使用副本组预热缓存</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#改造副本组方案预热缓存"><span class="nav-number">3.2.5.3.2.</span> <span class="nav-text"> 改造副本组方案预热缓存</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结-10"><span class="nav-number">3.2.5.4.</span> <span class="nav-text"> 小结</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消息队列"><span class="nav-number">4.</span> <span class="nav-text"> 消息队列</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fayhot"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Fayhot</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fayhot" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fayhot" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liuguoqing228@gmail.com" title="E-Mail → mailto:liuguoqing228@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/shisanyaowan" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;shisanyaowan" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fayhot</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.5.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
