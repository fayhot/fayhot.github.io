<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Fayhot's Blog" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-pace-theme-center-atom.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://fayhot.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: true,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="基础篇  高并发系统：它的通用设计方法是什么 高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。 我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：   Scale-out（横向扩展） 分而治之是一种常见的高并发系统设">
<meta name="keywords" content="Architecture">
<meta property="og:type" content="article">
<meta property="og:title" content="海量高并发系统架构设计">
<meta property="og:url" content="http:&#x2F;&#x2F;fayhot.github.io&#x2F;rd&#x2F;high-performance-architecture.html">
<meta property="og:site_name" content="Fayhot&#39;s Blog">
<meta property="og:description" content="基础篇  高并发系统：它的通用设计方法是什么 高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。 我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：   Scale-out（横向扩展） 分而治之是一种常见的高并发系统设">
<meta property="og:locale" content="en">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801015445.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801020223.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801022321.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801023138.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801100734.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801104931.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105052.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105411.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801105504.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801114354.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801115650.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801120009.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801123011.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801132328.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801132935.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801133231.png">
<meta property="og:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801134036.png">
<meta property="og:updated_time" content="2021-08-01T05:47:33.149Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;fayhot&#x2F;figurebed&#x2F;master&#x2F;20210412&#x2F;20210801015445.png">

<link rel="canonical" href="http://fayhot.github.io/rd/high-performance-architecture.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>海量高并发系统架构设计 | Fayhot's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fayhot's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="Searching..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://fayhot.github.io/rd/high-performance-architecture.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Fayhot">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fayhot's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          海量高并发系统架构设计
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-08-01 01:28:59 / Modified: 13:47:33" itemprop="dateCreated datePublished" datetime="2021-08-01T01:28:59+08:00">2021-08-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Research-And-Develop/" itemprop="url" rel="index">
                    <span itemprop="name">Research And Develop</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h3 id="基础篇"><a class="markdownIt-Anchor" href="#基础篇"></a> 基础篇</h3>
<h4 id="高并发系统它的通用设计方法是什么"><a class="markdownIt-Anchor" href="#高并发系统它的通用设计方法是什么"></a> 高并发系统：它的通用设计方法是什么</h4>
<p>高并发代表着大流量，高并发系统设计的魅力就在于我们能够凭借自己的聪明才智设计巧妙的方案，从而抵抗巨大流量的冲击，带给用户更好的使用体验。这些方案好似能操纵流量，让流量更加平稳得被系统中的服务和组件处理。</p>
<p>我们在应对高并发大流量时也会采用类似 抵御洪水 的方案，归纳起来共有三种方法：</p>
<ol>
<li>
<p>Scale-out（横向扩展）<br>
分而治之是一种常见的高并发系统设计方法，采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。</p>
</li>
<li>
<p>缓存<br>
使用缓存来提高系统的性能，就好比用 「拓宽河道」的方式抵抗高并发大流量的冲击。</p>
</li>
<li>
<p>异步<br>
在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。</p>
</li>
</ol>
<a id="more"></a>
<p>我们先来了解第一种方法：Scale-out。</p>
<h5 id="scale-up-vs-scale-out"><a class="markdownIt-Anchor" href="#scale-up-vs-scale-out"></a> Scale-up vs Scale-out</h5>
<ul>
<li>Scale-up 通过购买性能更好的硬件来提升系统的并发处理能力</li>
<li>Scale-out 将多个低性能的机器组成一个分布式集群来共同抵御高并发流量的冲击。</li>
</ul>
<p>一般来讲，在我们系统设计初期会考虑使用 Scale-up 的方式，因为这种方案足够简单，所谓能用堆砌硬件解决的问题就用硬件来解决，但是当系统并发超过了单机的极限时，我们就要使用 Scale-out 的方式。</p>
<p>Scale-out 虽然能够突破单机的限制，但也会引入一些复杂问题。比如，如果某个节点出现故障如何保证整体可用性？当多个节点有状态需要同步时，如何保证状态信息在不同节点的一致性？如何做到使用方无感知的增加和删除节点？等等。其中每一个问题都涉及很多的知识点，我会在后面的课程中深入地讲解，这里暂时不展开了。</p>
<p>说完了 Scale-out，我们再来看看高并发系统设计的另一种方法：缓存。</p>
<h5 id="缓存提升性能"><a class="markdownIt-Anchor" href="#缓存提升性能"></a> 缓存提升性能</h5>
<p>我们使用缓存的主要作用是提升系统的访问性能，那么在高并发的场景下，就可以支撑更多用户的同时访问。</p>
<p>那么为什么缓存可以大幅度提升系统的性能呢？我们知道数据是放在持久化存储中的，一般的持久化存储都是使用磁盘作为存储介质的，而普通磁盘数据由机械手臂、磁头、转轴、盘片组成，盘片又分为磁道、柱面和扇区。</p>
<p>盘片是存储介质，每个盘片被划分为多个同心圆，信息都被存储在同心圆之中，这些 同心圆就是磁道。在磁盘工作时盘片是在高速旋转的，机械手臂驱动磁头沿着径向移动，在磁道上读取所需要的数据。我们把<strong>磁头寻找信息花费的时间叫做寻道时间</strong>。</p>
<p>普通磁盘的寻道时间是 <code>10ms</code> 左右，而相比于磁盘寻道花费的时间，CPU 执行指令和内存寻址的时间都在是 <code>ns（纳秒）</code>级别，从千兆网卡上读取数据的时间是在 <code>μs（微秒）</code>级别。所以在整个计算机体系中，磁盘是最慢的一环，甚至比其它的组件要慢几个数量级。因此，我们通常使用以内存作为存储介质的缓存，以此提升性能。</p>
<p>当然，缓存的语义已经丰富了很多，我们<strong>可以将任何降低响应时间的中间存储都称为缓存</strong>。缓存的思想遍布很多设计领域，比如在操作系统中 <code>CPU</code> 有<code>多级缓存</code>，文件有 <code>Page Cache 缓存</code>，你应该有所了解。</p>
<h5 id="异步处理"><a class="markdownIt-Anchor" href="#异步处理"></a> 异步处理</h5>
<p>异步 也是一种常见的高并发设计方法，我们在很多文章和演讲中都能听到这个名词，与之共同出现的还有它的反义词：同步。比如，分布式服务框架 Dubbo 中有同步方法调用和异步方法调用，IO 模型中有同步 IO 和异步 IO。</p>
<p>那么什么是同步，什么是异步呢？ 以方法调用为例，同步调用代表调用方要阻塞等待被调用方法中的逻辑执行完成。这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性能下降甚至发生雪崩。</p>
<p>异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执行完毕后再通过回调、事件通知等方式将结果反馈给调用方。</p>
<p>异步调用在大规模高并发系统中被大量使用，比如我们熟知的 12306 网站。 当我们订票时，页面会显示系统正在排队，这个提示就代表着系统在异步处理我们的订票请求。在 12306 系统中查询余票、下单和更改余票状态都是比较耗时的操作，可能涉及多个内部系统的互相调用，如果是同步调用就会像 12306 刚刚上线时那样，高峰期永远不可能下单成功。</p>
<p>而采用异步的方式，后端处理时会把请求丢到消息队列中，同时快速响应用户，告诉用户我们正在排队处理，然后释放出资源来处理更多的请求。订票请求处理完之后，再通知用户订票成功或者失败。</p>
<p>处理逻辑后移到异步处理程序中，Web 服务的压力小了，资源占用的少了，自然就能接收更多的用户订票请求，系统承受高并发的能力也就提升了。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801015445.png"></p>
<p>建议一般系统的演进过程应该遵循下面的思路：</p>
<ol>
<li>最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。</li>
<li>随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。</li>
<li>当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。</li>
</ol>
<h4 id="架构分层"><a class="markdownIt-Anchor" href="#架构分层"></a> 架构分层</h4>
<p>软件架构分层在软件工程中是一种常见的设计方式，它是将整体系统拆分成 N 个层次，每个层次有独立的职责，多个层次协同提供完整的功能。</p>
<p>分层的设计可以简化系统设计，让不同的人专注做某一层次的事情。想象一下，如果你要设计一款网络程序却没有分层，该是一件多么痛苦的事情。而有了分层的设计，你只需要专注设计应用层的程序就可以了，其他的，都可以交给下面几层来完成。再有，分层之后可以做到很高的复用。最后一点，分层架构可以让我们更容易做横向扩展。</p>
<p>我们可以将原先的三层架构细化成下面的样子：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801020223.png"></p>
<p>这个分层架构中的每一层的作用：</p>
<ul>
<li>
<p>终端显示层：<br>
各端模板渲染并执行显示的层。当前主要是 Velocity 渲染，JS 渲染， JSP 渲染，移动端展示等。</p>
</li>
<li>
<p>开放接口层：<br>
将 Service 层方法封装成开放接口，同时进行网关安全控制和流量控制等。</p>
</li>
<li>
<p>Web 层：<br>
主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。</p>
</li>
<li>
<p>Service 层：业务逻辑层。</p>
</li>
<li>
<p>Manager 层：<br>
通用业务处理层。这一层主要有两个作用：<br>
其一，你可以将原先 Service 层的一些通用能力下沉到这一层，比如 与缓存和存储交互策略，中间件的接入；<br>
其二，你也可以在这一层 封装对第三方接口的调用，比如调用支付服务，调用审核服务等。<br>
DAO 层：</p>
</li>
<li>
<p>数据访问层，与底层 MySQL、Oracle、Hbase 等进行数据交互。</p>
</li>
<li>
<p>外部接口或第三方平台：<br>
包括其它部门 RPC 开放接口，基础平台，其它公司的 HTTP 接口。</p>
</li>
</ul>
<p>在这个分层架构中 主要增加了 Manager 层，它与 Service 层的关系是：</p>
<ol>
<li>Manager 层提供原子的服务接口</li>
<li>Service 层负责依据业务逻辑来编排原子接口。</li>
</ol>
<p>以上面的例子来说，Manager 层提供 创建用户 和 获取用户信息 的接口，而 Service 层负责将这两个接口组装起来。这样就把原先散布在表现层的业务逻辑都统一到了 Service 层，每一层的边界就非常清晰了。</p>
<blockquote>
<p><strong>分层架构需要考虑的另一个因素，是层次之间一定是相邻层互相依赖，数据的流转也只能在相邻的两层之间流转</strong>。</p>
</blockquote>
<p>我们还是以三层架构为例，数据从表示层进入之后一定要流转到逻辑层，做业务逻辑处理，然后流转到数据访问层来和数据库交互。</p>
<p><strong>分层架构的不足</strong><br>
任何事物都不可能是尽善尽美的，分层架构虽有优势也会有缺陷，它最主要的一个缺陷就是增加了代码的复杂度，性能上会有损耗</p>
<h4 id="系统设计目标高性能-高可用-可扩展"><a class="markdownIt-Anchor" href="#系统设计目标高性能-高可用-可扩展"></a> 系统设计目标：高性能、高可用、可扩展</h4>
<p>高并发系统设计的三大目标：高性能、高可用、可扩展</p>
<h5 id="高并发"><a class="markdownIt-Anchor" href="#高并发"></a> 高并发</h5>
<p><strong>高并发</strong>， 是指运用设计手段让系统能够处理更多的用户并发请求，也就是承担更大的流量。它是一切架构设计的背景和前提，脱离了它去谈性能和可用性是没有意义的。很显然嘛，你在每秒一次请求和每秒一万次请求，两种不同的场景下，分别做到毫秒级响应时间和五个九（99.999%）的可用性，无论是设计难度还是方案的复杂度，都不是一个级别的。</p>
<p>而<strong>性能和可用性</strong>， 是我们实现高并发系统设计必须考虑的因素。</p>
<p>性能反应了系统的使用体验，想象一下，同样承担每秒一万次请求的两个系统，一个响应时间是毫秒级，一个响应时间在秒级别，它们带给用户的体验肯定是不同的。</p>
<p>可用性则表示系统可以正常服务用户的时间。我们再类比一下，还是两个承担每秒一万次的系统，一个可以做到全年不停机、无故障，一个隔三差五宕机维护，如果你是用户，你会选择使用哪一个系统呢？答案不言而喻。</p>
<p>另一个耳熟能详的名词叫 可扩展性 ，它同样是高并发系统设计需要考虑的因素。为什么呢？我来举一个具体的例子。</p>
<p>流量分为 <code>平时流量</code> 和 <code>峰值流量</code> 两种，峰值流量可能会是平时流量的几倍甚至几十倍，在应对峰值流量的时候，我们通常需要在架构和方案上做更多的准备。这就是淘宝会花费大半年的时间准备双十一，也是在面对「明星离婚」等热点事件时，看起来无懈可击的微博系统还是会出现服务不可用的原因。 而易于扩展的系统能在短时间内迅速完成扩容，更加平稳地承担峰值流量。</p>
<p>高性能、高可用和可扩展，是我们在做高并发系统设计时追求的三个目标，下面进一步了解在高并发大流量下如何设计高性能、高可用和易于扩展的系统。</p>
<p><strong>性能优化原则</strong></p>
<ol>
<li>性能优化一定不能盲目，一定是问题导向的<br>
脱离了问题，盲目地提早优化会增加系统的复杂度，浪费开发人员的时间，也因为某些优化可能会对业务上有些折中的考虑，所以也会损伤业务。</li>
<li>性能优化也遵循「八二原则」<br>
即你可以用 20% 的精力解决 80% 的性能问题。所以我们在优化过程中一定要抓住主要矛盾，优先优化主要的性能瓶颈点。</li>
<li>性能优化也要有数据支撑<br>
在优化过程中，你要时刻了解你的优化让响应时间减少了多少，提升了多少的吞吐量。</li>
<li>性能优化的过程是持续的</li>
</ol>
<p><strong>性能的度量指标</strong><br>
一般来说，度量性能的指标是 <code>系统接口的响应时间</code>，但是单次的响应时间是没有意义的，你需要知道一段时间的性能情况是什么样的。所以，我们需要收集这段时间的响应时间数据，然后依据一些统计方法计算出 特征值，这些特征值就能够代表这段时间的性能情况。我们常见的特征值有以下几类。</p>
<ol>
<li>平均值</li>
<li>最大值</li>
<li>分位值<br>
分位值有很多种，比如 90 分位、95 分位、75 分位。以 90 分位为例，我们把这段时间请求的 响应时间从小到大排序，假如一共有 100 个请求，那么排在第 90 位的响应时间就是 90 分位值。分位值排除了偶发极慢请求对于数据的影响，能够很好地反应这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。</li>
</ol>
<p>在我来看，分位值是最适合作为时间段内，响应时间统计值来使用的，在实际工作中也应用最多。除此之外，平均值也可以作为一个参考值来使用。</p>
<p>我在上面提到，脱离了并发来谈性能是没有意义的，我们通常使用 吞吐量 或者 同时在线用户数 来度量并发和流量，使用吞吐量的情况会更多一些。但是你要知道，这两个指标是呈倒数关系的。</p>
<p>这很好理解，响应时间 1s 时，吞吐量是每秒 1 次，响应时间缩短到 10ms，那么吞吐量就上升到每秒 100 次。所以，一般我们度量性能时都会同时兼顾吞吐量和响应时间，比如我们设立性能优化的目标时通常会这样表述：在每秒 1 万次的请求量下，响应时间 99 分位值在 10ms 以下。</p>
<p>那么，响应时间究竟控制在多长时间比较合适呢？这个不能一概而论。</p>
<p>从用户使用体验的角度来看：</p>
<ul>
<li>
<p>200ms 是第一个分界点：<br>
接口的响应时间在 200ms 之内，用户是感觉不到延迟的，就像是瞬时发生的一样。</p>
</li>
<li>
<p>1s 是另外一个分界点：<br>
接口的响应时间在 1s 之内时，虽然用户可以感受到一些延迟，但却是可以接受的</p>
</li>
<li>
<p>超过 1s 之后用户就会有明显等待的感觉，等待时间越长，用户的使用体验就越差。</p>
</li>
</ul>
<p>所以，健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。</p>
<p><strong>高并发下的性能优化</strong><br>
假如说，你现在有一个系统，这个系统中处理核心只有一个，执行的任务的响应时间都在 10ms，它的吞吐量是在每秒 100 次。那么我们如何来优化性能从而提高系统的并发能力呢？主要有两种思路：</p>
<ol>
<li>一种是提高系统的处理核心数</li>
<li>一种是减少单次任务的响应时间。</li>
</ol>
<h6 id="提高系统的处理核心数"><a class="markdownIt-Anchor" href="#提高系统的处理核心数"></a> 提高系统的处理核心数</h6>
<p>提高系统的处理核心数就是 <code>增加系统的并行处理能力</code>，这个思路是优化性能最简单的途径。拿上一个例子来说，你可以把系统的处理核心数增加为两个，并且增加一个进程，让这两个进程跑在不同的核心上。这样从理论上，你系统的吞吐量可以增加一倍。当然了，在这种情况下，吞吐量和响应时间就不是倒数关系了，而是：<code>吞吐量 = 并发进程数 / 响应时间</code>。</p>
<p>计算机领域的阿姆达尔定律（Amdahl’s law）是吉恩·阿姆达尔在 1967 年提出的。它描述了并发进程数与响应时间之间的关系，含义是在固定负载下，并行计算的加速比，也就是并行化之后效率提升情况，可以用下面公式来表示：<code>(Ws + Wp) / (Ws + Wp/s)</code></p>
<p>其中，<code>Ws</code> 表示任务中的串行计算量，<code>Wp</code> 表示任务中的并行计算量，<code>s</code> 表示并行进程数。从这个公式我们可以推导出另外一个公式：<code>1/(1-p+p/s)</code></p>
<p>其中，<code>s</code> 还是表示并行进程数，<code>p</code> 表示任务中并行部分的占比。当 <code>p</code> 为 1 时，也就是完全并行时，加速比与并行进程数相等；当 <code>p</code> 为 0 时，即完全串行时，加速比为 1，也就是说完全无加速；当 <code>s</code> 趋近于无穷大的时候，加速比就等于 <code>1/(1-p)</code>，你可以看到它完全和 <code>p</code> 成正比。特别是，当 p 为 1 时，加速比趋近于无穷大。</p>
<blockquote>
<p><strong>随着并发进程数的增加，并行的任务对于系统资源的争抢也会愈发严重。在某一个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是性能测试中的 拐点模型</strong>。</p>
</blockquote>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801022321.png"></p>
<p>从图中你可以发现：</p>
<ul>
<li>并发用户数处于轻压力区时，响应时间平稳，吞吐量和并发用户数线性相关。</li>
<li>当并发用户数处于重压力区时，系统资源利用率到达极限，吞吐量开始有下降的趋势，响应时间也会略有上升。</li>
<li>这个时候，再对系统增加压力，系统就进入拐点区，处于超负荷状态，吞吐量下降，响应时间大幅度上升。</li>
</ul>
<p>所以我们在评估系统性能时通常需要做压力测试，目的就是找到系统的「拐点」，从而知道系统的承载能力，也便于找到系统的瓶颈，持续优化系统性能。</p>
<p>说完了提升并行能力，我们再看看优化性能的另一种方式：减少单次任务响应时间。</p>
<h6 id="减少单次任务响应时间"><a class="markdownIt-Anchor" href="#减少单次任务响应时间"></a> 减少单次任务响应时间</h6>
<p>想要减少任务的响应时间，首先要看你的系统是 CPU 密集型 还是 IO 密集型 的，因为不同类型的系统性能优化方式不尽相同。</p>
<p><strong>CPU 密集型系统</strong><br>
CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段。比方说，如果系统的主要任务是计算 Hash 值，那么这时选用更高性能的 Hash 算法就可以大大提升系统的性能。发现这类问题的主要方式，是通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块，比如 Linux 的 perf、eBPF 等。</p>
<p><strong>IO 密集型系统</strong><br>
IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这里 IO 指的是磁盘 IO 和网络 IO。我们熟知的系统大部分都属于 IO 密集型，比如数据库系统、缓存系统、Web 系统。这类系统的性能瓶颈可能出在系统内部，也可能是依赖的其他系统，而发现这类性能瓶颈的手段主要有两类。</p>
<ol>
<li>
<p>采用工具<br>
Linux 的工具集很丰富，完全可以满足你的优化需要，比如网络协议栈、网卡、磁盘、文件系统、内存，等等。这些工具的用法很多，你可以在排查问题的过程中逐渐积累。除此之外呢，一些开发语言还有针对语言特性的分析工具，比如说 Java 语言就有其专属的内存分析工具。</p>
</li>
<li>
<p>通过 监控 来发现性能问题。<br>
在监控中我们可以对任务的每一个步骤做分时的统计，从而找到任务的哪一步消耗了更多的时间。这一部分在演进篇中会有专门的介绍，这里就不再展开了。</p>
</li>
</ol>
<p>那么找到了系统的瓶颈点，我们要如何优化呢？优化方案会随着问题的不同而不同。比方说，如果是数据库访问慢，那么就要看是不是有锁表的情况、是不是有全表扫描、索引加得是否合适、是否有 JOIN 操作、需不需要加缓存，等等；如果是网络的问题，就要看网络的参数是否有优化的空间，抓包来看是否有大量的超时重传，网卡是否有大量丢包等。</p>
<h5 id="高可用"><a class="markdownIt-Anchor" href="#高可用"></a> 高可用</h5>
<p>高可用性（High Availability，HA），它指的是系统具备较高的无故障运行的能力。<br>
可用性是一个抽象的概念，你需要知道要如何来度量它，与之相关的概念是： MTBF 和 MTTR。</p>
<p>**MTBF(Mean Time Between Failure)**是平均故障间隔的意思，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。</p>
<p>**MTTR(Mean Time To Repair)**表示故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。</p>
<p>可用性与 MTBF 和 MTTR 的值息息相关，我们可以用下面的公式表示它们之间的关系：</p>
<blockquote>
<p><code>Availability = MTBF / (MTBF + MTTR)</code></p>
</blockquote>
<p>这个公式计算出的结果是一个比例，而这个比例代表着系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801023138.png"></p>
<p><strong>高可用系统设计的思路</strong></p>
<h6 id="系统设计"><a class="markdownIt-Anchor" href="#系统设计"></a> 系统设计</h6>
<p><strong>Design for failure</strong> 是我们做高可用系统设计时秉持的第一原则。在承担百万 QPS 的高并发系统中，集群中机器的数量成百上千台，单机的故障是常态，几乎每一天都有发生故障的可能。</p>
<p>未雨绸缪才能决胜千里。我们在做系统设计的时候，要把发生故障作为一个重要的考虑点，预先考虑如何自动化地发现故障，发生故障之后要如何解决。当然了，除了要有未雨绸缪的思维之外，我们还需要掌握一些具体的优化方法，比如<strong>failover（故障转移）、超时控制以及降级和限流</strong>。</p>
<p><strong>failover（故障转移）</strong><br>
一般来说，发生 failover 的节点可能有两种情况：</p>
<ol>
<li>是在 完全对等 的节点之间做 failover。</li>
<li>是在 不对等 的节点之间，即系统中存在主节点也存在备节点。</li>
</ol>
<p>在对等节点之间做 failover 相对来说简单些。在这类系统中所有节点都承担读写流量，并且节点中不保存状态，每个节点都可以作为另一个节点的镜像。在这种情况下，如果访问某一个节点失败，那么简单地随机访问另一个节点就好了。<br>
举个例子，Nginx 可以配置当某一个 Tomcat 出现大于 500 的请求的时候，重试请求另一个 Tomcat 节点，就像下面这样：</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801100734.png"></p>
<p>针对不对等节点的 failover 机制会复杂很多。比方说我们有一个主节点，有多台备用节点，这些备用节点可以是热备（同样在线提供服务的备用节点），也可以是冷备（只作为备份使用），那么我们就需要在代码中控制如何检测主备机器是否故障，以及如何做主备切换。</p>
<p>使用最广泛的故障检测机制是「心跳」。你可以在客户端上定期地向主节点发送心跳包，也可以从备份节点上定期发送心跳包。当一段时间内未收到心跳包，就可以认为主节点已经发生故障，可以触发选主的操作。</p>
<p>选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比方说 Paxos，Raft。</p>
<p><strong>调用超时控制</strong><br>
除了故障转移以外，对于系统间调用超时的控制也是高可用系统设计的一个重要考虑方面。</p>
<p>复杂的高并发系统通常会有很多的系统模块组成，同时也会依赖很多的组件和服务，比如说缓存组件，队列服务等等。<strong>它们之间的调用最怕的就是延迟而非失败</strong> ，因为失败通常是瞬时的，可以通过重试的方式解决。而一旦调用某一个模块或者服务发生比较大的延迟，调用方就会阻塞在这次调用上，它已经占用的资源得不到释放。当存在大量这种阻塞请求时，调用方就会因为用尽资源而挂掉。</p>
<p>在系统开发的初期，超时控制通常不被重视，或者是没有方式来确定正确的超时时间。</p>
<blockquote>
<p>模块之间通过 RPC 框架来调用，超时时间是默认的 30 秒。平时系统运行得非常稳定，可是一旦遇到比较大的流量，RPC 服务端出现一定数量慢请求的时候，RPC 客户端线程就会大量阻塞在这些慢请求上长达 30 秒，造成 RPC 客户端用尽调用线程而挂掉。后面我们在故障复盘的时候发现这个问题后，调整了 RPC，数据库，缓存以及调用第三方服务的超时时间，这样在出现慢请求的时候可以触发超时，就不会造成整体系统雪崩。</p>
</blockquote>
<p>既然要做超时控制，那么我们怎么来确定超时时间呢？这是一个比较困难的问题。</p>
<blockquote>
<p>超时时间短了，会造成大量的超时错误，对用户体验产生影响；超时时间长了，又起不到作用。 我<strong>建议你通过收集系统之间的调用日志，统计比如说 99% 的响应时间是怎样的，然后依据这个时间来指定超时时间</strong>。 如果没有调用的日志，那么你只能按照经验值来指定超时时间。不过，无论你使用哪种方式，超时时间都不是一成不变的，需要在后面的系统维护过程中不断地修改。</p>
</blockquote>
<p>超时控制实际上就是不让请求一直保持，而是在经过一定时间之后让请求失败，释放资源给接下来的请求使用。这对于用户来说是有损的，但是却是必要的，因为它牺牲了少量的请求却保证了整体系统的可用性。而我们还有另外两种有损的方案能保证系统的高可用，它们就是降级和限流。</p>
<p><strong>降级</strong><br>
<strong>降级是为了保证核心服务的稳定而牺牲非核心服务的做法</strong>。 比方说我们发一条微博会先经过反垃圾服务检测，检测内容是否是广告，通过后才会完成诸如写数据库等逻辑。</p>
<p>反垃圾的检测是一个相对比较重的操作，因为涉及到非常多的策略匹配，在日常流量下虽然会比较耗时却还能正常响应。但是当并发较高的情况下，它就有可能成为瓶颈，而且它也不是发布微博的主体流程，所以我们可以暂时关闭反垃圾服务检测，这样就可以保证主体的流程更加稳定。</p>
<p><strong>限流</strong><br>
<strong>限流完全是另外一种思路</strong>， 它通过对并发的请求进行限速来保护系统。</p>
<p>比如对于 Web 应用，我限制单机只能处理每秒 1000 次的请求，超过的部分直接返回错误给客户端。虽然这种做法损害了用户的使用体验，但是它是在极端并发下的无奈之举，是短暂的行为，因此是可以接受的。</p>
<p>实际上，无论是降级还是限流，在细节上还有很多可供探讨的地方，我会在后面的课程中，随着系统的不断演进深入地剖析，在基础篇里就不多说了。</p>
<h6 id="系统运维"><a class="markdownIt-Anchor" href="#系统运维"></a> 系统运维</h6>
<p>在系统设计阶段为了保证系统的可用性可以采取上面的几种方法，那在系统运维的层面又能做哪些事情呢？其实，我们可以从 <strong>灰度发布、故障演练</strong> 两个方面来考虑如何提升系统的可用性。</p>
<p>你应该知道，在业务平稳运行过程中，系统是很少发生故障的，90% 的故障是发生在上线变更阶段的。比方说，你上了一个新的功能，由于设计方案的问题，数据库的慢请求数翻了一倍，导致系统请求被拖慢而产生故障。</p>
<p>如果没有变更，数据库怎么会无缘无故地产生那么多的慢请求呢？因此，为了提升系统的可用性，重视变更管理尤为重要。而除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外， 另一个主要的手段就是灰度发布。</p>
<p><strong>灰度发布</strong><br>
灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。一般情况下，灰度发布是以机器维度进行的。比方说，我们先在 10% 的机器上进行变更，同时观察 Dashboard 上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。</p>
<p>灰度发布给了开发和运维同学绝佳的机会，让他们能在线上流量上观察变更带来的影响，是保证系统高可用的重要关卡。</p>
<p>灰度发布是在系统正常运行条件下，保证系统高可用的运维手段，那么我们如何知道发生故障时系统的表现呢？这里就要依靠另外一个手段： 故障演练。</p>
<p><strong>故障演练</strong><br>
故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。</p>
<p>一个复杂的高并发系统依赖了太多的组件，比方说磁盘，数据库，网卡等，这些组件随时随地都可能会发生故障，而一旦它们发生故障，会不会如蝴蝶效应一般造成整体服务不可用呢？我们并不知道，因此，故障演练尤为重要。</p>
<p>在我来看， <strong>故障演练和时下比较流行的“混沌工程”的思路如出一辙</strong>， 作为混沌工程的鼻祖，Netfix 在 2010 年推出的 <strong>Chaos Monkey</strong> 工具就是故障演练绝佳的工具。它通过在线上系统上随机地关闭线上节点来模拟故障，让工程师可以了解，在出现此类故障时会有什么样的影响。</p>
<p>当然，这一切是以你的系统可以抵御一些异常情况为前提的。如果你的系统还没有做到这一点，那么 我建议你 另外搭建一套和线上部署结构一模一样的线下系统，然后在这套系统上做故障演练，从而避免对生产系统造成影响。</p>
<p>说了这么多，你可以看到从开发和运维角度上来看，提升可用性的方法是不同的：</p>
<ul>
<li>开发 注重的是如何处理故障，关键词是 冗余和取舍。<br>
冗余指的是有备用节点，集群来顶替出故障的服务，比如文中提到的故障转移，还有多活架构等等；取舍指的是丢卒保车，保障主体服务的安全。<br>
 </li>
<li>从 运维角度 来看则更偏保守，注重的是如何避免故障的发生<br>
比如更关注变更管理以及如何做故障的演练。</li>
</ul>
<p><strong>你还需要注意的是</strong>，提高系统的可用性有时候是以牺牲用户体验或者是牺牲系统性能为前提的，也需要大量人力来建设相应的系统，完善机制。所以我们要把握一个度，不该做过度的优化。就像我在文中提到的，核心系统四个九的可用性已经可以满足需求，就没有必要一味地追求五个九甚至六个九的可用性。</p>
<p>另外，一般的系统或者组件都是追求极致的性能的，那么有没有不追求性能，只追求极致的可用性的呢？答案是有的。比如配置下发的系统，它只需要在其它系统启动时提供一份配置即可，所以秒级返回也可，十秒钟也 OK，无非就是增加了其它系统的启动速度而已。但是，它对可用性的要求是极高的，甚至会到六个九，原因是配置可以获取的慢，但是不能获取不到。我给你举这个例子是想让你了解， 可用性和性能有时候是需要做取舍的，但如何取舍就要视不同的系统而定，不能一概而论了。</p>
<h5 id="易于扩展"><a class="markdownIt-Anchor" href="#易于扩展"></a> 易于扩展</h5>
<p>从架构设计上来说，高可扩展性是一个设计的指标，<strong>它表示可以通过增加机器的方式来线性提高系统的处理能力，从而承担更高的流量和并发</strong>。</p>
<p>你可能会问：在架构设计之初，为什么不预先考虑好使用多少台机器，支持现有的并发呢？<br>
答案 <strong>是峰值的流量不可控</strong>。</p>
<p>一般来说，基于成本考虑，在业务平稳期，我们会预留 30%～50% 的冗余以应对运营活动或者推广可能带来的峰值流量，但是当有一个突发事件发生时，流量可能瞬间提升到 2～3 倍甚至更高，我们还以微博为例。</p>
<p>鹿晗和关晓彤互圈公布恋情，大家会到两个人的微博下面，或围观，或互动，微博的流量短时间内增长迅速，微博信息流也短暂出现无法刷出新的消息的情况。</p>
<p>那我们要如何应对突发的流量呢？架构的改造已经来不及了，最快的方式就是堆机器。不过我们需要保证，扩容了三倍的机器之后，相应的我们的系统也能支撑三倍的流量。有的人可能会产生疑问：这不是显而易见的吗？很简单啊。真的是这样吗？我们来看看做这件事儿难在哪儿。</p>
<p><strong>为什么提升扩展性会很复杂</strong><br>
在上一讲中，我提到可以在单机系统中通过增加处理核心的方式，来增加系统的并行处理能力，但这个方式并不总生效。因为当并行的任务数较多时，系统会因为争抢资源而达到性能上的拐点，系统处理能力不升反降。</p>
<p>而对于由多台机器组成的集群系统来说也是如此。集群系统中，不同的系统分层上可能存在一些 「瓶颈点」，这些瓶颈点制约着系统的横线扩展能力。这句话比较抽象，我举个例子你就明白了。</p>
<p>比方说，你系统的流量是每秒 1000 次请求，对数据库的请求量也是每秒 1000 次。如果流量增加 10 倍，虽然系统可以通过扩容正常服务，数据库却成了瓶颈。再比方说，单机网络带宽是 50Mbps，那么如果扩容到 30 台机器，前端负载均衡的带宽就超过了千兆带宽的限制，也会成为瓶颈点。那么，我们的系统中存在哪些服务会成为制约系统扩展的重要因素呢？</p>
<p>其实，无状态的服务和组件更易于扩展，而像 MySQL 这种存储服务是有状态的，就比较难以扩展。因为向存储集群中增加或者减少机器时，会涉及大量数据的迁移，而一般传统的关系型数据库都不支持。这就是为什么提升系统扩展性会很复杂的主要原因。</p>
<p>除此之外，从例子中你可以看到，我们需要站在整体架构的角度，而不仅仅是业务服务器的角度来考虑系统的扩展性 。 所以说，<strong>数据库、缓存、依赖的第三方、负载均衡、交换机带宽</strong>等等 都是系统扩展时需要考虑的因素。我们要知道系统并发到了某一个量级之后，哪一个因素会成为我们的瓶颈点，从而针对性地进行扩展。</p>
<p>针对这些复杂的扩展性问题，我提炼了一些系统设计思路，供你了解。</p>
<p><strong>高可扩展性的设计思路</strong><br>
<strong>拆分</strong> 是提升系统扩展性最重要的一个思路，它会把庞杂的系统拆分成独立的，有单一职责的模块。相对于大系统来说，考虑一个一个小模块的扩展性当然会简单一些。将复杂的问题简单化，这就是我们的思路。</p>
<p>但对于不同类型的模块，我们在拆分上遵循的原则是不一样的。我给你举一个简单的例子，假如你要设计一个社区，那么社区会有几个模块呢？可能有 5 个模块。</p>
<ol>
<li>用户：负责维护社区用户信息，注册，登陆等；</li>
<li>关系：用户之间关注、好友、拉黑等关系的维护；</li>
<li>内容：社区发的内容，就像朋友圈或者微博的内容；</li>
<li>评论、赞：用户可能会有的两种常规互动操作；</li>
<li>搜索：用户的搜索，内容的搜索。</li>
</ol>
<p>而部署方式遵照最简单的三层部署架构，负载均衡负责请求的分发，应用服务器负责业务逻辑的处理，数据库负责数据的存储落地。这时，所有模块的业务代码都混合在一起了，数据也都存储在一个库里。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801104931.png"></p>
<h6 id="存储层的扩展性"><a class="markdownIt-Anchor" href="#存储层的扩展性"></a> 存储层的扩展性</h6>
<p>无论是存储的数据量，还是并发访问量，不同的业务模块之间的量级相差很大，比如说成熟社区中，关系的数据量是远远大于用户数据量的，但是用户数据的访问量却远比关系数据要大。所以假如存储目前的瓶颈点是容量，那么我们只需要针对关系模块的数据做拆分就好了，而不需要拆分用户模块的数据。 所以<strong>存储拆分首先考虑的维度是业务维度</strong>。</p>
<p>拆分之后，这个简单的社区系统就有了用户库、内容库、评论库、点赞库和关系库。这么做还能隔离故障，某一个库「挂了」不会影响到其它的数据库。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105052.png"></p>
<p><strong>按照业务拆分，在一定程度上提升了系统的扩展性</strong>，但系统运行时间长了之后，单一的业务数据库在容量和并发请求量上仍然会超过单机的限制。 这时，<strong>我们就需要针对数据库做第二次拆分</strong>。</p>
<p><strong>这次拆分是按照数据特征做水平的拆分</strong> ，比如说我们可以给用户库增加两个节点，然后按照某些算法将用户的数据拆分到这三个库里面，具体的算法我会在后面讲述数据库分库分表时和你细说。</p>
<p>水平拆分之后，我们就可以让数据库突破单机的限制了。但这里要注意，我们不能随意地增加节点，因为一旦增加节点就需要手动地迁移数据，成本还是很高的。所以基于长远的考虑，<strong>我们最好一次性增加足够的节点以避免频繁地扩容</strong>。</p>
<p>当数据库按照业务和数据维度拆分之后，我们 <strong>尽量不要使用事务</strong>。因为当一个事务中同时更新不同的数据库时，需要使用二阶段提交，来协调所有数据库要么全部更新成功，要么全部更新失败。这个协调的成本会随着资源的扩展不断升高，最终达到无法承受的程度。</p>
<p>说完了存储层的扩展性，我们来看看业务层是如何做到易于扩展的。</p>
<h6 id="业务层的扩展性"><a class="markdownIt-Anchor" href="#业务层的扩展性"></a> 业务层的扩展性</h6>
<p>我们一般会从三个维度考虑业务层的拆分方案，它们分别是：<strong>业务纬度 ，重要性纬度 和 请求来源纬度</strong>。</p>
<p>首先，我们需要<strong>把相同业务的服务拆分成单独的业务池</strong>，比方说上面的社区系统中，我们可以按照业务的维度拆分成用户池、内容池、关系池、评论池、点赞池和搜索池。</p>
<p>每个业务依赖独自的数据库资源，不会依赖其它业务的数据库资源。这样当某一个业务的接口成为瓶颈时，我们只需要扩展业务的池子，以及确认上下游的依赖方就可以了，这样就大大减少了扩容的复杂度。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105411.png"></p>
<p>除此之外，我们还可以<strong>根据业务接口的重要程度，把业务分为核心池和非核心池</strong> （池子就是一组机器组成的集群） 。打个比方，就关系池而言，关注、取消关注接口相对重要一些，可以放在核心池里面；拉黑和取消拉黑的操作就相对不那么重要，可以放在非核心池里面。这样，我们可以优先保证核心池的性能，当整体流量上升时优先扩容核心池，降级部分非核心池的接口，从而保证整体系统的稳定性。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801105504.png"></p>
<p>最后，你还可以根据接入客户端类型的不同做业务池的拆分。比如说，服务于客户端接口的业务可以定义为外网池，服务于小程序或者 HTML5 页面的业务可以定义为 H5 池，服务于内部其它部门的业务可以定义为内网池，等等。</p>
<p>了解了提升系统扩展性的复杂度以及系统拆分的思路。拆分看起来比较简单，可是什么时候做拆分，如何做拆分还是有很多细节考虑的。</p>
<p>未做拆分的系统虽然可扩展性不强，但是却足够简单，无论是系统开发还是运行维护都不需要投入很大的精力。拆分之后，需求开发需要横跨多个系统多个小团队，排查问题也需要涉及多个系统，运行维护上，可能每个子系统都需要有专人来负责，对于团队是一个比较大的考验。这个考验是我们必须要经历的一个大坎，需要我们做好准备。</p>
<h4 id="番外memcahed组件实现原理"><a class="markdownIt-Anchor" href="#番外memcahed组件实现原理"></a> 番外：Memcahed组件实现原理</h4>
<p>分享一个真实案例。在之前的一个项目中，我们使用 Memcached 作为缓存组件来提升数据的读取性能。在使用的过程中，我们发现一个存储用户认证信息的缓存的命中率极低，只有 20%。</p>
<p>因为这个认证信息只有极少数的用户会有，大部分的用户在数据库中是没有这个数据的，所以最初我认为是因为查询数据库的时候，没有査询到数据导致没有设置到缓存，所以每次查询缓存的时候就不会命中。</p>
<p>于是，我增加了「<code>从数据库中查询到空数据后也回中缓存</code>」的逻辑，但是上线之后效果并不明显。这时，我查看了一下 Memcached 节点的统计信息，发现单个节点 2G 的内存空间仅仅被使用了 300M，而且缓存 tem 剔除数非常得高，达到了几十亿。</p>
<p>我们知道 Memcached 内部采用的是名为 <code>Slab Allocator</code> 的机制来分配和管理内存的，主要为了解决內存分配碎片的问题。这种机制会预先分配若干组内存区域，每一组称为一个 <code>slab class</code>，每个 <code>slab class</code> 下的各个内存区域大小是相同的，每个内存区域称之为 <code>chunk</code>。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801114354.png"></p>
<p>当存储一个数据时，先要看这个数据大小是多少，要存储在哪一个 <code>slab class</code> 下。如果这个 <code>slab class</code> 没有足够的空间了，那么会查找更大的 <code>slab class</code> 直到找到合适的为止。</p>
<p>于是，我考虑是不是因为缓存用户认证信息时没有找到合适的<code>slab class</code>，才导致数据不断地被剔除出缓存，从而造成缓存命中率低。所以我看了一下 <code>slab</code> 的统计信息，发现 <code>slab class5</code> 占用了 2G 内存中的 1.9G，而用户认证信息会被存放在 <code>slab class6</code> 下，而这个 <code>slab class</code> 的剔除数量非常高。再抓取这个 <code>slab class</code> 下的一小部分数据，发现确实都是用户认证信息数据，此时，我才找到问题的根本原因。</p>
<p>你看，如果不了解 Memcached 的内存分配原理，你可能永远都无法彻底解决这个问题。</p>
<p>所以，在面试的过程中，当你被问到组件的实现原理时，面试官其实想要了解你，是否对于实现原理中涉及的基础知识有足够的了解？在实际开发中，你是否能够运用这些基础知识来设计合理的方案？以及，当这些组件发生问题的时候，你是否有思路解决？</p>
<p>所以，其实你无需对组件达到源代码级别的了解，只需要深入了解它的实现原理，再结合一些基础知识，如算法、网络、操作系统等等，就足够应对 80% 的面试问题。</p>
<h3 id="数据库"><a class="markdownIt-Anchor" href="#数据库"></a> 数据库</h3>
<h4 id="池化技术"><a class="markdownIt-Anchor" href="#池化技术"></a> 池化技术</h4>
<p>如何减少频繁创建数据库连接的性能损耗？</p>
<p>单纯地讲解理论，讲解方案会比较枯燥，所以我将用一个虚拟的系统作为贯穿整个课程的主线，说明当这个系统到达某一个阶段时，我们会遇到什么问题，然后要采用什么样的方案应对，应对的过程中又涉及哪些技术点。通过这样的讲述方式，力求以案例引出问题，能够让你了解遇到不同问题时，解决思路是怎样的。</p>
<p>你公司看到了一个新的商业机会，希望你能带领一名兄弟，迅速研发出一套面向某个垂直领域的电商系统。</p>
<p>在人手紧张，时间不足的情况下，为了能够完成任务，你毫不犹豫地采用了 最简单的架构 ：前端一台 Web 服务器运行业务代码，后端一台数据库服务器存储业务数据。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801115650.png"></p>
<p>这个架构图是我们每个人最熟悉的，最简单的架构原型，很多系统在一开始都是长这样的，只是随着业务复杂度的提高，架构做了叠加，然后看起来就越来越复杂了。</p>
<p>再说回我们的垂直电商系统，系统一开始上线之后，虽然用户量不大，但运行平稳，你很有成就感，不过 CEO 觉得用户量太少了，所以紧急调动运营同学做了一次全网的流量推广。</p>
<p>这一推广很快带来了一大波流量， 但这时，系统的访问速度开始变慢。</p>
<p>分析程序的日志之后，你发现系统慢的原因 出现在和数据库的交互上 。因为你们数据库的调用方式是先获取数据库的连接，然后依靠这条连接从数据库中查询数据，最后关闭连接释放数据库资源。这种调用方式下，每次执行 SQL 都需要重新建立连接，所以你怀疑， <strong>是不是频繁地建立数据库连接耗费时间长导致了访问慢的问题</strong>。</p>
<p><strong>那么为什么频繁创建连接会造成响应时间慢呢？来看一个实际的测试</strong>。<br>
我用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="comment"># -i: 指定网卡</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">tcpdump -i bond0 -nn -tttt port 4490</span></pre></td></tr></table></figure>
<p>命令抓取了线上 MySQL 建立连接的网络包来做分析，从抓包结果来看，整个 MySQL 的连接过程可以分为两部分：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801120009.png"></p>
<ul>
<li>
<p>第一部分是前三个数据包<br>
第一个数据包是客户端向服务端发送的一个 SYN 包，<br>
第二个包是服务端回给客户端的 ACK 包以及一个 SYN 包，<br>
第三个包是客户端回给服务端的 ACK 包，熟悉 TCP 协议的同学可以看出这是一个 TCP 的三次握手过程。</p>
</li>
<li>
<p>第二部分是 MySQL 服务端校验客户端密码的过程。<br>
其中第一个包是服务端发给客户端要求认证的报文，<br>
第二和第三个包是客户端将加密后的密码发送给服务端的包，<br>
最后两个包是服务端回给客户端认证 OK 的报文。</p>
</li>
</ul>
<p>从图中，你可以看到整个连接过程大概消耗了 4ms（969012-964904）。</p>
<p>那么单条 SQL 执行时间是多少呢？我们统计了一段时间的 SQL 执行时间，发现 SQL 的平均执行时间大概是 1ms，也就是说相比于 SQL 的执行，MySQL 建立连接的过程是比较耗时的。这在请求量小的时候其实影响不大，因为无论是建立连接还是执行 SQL，耗时都是毫秒级别的。可是请求量上来之后，如果按照原来的方式建立一次连接只执行一条 SQL 的话，1s 只能执行 200 次数据库的查询，而数据库建立连接的时间占了其中 4/5。</p>
<p>一番谷歌搜索之后，你发现解决方案也很简单，只要使用连接池将数据库连接预先建立好，这样在使用的时候就不需要频繁地创建连接了。调整之后，你发现 1s 就可以执行 1000 次的数据库查询，查询性能大大的提升了。</p>
<h5 id="用连接池预先建立数据库连接"><a class="markdownIt-Anchor" href="#用连接池预先建立数据库连接"></a> 用连接池预先建立数据库连接</h5>
<p>在开发过程中我们会用到很多的连接池，像是数据库连接池、HTTP 连接池、Redis 连接池等等。而连接池的管理是连接池设计的核心， 我就以数据库连接池为例，来说明一下连接池管理的关键点。</p>
<p>数据库连接池有两个最重要的配置： <strong>最小连接数和最大连接数</strong>， 它们控制着从连接池中获取连接的流程</p>
<ul>
<li>如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；</li>
<li>如果连接池中有空闲连接则复用空闲连接；</li>
<li>如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；</li>
<li>如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（C3P0 的连接池配置是 checkoutTimeout）+ 等待旧的连接可用；</li>
<li>如果等待超过了这个设定时间则向用户抛出错误。</li>
</ul>
<p>对于数据库连接池，根据我的经验，一般在线上我<strong>建议最小连接数控制在 10 左右</strong>，<strong>最大连接数控制在 20～30 左右即可</strong>。</p>
<p>在这里，你需要注意池子中连接的维护问题:</p>
<ol>
<li>
<p>数据库的域名对应的 IP 发生了变更，池子的连接还是使用旧的 IP，当旧的 IP 下的数据库服务关闭后，再使用这个连接查询就会发生错误；</p>
</li>
<li>
<p>MySQL 有个参数是 wait_timeout，控制着当数据库连接闲置多长时间后，数据库会主动的关闭这条连接。这个机制对于数据库使用方是无感知的，所以当我们使用这个被关闭的连接时就会发生错误。</p>
</li>
</ol>
<p>那么，怎么保证你启动着的数据库一定是可用的呢？</p>
<ol>
<li>
<p>启动一个线程来定期检测连接池中的连接是否可用，比如使用连接发送 <code>select 1</code> 的命令给数据库看是否会抛出异常，如果抛出异常则将这个连接从连接池中移除，并且尝试关闭。目前 C3P0 连接池可以采用这种方式来检测连接是否可用， 也是我比较推荐的方式。</p>
</li>
<li>
<p>在获取到连接之后，先校验连接是否可用，如果可用才会执行 SQL 语句。比如 DBCP 连接池的 testOnBorrow 配置项，就是控制是否开启这个验证。这种方式在获取连接时会引入多余的开销， 在线上系统中还是尽量不要开启，在测试服务上可以使用。</p>
</li>
</ol>
<p>至此，你彻底搞清楚了连接池的工作原理。可是，当你刚想松一口气的时候，CEO 又提出了一个新的需求。你分析了一下这个需求，发现在一个非常重要的接口中，你需要访问 3 次数据库。根据经验判断，你觉得这里未来肯定会成为系统瓶颈。</p>
<p>进一步想，你觉得可以创建多个线程来并行处理与数据库之间的交互，这样速度就能快了。不过，因为有了上次数据库的教训，你想到在高并发阶段，频繁创建线程的开销也会很大，于是顺着之前的思路继续想，猜测到了线程池。</p>
<h5 id="用线程池预先创建线程"><a class="markdownIt-Anchor" href="#用线程池预先创建线程"></a> 用线程池预先创建线程</h5>
<p>JDK 1.5 中引入的 ThreadPoolExecutor 就是一种线程池的实现，它有两个重要的参数：coreThreadCount 和 maxThreadCount，这两个参数控制着线程池的执行过程。</p>
<ul>
<li>如果线程池中的线程数少于 coreThreadCount 时，处理新的任务时会创建新的线程；</li>
<li>如果线程数大于 coreThreadCount 则把任务丢到一个队列里面，由当前空闲的线程执行；</li>
<li>当队列中的任务堆积满了的时候，则继续创建线程，直到达到 maxThreadCount；</li>
<li>当线程数达到 maxTheadCount 时还有新的任务提交，那么我们就不得不将它们丢弃了。</li>
</ul>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801123011.png"></p>
<p>这个任务处理流程看似简单，实际上有很多坑，你在使用的时候一定要注意。</p>
<p>首先， JDK 实现的这个线程池优 先把任务放入队列暂存起来，而不是创建更多的线程 ，它比较适用于执行 CPU 密集型的任务，也就是需要执行大量 CPU 运算的任务。这是为什么呢？因为执行 CPU 密集型的任务时 CPU 比较繁忙，因此只需要创建和 CPU 核数相当的线程就好了，多了反而会造成线程上下文切换，降低任务执行效率。所以当当前线程数超过核心线程数时，线程池不会增加线程，而是放在队列里等待核心线程空闲下来。</p>
<p>但是，我们平时开发的 Web 系统通常都有大量的 IO 操作，比方说查询数据库、查询缓存等等。任务在执行 IO 操作的时候 CPU 就空闲了下来，这时如果增加执行任务的线程数而不是把任务暂存在队列中，就可以在单位时间内执行更多的任务，大大提高了任务执行的吞吐量。所以你看 Tomcat 使用的线程池就不是 JDK 原生的线程池，而是做了一些改造，当线程数超过 coreThreadCount 之后会优先创建线程，直到线程数到达 maxThreadCount，这样就比较适合于 Web 系统大量 IO 操作的场景了，你在实际运用过程中也可以参考借鉴。</p>
<p>其次，<strong>线程池中使用的队列的堆积量也是我们需要监控的重要指标</strong> ，对于实时性要求比较高的任务来说，这个指标尤为关键。</p>
<p>我在实际项目中就曾经遇到过任务被丢给线程池之后，长时间都没有被执行的诡异问题。 最初，我认为这是代码的 Bug 导致的，后来经过排查发现，是因为线程池的 coreThreadCount 和 maxThreadCount 设置的比较小，导致任务在线程池里面大量的堆积，在调大了这两个参数之后问题就解决了。跳出这个坑之后，我就把重要线程池的队列任务堆积量 ，作为一个重要的监控指标放到了系统监控大屏上。</p>
<p>最后， 如果你使用线程池请一定记住 <strong>不要使用无界队列</strong>（<strong>即没有设置固定大小的队列</strong>） 。也许你会觉得使用了无界队列后，任务就永远不会被丢弃，只要任务对实时性要求不高，反正早晚有消费完的一天。但是，大量的任务堆积会占用大量的内存空间，一旦内存空间被占满就会频繁地触发 Full GC，造成服务不可用，我之前排查过的一次 GC 引起的宕机，起因就是系统中的一个线程池使用了无界队列。</p>
<p>回顾一下这两种技术，会发现它们都有一个 共同点：</p>
<blockquote>
<p>它们所管理的对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源 。<br>
所以，我们把它们放在一个池子里统一管理起来，以达到提升性能和资源复用的目的 。</p>
</blockquote>
<p>这是一种常见的软件设计思想，叫做<strong>池化技术</strong>， 它的<strong>核心思想是空间换时间</strong>，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本，总之是好处多多。</p>
<p>池化技术也存在一些缺陷，比方说存储池子中的对象肯定需要消耗多余的内存，如果对象没有被频繁使用，就会造成内存上的浪费。再比方说，池子中的对象需要在系统启动的时候就预先创建完成，这在一定程度上增加了系统启动时间。</p>
<p>可这些缺陷相比池化技术的优势来说就比较微不足道了，只要我们确认要使用的对象在创建时确实比较耗时或者消耗资源，并且这些对象也确实会被频繁地创建和销毁，我们就可以使用池化技术来优化。</p>
<p>在遇到数据库查询性能下降的问题时，我们使用数据库连接池解决了频繁创建连接带来的性能问题，后面又使用线程池提升了并行查询数据库的性能。</p>
<h5 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h5>
<p>其实，连接池和线程池你并不陌生，不过你可能对它们的原理和使用方式上还存在困惑或者误区，我在面试时，就发现有很多的同学对线程池的基本使用方式都不了解。借用这节课，我想再次强调的重点是：</p>
<ol>
<li>池子的最大值和最小值的设置很重要，初期可以依据经验来设置，后面还是需要根据实际运行情况做调整。</li>
<li>池子中的对象需要在使用之前预先初始化完成，这叫做 <strong>池子的预热</strong> ，比方说使用线程池时就需要预先初始化所有的核心线程。如果池子未经过预热可能会导致系统重启后产生比较多的慢请求。</li>
<li>池化技术核心是一种空间换时间优化方法的实践，所以要关注空间占用情况，避免出现空间过度使用出现内存泄露或者频繁垃圾回收等问题。</li>
</ol>
<h4 id="数据库优化方案"><a class="markdownIt-Anchor" href="#数据库优化方案"></a> 数据库优化方案</h4>
<h5 id="主从分离"><a class="markdownIt-Anchor" href="#主从分离"></a> 主从分离</h5>
<p>我们用池化技术解决了数据库连接复用的问题，这时，你的垂直电商系统虽然整体架构上没有变化，但是和数据库交互的过程有了变化，在你的 Web 工程和数据库之间增加了数据库连接池，减少了频繁创建连接的成本，从上节课的测试来看性能上可以提升 80%。现在的架构图如下所示：<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801132328.png"></p>
<p>你的数据库还是单机部署，依据一些云厂商的 Benchmark 的结果，在 4 核 8G 的机器上运 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS。这时，运营负责人说正在准备双十一活动，并且公司层面会继续投入资金在全渠道进行推广，这无疑会引发查询量骤然增加的问题。那么今天，我们就一起来看看当查询请求增加时，应该如何做主从分离来解决问题。</p>
<p><strong>主从读写分离</strong><br>
其实，大部分系统的访问模型是 读多写少，读写请求量的差距可能达到几个数量级。</p>
<p>这很好理解，刷朋友圈的请求量肯定比发朋友圈的量大，淘宝上一个商品的浏览量也肯定远大于它的下单量。因此，我们优先考虑数据库如何抗住更高的查询请求，那么首先你需要把读写流量区分开，因为这样才方便针对读流量做单独的扩展，这就是我们所说的主从读写分离。</p>
<p>它其实是个流量分离的问题，就好比道路交通管制一样，一个四车道的大马路划出三个车道给领导外宾通过，另外一个车道给我们使用，优先保证领导先行，就是这个道理。</p>
<p>这个方法本身是一种常规的做法，即使在一个大的项目中，它也是一个应对数据库突发读流量的有效方法。</p>
<p>我目前的项目中就曾出现过前端流量突增导致从库负载过高的问题，DBA 兄弟会优先做一个从库扩容上去，这样对数据库的读流量就会落入到多个从库上，从库的负载就降了下来，然后研发同学再考虑使用什么样的方案将流量挡在数据库层之上。</p>
<p><strong>主从读写的两个技术关键点</strong><br>
一般来说在主从读写分离机制中，我们将一个数据库的数据拷贝为一份或者多份，并且写入到其它的数据库服务器中，原始的数据库我们称为 主库，主要负责数据的写入，拷贝的目标数据库称为 从库，主要负责支持数据查询。可以看到，主从读写分离有两个技术上的关键点：</p>
<ol>
<li>数据的拷贝，我们称为主从复制；</li>
<li>在主从分离的情况下，我们<strong>如何屏蔽主从分离带来的访问数据库方式的变化</strong>，让开发同学像是在使用单一数据库一样。</li>
</ol>
<h6 id="主从复制"><a class="markdownIt-Anchor" href="#主从复制"></a> 主从复制</h6>
<p>MySQL 的主从复制是依赖于 binlog 的，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上二进制日志文件。<strong>主从复制就是将 binlog 中的数据从主库传输到从库上</strong> ，一般这个过程是异步的，即主库上的操作不会等待 binlog 同步的完成。</p>
<p><strong>主从复制的过程</strong></p>
<ol>
<li>首先从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中</li>
<li>主库也会创建一个 log dump 线程来发送 binlog 给从库；</li>
<li>同时，从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。</li>
</ol>
<p>这是一种比较常见的主从复制方式。</p>
<p>在这个方案中，使用独立的 log dump 线程是一种异步的方式，可以避免对主库的主体更新流程产生影响，而从库在接收到信息后并不是写入从库的存储中，是写入一个 relay log，是避免写入从库实际存储会比较耗时，最终造成从库和主库延迟变长。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801132935.png"></p>
<p>你会发现，基于性能的考虑，主库的写入流程并没有等待主从同步完成就会返回结果，那么在极端的情况下，比如说主库上 binlog 还没有来得及刷新到磁盘上就出现了磁盘损坏或者机器掉电，就会导致 binlog 的丢失，最终造成主从数据的不一致。 不过，<strong>这种情况出现的概率很低，对于互联网的项目来说是可以容忍的</strong>。</p>
<p>做了主从复制之后，我们就可以在写入时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响到读请求的执行。同时呢，在读流量比较大的情况下，我们可以部署多个从库共同承担读流量，这就是所说的 <strong>一主多从</strong> 部署方式，在你的垂直电商项目中就可以通过这种方式来抵御较高的并发读流量。另外，从库也可以当成一个备库来使用，以避免主库故障导致数据丢失。</p>
<p>那么你可能会说，是不是我<strong>无限制地增加从库的数量就可以抵抗大量的并发呢</strong>？ 实际上并不是的。因为随着从库数量增加，从库连接上来的 IO 线程比较多，主库也需要创建同样多的 log dump 线程来处理复制的请求，对于主库资源消耗比较高，同时受限于主库的网络带宽，所以在实际使用中，<strong>一般一个主库最多挂 3～5 个从库</strong>。</p>
<p>当然，主从复制也有一些缺陷， 除了带来了部署上的复杂度，还有就是会带来一定的主从同步的延迟，这种延迟有时候会对业务产生一定的影响，我举个例子你就明白了。</p>
<p>在发微博的过程中会有些同步的操作，像是更新数据库的操作，也有一些异步的操作，比如说将微博的信息同步给审核系统，所以我们在更新完主库之后，会将微博的 ID 写入消息队列，再由队列处理机依据 ID 在从库中获取微博信息再发送给审核系统。 此时如果主从数据库存在延迟，会导致在从库中获取不到微博信息，整个流程会出现异常。</p>
<p><img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801133231.png"></p>
<p>这个问题解决的思路有很多，核心思想就是<strong>尽量不去从库中查询信息</strong> ，纯粹以上面的例子来说，我就有三种解决方案：</p>
<ul>
<li>
<p>第一种方案是数据的冗余。<br>
你可以在发送消息队列时不仅仅发送微博 ID，而是发送队列处理机需要的所有微博信息，借此避免从数据库中重新查询数据。<br>
 </p>
</li>
<li>
<p>第二种方案是使用缓存。<br>
我可以在同步写数据库的同时，也把微博的数据写入到 Memcached 缓存里面，这样队列处理机在获取微博信息的时候会优先查询缓存，这样也可以保证数据的一致性。<br>
 </p>
</li>
<li>
<p>最后一种方案是查询主库。<br>
我可以在队列处理机中不查询从库而改为查询主库。不过，这种方式使用起来要慎重，要明确查询的量级不会很大，是在主库的可承受范围之内，否则会对主库造成比较大的压力。<br>
 </p>
</li>
</ul>
<p>我会优先考虑第一种方案，因为这种方式足够简单， <strong>不过可能造成单条消息比较大，从而增加了消息发送的带宽和时间</strong> 。</p>
<p>缓存的方案比较 <strong>适合新增数据的场景</strong>，在更新数据的场景下， 先更新缓存可能会造成数据的不一致 ，比方说两个线程同时更新数据：</p>
<ol>
<li>线程 A 把缓存中的数据更新为 1</li>
<li>此时另一个线程 B 把缓存中的数据更新为 2，然后线程 B 又更新数据库中的数据为 2，</li>
<li>此时线程 A 更新数据库中的数据为 1，这样数据库中的值（1）和缓存中的值（2）就不一致了。</li>
</ol>
<p>最后，若<strong>非万不得已的情况下，我不会使用第三种方案</strong>。原因是这种方案要提供一个查询主库的接口，在团队开发的过程中，你很难保证其他同学不会滥用这个方法，而一旦主库承担了大量的读请求导致崩溃，那么对于整体系统的影响是极大的。</p>
<p>所以对这三种方案来说，你要有所取舍，根据实际项目情况做好选择。</p>
<p>另外，<strong>主从同步的延迟</strong>，是我们排查问题时很容易忽略的一个问题。 有时候我们遇到从数据库中获取不到信息的诡异问题时，会纠结于代码中是否有一些逻辑会把之前写入的内容删除，但是你又会发现，过了一段时间再去查询时又可以读到数据了，这基本上就是主从延迟在作怪。</p>
<blockquote>
<p>所以，一般我们会把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。</p>
</blockquote>
<h6 id="如何访问数据库"><a class="markdownIt-Anchor" href="#如何访问数据库"></a> 如何访问数据库</h6>
<p>我们已经使用主从复制的技术将数据复制到了多个节点，也实现了数据库读写的分离，这时，对于数据库的使用方式发生了变化。以前只需要使用一个数据库地址就好了，现在需要使用一个主库地址和多个从库地址，并且需要区分写入操作和查询操作，如果结合下一节课中要讲解的内容 分库分表，复杂度会提升更多。 为了降低实现的复杂度，业界涌现了很多数据库中间件来解决数据库的访问问题，这些中间件可以分为两类。</p>
<ol>
<li>
<p>第一类以淘宝的 TDDL（ Taobao Distributed Data Layer）为代表，以代码形式内嵌运行在应用程序内部。<br>
你可以把它看成是一种数据源的代理，它的配置管理着多个数据源，每个数据源对应一个数据库，可能是主库，可能是从库。当有一个数据库请求时，中间件将 SQL 语句发给某一个指定的数据源来处理，然后将处理结果返回。</p>
<p>这一类中间件的优点是简单易用，没有多余的部署成本，因为它是植入到应用程序内部，与应用程序一同运行的，所以比较适合运维能力较弱的小团队使用；缺点是缺乏多语言的支持，目前业界这一类的主流方案除了 TDDL，还有早期的网易 DDB，它们都是 Java 语言开发的，无法支持其他的语言。另外，版本升级也依赖使用方更新，比较困难。<br>
 </p>
</li>
<li>
<p>另一类是单独部署的代理层方案<br>
这一类方案代表比较多，如早期阿里巴巴开源的 Cobar，基于 Cobar 开发出来的 Mycat，360 开源的 Atlas，美团开源的基于 Atlas 开发的 DBProxy 等等。</p>
</li>
</ol>
<p>第2类中间件部署在独立的服务器上，业务代码如同在使用单一数据库一样使用它，实际上它内部管理着很多的数据源，当有数据库请求时，它会对 SQL 语句做必要的改写，然后发往指定的数据源。</p>
<p>它一般使用标准的 MySQL 通信协议，所以可以很好地支持多语言。由于它是独立部署的，所以也比较方便进行维护升级，比较适合有一定运维能力的大中型团队使用。它的缺陷是所有的 SQL 语句都需要跨两次网络：从应用到代理层和从代理层到数据源，所以在性能上会有一些损耗。<br>
<img alt data-src="https://raw.githubusercontent.com/fayhot/figurebed/master/20210412/20210801134036.png"><br>
这些中间件，对你而言，可能并不陌生，但是我想让你注意到是， <strong>在使用任何中间件的时候一定要保证对于中间件有足够深入的了解</strong>，否则一旦出了问题没法快速地解决就悲剧了。</p>
<h6 id="小结-2"><a class="markdownIt-Anchor" href="#小结-2"></a> 小结</h6>
<p>了解了查询量增加时，我们如何通过<strong>主从分离</strong>和<strong>一主多从</strong>部署抵抗增加的数据库流量的，你除了掌握主从复制的技术之外，还需要 <strong>了解主从分离会带来什么问题以及它们的解决办法</strong> 。</p>
<ol>
<li>主从读写分离以及部署一主多从可以解决突发的数据库读流量，是一种数据库 <code>横向扩展</code> 的方法；</li>
<li>读写分离后，<strong>主从的延迟是一个关键的监控指标</strong>，可能会造成写入数据之后立刻读的时候读取不到的情况；</li>
<li>业界有很多的方案可以屏蔽主从分离之后数据库访问的细节，让开发人员像是访问单一数据库一样，包括有像 TDDL、Sharding-JDBC 这样的嵌入应用内部的方案，也有像 Mycat 这样的独立部署的代理方案。</li>
</ol>
<p>其实，<strong>我们可以把主从复制引申为存储节点之间互相复制存储数据的技术</strong> ，它可以实现数据的冗余，以达到备份和提升横向扩展能力的作用。在使用主从复制这个技术点时，你一般会考虑两个问题：</p>
<ol>
<li>主从的一致性和写入性能的权衡<br>
如果你要保证所有从节点都写入成功，那么写入性能一定会受影响；<br>
如果你只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致， 而在互联网的项目中，我们一般会<strong>优先考虑性能而不是数据的强一致性</strong>。<br>
 </li>
<li>主从的延迟问题<br>
很多诡异的读取不到数据的问题都可能会和它有关，如果你遇到这类问题不妨先看看主从延迟的数据。</li>
</ol>
<p>我们采用的很多组件都会使用到这个技术，比如</p>
<ol>
<li>Redis 也是通过主从复制实现读写分离；</li>
<li>Elasticsearch 中存储的索引分片也可以被复制到多个节点中；</li>
<li>写入到 HDFS 中文件也会被复制到多个 DataNode 中。</li>
</ol>
<p>只是不同的组件对于复制的一致性、延迟要求不同，采用的方案也不同。 但是这种设计的思想是通用的，是你需要了解的，这样你在学习其他存储组件的时候就能够触类旁通了。</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Architecture/" rel="tag"><i class="fa fa-tag"></i> Architecture</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/rd/mysql-protocol.html" rel="prev" title="Mysql浅尝辄止">
      <i class="fa fa-chevron-left"></i> Mysql浅尝辄止
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#基础篇"><span class="nav-number">1.</span> <span class="nav-text"> 基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#高并发系统它的通用设计方法是什么"><span class="nav-number">1.1.</span> <span class="nav-text"> 高并发系统：它的通用设计方法是什么</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#scale-up-vs-scale-out"><span class="nav-number">1.1.1.</span> <span class="nav-text"> Scale-up vs Scale-out</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缓存提升性能"><span class="nav-number">1.1.2.</span> <span class="nav-text"> 缓存提升性能</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#异步处理"><span class="nav-number">1.1.3.</span> <span class="nav-text"> 异步处理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构分层"><span class="nav-number">1.2.</span> <span class="nav-text"> 架构分层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#系统设计目标高性能-高可用-可扩展"><span class="nav-number">1.3.</span> <span class="nav-text"> 系统设计目标：高性能、高可用、可扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#高并发"><span class="nav-number">1.3.1.</span> <span class="nav-text"> 高并发</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#提高系统的处理核心数"><span class="nav-number">1.3.1.1.</span> <span class="nav-text"> 提高系统的处理核心数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#减少单次任务响应时间"><span class="nav-number">1.3.1.2.</span> <span class="nav-text"> 减少单次任务响应时间</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#高可用"><span class="nav-number">1.3.2.</span> <span class="nav-text"> 高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#系统设计"><span class="nav-number">1.3.2.1.</span> <span class="nav-text"> 系统设计</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#系统运维"><span class="nav-number">1.3.2.2.</span> <span class="nav-text"> 系统运维</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#易于扩展"><span class="nav-number">1.3.3.</span> <span class="nav-text"> 易于扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#存储层的扩展性"><span class="nav-number">1.3.3.1.</span> <span class="nav-text"> 存储层的扩展性</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#业务层的扩展性"><span class="nav-number">1.3.3.2.</span> <span class="nav-text"> 业务层的扩展性</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#番外memcahed组件实现原理"><span class="nav-number">1.4.</span> <span class="nav-text"> 番外：Memcahed组件实现原理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据库"><span class="nav-number">2.</span> <span class="nav-text"> 数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#池化技术"><span class="nav-number">2.1.</span> <span class="nav-text"> 池化技术</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#用连接池预先建立数据库连接"><span class="nav-number">2.1.1.</span> <span class="nav-text"> 用连接池预先建立数据库连接</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#用线程池预先创建线程"><span class="nav-number">2.1.2.</span> <span class="nav-text"> 用线程池预先创建线程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#小结"><span class="nav-number">2.1.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据库优化方案"><span class="nav-number">2.2.</span> <span class="nav-text"> 数据库优化方案</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#主从分离"><span class="nav-number">2.2.1.</span> <span class="nav-text"> 主从分离</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#主从复制"><span class="nav-number">2.2.1.1.</span> <span class="nav-text"> 主从复制</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#如何访问数据库"><span class="nav-number">2.2.1.2.</span> <span class="nav-text"> 如何访问数据库</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#小结-2"><span class="nav-number">2.2.1.3.</span> <span class="nav-text"> 小结</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fayhot"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Fayhot</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">39</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/fayhot" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fayhot" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:liuguoqing228@gmail.com" title="E-Mail → mailto:liuguoqing228@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/shisanyaowan" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;shisanyaowan" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fayhot</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.5.0
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
